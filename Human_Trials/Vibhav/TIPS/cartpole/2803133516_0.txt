FDM train: iteration: 500, fdm_loss: 0.016456
FDM train: iteration: 1000, fdm_loss: 0.008164
FDM train: iteration: 1500, fdm_loss: 0.006700
FDM train: iteration: 2000, fdm_loss: 0.003112
FDM train: iteration: 2500, fdm_loss: 0.001310
FDM train: iteration: 3000, fdm_loss: 0.000589
FDM train: iteration: 3500, fdm_loss: 0.000684
FDM train: iteration: 4000, fdm_loss: 0.000512
FDM train: iteration: 4500, fdm_loss: 0.000555
FDM train: iteration: 5000, fdm_loss: 0.000653
FDM train: iteration: 5500, fdm_loss: 0.000551
FDM train: iteration: 6000, fdm_loss: 0.000467
FDM train: iteration: 6500, fdm_loss: 0.000442
FDM train: iteration: 7000, fdm_loss: 0.000373
FDM train: iteration: 7500, fdm_loss: 0.000350
FDM train: iteration: 8000, fdm_loss: 0.000332
FDM train: iteration: 8500, fdm_loss: 0.000333
FDM train: iteration: 9000, fdm_loss: 0.000092
FDM train: iteration: 9500, fdm_loss: 0.000100
FDM train: iteration: 10000, fdm_loss: 0.000053
FDM train: iteration: 10500, fdm_loss: 0.000073
FDM train: iteration: 11000, fdm_loss: 0.000072
FDM train: iteration: 11500, fdm_loss: 0.000056
FDM train: iteration: 12000, fdm_loss: 0.000045
FDM train: iteration: 12500, fdm_loss: 0.000042
FDM train: iteration: 13000, fdm_loss: 0.000045
FDM train: iteration: 13500, fdm_loss: 0.000101
FDM train: iteration: 14000, fdm_loss: 0.000103
FDM train: iteration: 14500, fdm_loss: 0.000091
FDM train: iteration: 15000, fdm_loss: 0.000057
FDM train: iteration: 15500, fdm_loss: 0.000045
FDM train: iteration: 16000, fdm_loss: 0.000073
FDM train: iteration: 16500, fdm_loss: 0.000063
FDM train: iteration: 17000, fdm_loss: 0.000080
FDM train: iteration: 17500, fdm_loss: 0.000031
FDM train: iteration: 18000, fdm_loss: 0.000034
FDM train: iteration: 18500, fdm_loss: 0.000085
FDM train: iteration: 19000, fdm_loss: 0.000034
FDM train: iteration: 19500, fdm_loss: 0.000083
FDM train: iteration: 20000, fdm_loss: 0.000055
FDM train: iteration: 20500, fdm_loss: 0.000045
FDM train: iteration: 21000, fdm_loss: 0.000070
FDM train: iteration: 21500, fdm_loss: 0.000054
FDM train: iteration: 22000, fdm_loss: 0.000047
FDM train: iteration: 22500, fdm_loss: 0.000068
FDM train: iteration: 23000, fdm_loss: 0.000088
FDM train: iteration: 23500, fdm_loss: 0.000087
FDM train: iteration: 24000, fdm_loss: 0.000040
FDM train: iteration: 24500, fdm_loss: 0.000039
FDM train: iteration: 25000, fdm_loss: 0.000158
FDM train: iteration: 25500, fdm_loss: 0.000038
FDM train: iteration: 26000, fdm_loss: 0.000053
FDM train: iteration: 26500, fdm_loss: 0.000051
FDM train: iteration: 27000, fdm_loss: 0.000062
FDM train: iteration: 27500, fdm_loss: 0.000044
FDM train: iteration: 28000, fdm_loss: 0.000051
FDM train: iteration: 28500, fdm_loss: 0.000027
FDM train: iteration: 29000, fdm_loss: 0.000046
FDM train: iteration: 29500, fdm_loss: 0.000042
FDM train: iteration: 30000, fdm_loss: 0.000041
FDM train: iteration: 30500, fdm_loss: 0.000070
FDM train: iteration: 31000, fdm_loss: 0.000022
FDM train: iteration: 31500, fdm_loss: 0.000037
FDM train: iteration: 32000, fdm_loss: 0.000034

episode_reward:  19.0
Background Trial: 1, reward: 15.0
Background Trial: 2, reward: 14.0
Background Trial: 3, reward: 14.0
Background Trial: 4, reward: 15.0
Background Trial: 5, reward: 14.0
Background Trial: 6, reward: 14.0
Background Trial: 7, reward: 15.0
Background Trial: 8, reward: 14.0
Background Trial: 9, reward: 15.0
Iteration: 1, average_reward: 14.444444444444445, feedback_rate: 0.5


episode_reward:  19.0
Background Trial: 1, reward: 14.0
Background Trial: 2, reward: 15.0
Background Trial: 3, reward: 14.0
Background Trial: 4, reward: 15.0
Background Trial: 5, reward: 15.0
Background Trial: 6, reward: 15.0
Background Trial: 7, reward: 15.0
Background Trial: 8, reward: 15.0
Background Trial: 9, reward: 15.0
Iteration: 2, average_reward: 14.777777777777779, feedback_rate: 0.25


episode_reward:  24.0
Background Trial: 1, reward: 39.0
Background Trial: 2, reward: 36.0
Background Trial: 3, reward: 31.0
Background Trial: 4, reward: 34.0
Background Trial: 5, reward: 35.0
Background Trial: 6, reward: 31.0
Background Trial: 7, reward: 34.0
Background Trial: 8, reward: 35.0
Background Trial: 9, reward: 38.0
Iteration: 3, average_reward: 34.77777777777778, feedback_rate: 0.64


episode_reward: 138.0
Background Trial: 1, reward: 74.0
Background Trial: 2, reward: 77.0
Background Trial: 3, reward: 82.0
Background Trial: 4, reward: 77.0
Background Trial: 5, reward: 74.0
Background Trial: 6, reward: 76.0
Background Trial: 7, reward: 76.0
Background Trial: 8, reward: 75.0
Background Trial: 9, reward: 76.0
Iteration: 4, average_reward: 76.33333333333333, feedback_rate: 0.6258992805755396


episode_reward:  81.0
Background Trial: 1, reward: 136.0
Background Trial: 2, reward: 149.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 93.0
Background Trial: 5, reward: 89.0
Background Trial: 6, reward: 108.0
Background Trial: 7, reward: 112.0
Background Trial: 8, reward: 138.0
Background Trial: 9, reward: 173.0
Iteration: 5, average_reward: 133.11111111111111, feedback_rate: 0.5853658536585366


episode_reward:  93.0
Background Trial: 1, reward: 147.0
Background Trial: 2, reward: 144.0
Background Trial: 3, reward: 159.0
Background Trial: 4, reward: 153.0
Background Trial: 5, reward: 149.0
Background Trial: 6, reward: 139.0
Background Trial: 7, reward: 164.0
Background Trial: 8, reward: 144.0
Background Trial: 9, reward: 146.0
Iteration: 6, average_reward: 149.44444444444446, feedback_rate: 0.7446808510638298


episode_reward: 178.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 7, average_reward: 200.0, feedback_rate: 0.5307262569832403


episode_reward: 197.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 8, average_reward: 200.0, feedback_rate: 0.0


episode_reward:  43.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 9, average_reward: 200.0, feedback_rate: 0.0

