FDM train: iteration: 500, fdm_loss: 0.020813
FDM train: iteration: 1000, fdm_loss: 0.023994
FDM train: iteration: 1500, fdm_loss: 0.021305
FDM train: iteration: 2000, fdm_loss: 0.013895
FDM train: iteration: 2500, fdm_loss: 0.008153
FDM train: iteration: 3000, fdm_loss: 0.003232
FDM train: iteration: 3500, fdm_loss: 0.004017
FDM train: iteration: 4000, fdm_loss: 0.001774
FDM train: iteration: 4500, fdm_loss: 0.001692
FDM train: iteration: 5000, fdm_loss: 0.001129
FDM train: iteration: 5500, fdm_loss: 0.001037
FDM train: iteration: 6000, fdm_loss: 0.000980
FDM train: iteration: 6500, fdm_loss: 0.000809
FDM train: iteration: 7000, fdm_loss: 0.000454
FDM train: iteration: 7500, fdm_loss: 0.000303
FDM train: iteration: 8000, fdm_loss: 0.000293
FDM train: iteration: 8500, fdm_loss: 0.000280
FDM train: iteration: 9000, fdm_loss: 0.000215
FDM train: iteration: 9500, fdm_loss: 0.000177
FDM train: iteration: 10000, fdm_loss: 0.000204
FDM train: iteration: 10500, fdm_loss: 0.000162
FDM train: iteration: 11000, fdm_loss: 0.000204
FDM train: iteration: 11500, fdm_loss: 0.000162
FDM train: iteration: 12000, fdm_loss: 0.000118
FDM train: iteration: 12500, fdm_loss: 0.000178
FDM train: iteration: 13000, fdm_loss: 0.000122
FDM train: iteration: 13500, fdm_loss: 0.000161
FDM train: iteration: 14000, fdm_loss: 0.000140
FDM train: iteration: 14500, fdm_loss: 0.000102
FDM train: iteration: 15000, fdm_loss: 0.000126
FDM train: iteration: 15500, fdm_loss: 0.000141
FDM train: iteration: 16000, fdm_loss: 0.000126
FDM train: iteration: 16500, fdm_loss: 0.000136
FDM train: iteration: 17000, fdm_loss: 0.000101
FDM train: iteration: 17500, fdm_loss: 0.000123
FDM train: iteration: 18000, fdm_loss: 0.000094
FDM train: iteration: 18500, fdm_loss: 0.000103
FDM train: iteration: 19000, fdm_loss: 0.000179
FDM train: iteration: 19500, fdm_loss: 0.000110
FDM train: iteration: 20000, fdm_loss: 0.000094
FDM train: iteration: 20500, fdm_loss: 0.000113
FDM train: iteration: 21000, fdm_loss: 0.000069
FDM train: iteration: 21500, fdm_loss: 0.000083
FDM train: iteration: 22000, fdm_loss: 0.000120
FDM train: iteration: 22500, fdm_loss: 0.000060
FDM train: iteration: 23000, fdm_loss: 0.000050
FDM train: iteration: 23500, fdm_loss: 0.000090
FDM train: iteration: 24000, fdm_loss: 0.000072
FDM train: iteration: 24500, fdm_loss: 0.000096
FDM train: iteration: 25000, fdm_loss: 0.000046
FDM train: iteration: 25500, fdm_loss: 0.000048
FDM train: iteration: 26000, fdm_loss: 0.000078
FDM train: iteration: 26500, fdm_loss: 0.000049
FDM train: iteration: 27000, fdm_loss: 0.000045
FDM train: iteration: 27500, fdm_loss: 0.000057
FDM train: iteration: 28000, fdm_loss: 0.000063
FDM train: iteration: 28500, fdm_loss: 0.000057
FDM train: iteration: 29000, fdm_loss: 0.000045
FDM train: iteration: 29500, fdm_loss: 0.000042
FDM train: iteration: 30000, fdm_loss: 0.000028
FDM train: iteration: 30500, fdm_loss: 0.000059
FDM train: iteration: 31000, fdm_loss: 0.000034
FDM train: iteration: 31500, fdm_loss: 0.000023
FDM train: iteration: 32000, fdm_loss: 0.000020

episode_reward:  16.0
Background Trial: 1, reward: 16.0
Background Trial: 2, reward: 14.0
Background Trial: 3, reward: 15.0
Background Trial: 4, reward: 14.0
Background Trial: 5, reward: 14.0
Background Trial: 6, reward: 15.0
Background Trial: 7, reward: 15.0
Background Trial: 8, reward: 14.0
Background Trial: 9, reward: 15.0
Iteration: 1, average_reward: 14.666666666666666, feedback_rate: 0.058823529411764705


episode_reward:  22.0
Background Trial: 1, reward: 14.0
Background Trial: 2, reward: 14.0
Background Trial: 3, reward: 14.0
Background Trial: 4, reward: 14.0
Background Trial: 5, reward: 15.0
Background Trial: 6, reward: 15.0
Background Trial: 7, reward: 15.0
Background Trial: 8, reward: 14.0
Background Trial: 9, reward: 15.0
Iteration: 2, average_reward: 14.444444444444445, feedback_rate: 0.5652173913043478


episode_reward:  57.0
Background Trial: 1, reward: 57.0
Background Trial: 2, reward: 53.0
Background Trial: 3, reward: 55.0
Background Trial: 4, reward: 56.0
Background Trial: 5, reward: 55.0
Background Trial: 6, reward: 58.0
Background Trial: 7, reward: 58.0
Background Trial: 8, reward: 55.0
Background Trial: 9, reward: 55.0
Iteration: 3, average_reward: 55.77777777777778, feedback_rate: 0.6896551724137931


episode_reward: 102.0
Background Trial: 1, reward: 162.0
Background Trial: 2, reward: 141.0
Background Trial: 3, reward: 148.0
Background Trial: 4, reward: 146.0
Background Trial: 5, reward: 146.0
Background Trial: 6, reward: 163.0
Background Trial: 7, reward: 149.0
Background Trial: 8, reward: 153.0
Background Trial: 9, reward: 154.0
Iteration: 4, average_reward: 151.33333333333334, feedback_rate: 0.2524271844660194


episode_reward: 200.0
Background Trial: 1, reward: 183.0
Background Trial: 2, reward: 196.0
Background Trial: 3, reward: 187.0
Background Trial: 4, reward: 179.0
Background Trial: 5, reward: 193.0
Background Trial: 6, reward: 175.0
Background Trial: 7, reward: 195.0
Background Trial: 8, reward: 183.0
Background Trial: 9, reward: 192.0
Iteration: 5, average_reward: 187.0, feedback_rate: 0.07960199004975124


episode_reward: 200.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 6, average_reward: 200.0, feedback_rate: 0.08955223880597014


episode_reward: 200.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 7, average_reward: 200.0, feedback_rate: 0.05970149253731343


episode_reward: 173.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 8, average_reward: 200.0, feedback_rate: 0.0

