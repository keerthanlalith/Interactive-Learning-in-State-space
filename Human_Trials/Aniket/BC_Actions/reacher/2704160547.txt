Policy train: iteration: 500, policy_loss: 0.001488
Policy train: iteration: 1000, policy_loss: 0.001897
Policy train: iteration: 1500, policy_loss: 0.001676
Policy train: iteration: 2000, policy_loss: 0.001524
Policy train: iteration: 2500, policy_loss: 0.001548
Policy train: iteration: 3000, policy_loss: 0.002014
Policy train: iteration: 3500, policy_loss: 0.000883
Policy train: iteration: 4000, policy_loss: 0.001941
Policy train: iteration: 4500, policy_loss: 0.001540
Policy train: iteration: 5000, policy_loss: 0.001014
Policy train: iteration: 5500, policy_loss: 0.000956
Policy train: iteration: 6000, policy_loss: 0.000781

Background Trial: 1, reward: -182.17485567310487
Background Trial: 2, reward: -161.4901375253299
Background Trial: 3, reward: -108.19542554863811
Background Trial: 4, reward: -55.92985104054534
Background Trial: 5, reward: -62.6699109974136
Background Trial: 6, reward: -76.76486496490813
Background Trial: 7, reward: -180.14576354351755
Background Trial: 8, reward: -173.3604788436988
Background Trial: 9, reward: -106.25369422738457
Iteration: 1, average_reward: -122.99833137383787

Policy train: iteration: 500, policy_loss: 0.000723
Policy train: iteration: 1000, policy_loss: 0.001001
Policy train: iteration: 1500, policy_loss: 0.001012
Policy train: iteration: 2000, policy_loss: 0.000688
Policy train: iteration: 2500, policy_loss: 0.001176
Policy train: iteration: 3000, policy_loss: 0.000951
Policy train: iteration: 3500, policy_loss: 0.001147
Policy train: iteration: 4000, policy_loss: 0.001026
Policy train: iteration: 4500, policy_loss: 0.000935
Policy train: iteration: 5000, policy_loss: 0.001032
Policy train: iteration: 5500, policy_loss: 0.000847
Policy train: iteration: 6000, policy_loss: 0.001026

Background Trial: 1, reward: -327.70690271318267
Background Trial: 2, reward: -419.484455629624
Background Trial: 3, reward: -483.3779047418195
Background Trial: 4, reward: -486.28373832146684
Background Trial: 5, reward: -482.11724814723544
Background Trial: 6, reward: -446.1072302083192
Background Trial: 7, reward: -732.7632510861158
Background Trial: 8, reward: -698.7394439039884
Background Trial: 9, reward: -395.6838152078621
Iteration: 2, average_reward: -496.91822110662383

Policy train: iteration: 500, policy_loss: 0.000939
Policy train: iteration: 1000, policy_loss: 0.001103
Policy train: iteration: 1500, policy_loss: 0.000968
Policy train: iteration: 2000, policy_loss: 0.001307
Policy train: iteration: 2500, policy_loss: 0.001302
Policy train: iteration: 3000, policy_loss: 0.001448
Policy train: iteration: 3500, policy_loss: 0.000687
Policy train: iteration: 4000, policy_loss: 0.001216
Policy train: iteration: 4500, policy_loss: 0.000623
Policy train: iteration: 5000, policy_loss: 0.001057
Policy train: iteration: 5500, policy_loss: 0.001039
Policy train: iteration: 6000, policy_loss: 0.001252

Background Trial: 1, reward: -722.6834016693027
Background Trial: 2, reward: -330.1999754418295
Background Trial: 3, reward: -252.30354417098258
Background Trial: 4, reward: -331.23572524927886
Background Trial: 5, reward: -601.4964629668754
Background Trial: 6, reward: -298.8903886920202
Background Trial: 7, reward: -433.62788729905185
Background Trial: 8, reward: -703.5798009651897
Background Trial: 9, reward: -330.16939234992265
Iteration: 3, average_reward: -444.9096198671615

Policy train: iteration: 500, policy_loss: 0.000993
Policy train: iteration: 1000, policy_loss: 0.001030
Policy train: iteration: 1500, policy_loss: 0.001154
Policy train: iteration: 2000, policy_loss: 0.000661
Policy train: iteration: 2500, policy_loss: 0.000921
Policy train: iteration: 3000, policy_loss: 0.000667
Policy train: iteration: 3500, policy_loss: 0.001243
Policy train: iteration: 4000, policy_loss: 0.001321
Policy train: iteration: 4500, policy_loss: 0.000848
Policy train: iteration: 5000, policy_loss: 0.001450
Policy train: iteration: 5500, policy_loss: 0.000948
Policy train: iteration: 6000, policy_loss: 0.000938

Background Trial: 1, reward: -484.22112672937607
Background Trial: 2, reward: -477.408236694475
Background Trial: 3, reward: -206.71565990205718
Background Trial: 4, reward: -210.55309408834336
Background Trial: 5, reward: -513.3471177859587
Background Trial: 6, reward: -206.93954943791857
Background Trial: 7, reward: -486.63278756092967
Background Trial: 8, reward: -211.91629721459833
Background Trial: 9, reward: -500.72892251205025
Iteration: 4, average_reward: -366.49586576952305

Policy train: iteration: 500, policy_loss: 0.001466
Policy train: iteration: 1000, policy_loss: 0.001308
Policy train: iteration: 1500, policy_loss: 0.000801
Policy train: iteration: 2000, policy_loss: 0.001428
Policy train: iteration: 2500, policy_loss: 0.000942
Policy train: iteration: 3000, policy_loss: 0.001013
Policy train: iteration: 3500, policy_loss: 0.001113
Policy train: iteration: 4000, policy_loss: 0.000786
Policy train: iteration: 4500, policy_loss: 0.001153
Policy train: iteration: 5000, policy_loss: 0.000652
Policy train: iteration: 5500, policy_loss: 0.000733
Policy train: iteration: 6000, policy_loss: 0.000630

Background Trial: 1, reward: -614.2319108809256
Background Trial: 2, reward: -409.5632584432489
Background Trial: 3, reward: -337.25688953305115
Background Trial: 4, reward: -876.291182673005
Background Trial: 5, reward: -941.7727246144534
Background Trial: 6, reward: -429.4693578267917
Background Trial: 7, reward: -398.56921037111454
Background Trial: 8, reward: -926.8295685535692
Background Trial: 9, reward: -948.6758205739048
Iteration: 5, average_reward: -653.6288803855628

Policy train: iteration: 500, policy_loss: 0.000585
Policy train: iteration: 1000, policy_loss: 0.000934
Policy train: iteration: 1500, policy_loss: 0.000798
Policy train: iteration: 2000, policy_loss: 0.000873
Policy train: iteration: 2500, policy_loss: 0.000901
Policy train: iteration: 3000, policy_loss: 0.000970
Policy train: iteration: 3500, policy_loss: 0.000608
Policy train: iteration: 4000, policy_loss: 0.000923
Policy train: iteration: 4500, policy_loss: 0.000897
Policy train: iteration: 5000, policy_loss: 0.000836
Policy train: iteration: 5500, policy_loss: 0.000983
Policy train: iteration: 6000, policy_loss: 0.001095

Background Trial: 1, reward: -962.5989747265287
Background Trial: 2, reward: -947.5659734465816
Background Trial: 3, reward: -950.3295244838171
Background Trial: 4, reward: -941.6242232532288
Background Trial: 5, reward: -951.3025837546346
Background Trial: 6, reward: -331.9164023051579
Background Trial: 7, reward: -940.6356706391041
Background Trial: 8, reward: -363.9583852942846
Background Trial: 9, reward: -947.1705218073309
Iteration: 6, average_reward: -815.2335844122965

Policy train: iteration: 500, policy_loss: 0.000971
Policy train: iteration: 1000, policy_loss: 0.000749
Policy train: iteration: 1500, policy_loss: 0.000954
Policy train: iteration: 2000, policy_loss: 0.000594
Policy train: iteration: 2500, policy_loss: 0.000948
Policy train: iteration: 3000, policy_loss: 0.001253
Policy train: iteration: 3500, policy_loss: 0.001035
Policy train: iteration: 4000, policy_loss: 0.000929
Policy train: iteration: 4500, policy_loss: 0.000631
Policy train: iteration: 5000, policy_loss: 0.000810
Policy train: iteration: 5500, policy_loss: 0.000893
Policy train: iteration: 6000, policy_loss: 0.000518

Background Trial: 1, reward: -286.14713021333364
Background Trial: 2, reward: -328.51836157736966
Background Trial: 3, reward: -332.0018359477099
Background Trial: 4, reward: -405.5914085614693
Background Trial: 5, reward: -326.9301816030534
Background Trial: 6, reward: -342.90620972571406
Background Trial: 7, reward: -152.86014098685416
Background Trial: 8, reward: -56.681992559191876
Background Trial: 9, reward: -336.9934293777014
Iteration: 7, average_reward: -285.40341006137743

Policy train: iteration: 500, policy_loss: 0.000852
Policy train: iteration: 1000, policy_loss: 0.001140
Policy train: iteration: 1500, policy_loss: 0.000725
Policy train: iteration: 2000, policy_loss: 0.000620
Policy train: iteration: 2500, policy_loss: 0.000611
Policy train: iteration: 3000, policy_loss: 0.000752
Policy train: iteration: 3500, policy_loss: 0.000894
Policy train: iteration: 4000, policy_loss: 0.000798
Policy train: iteration: 4500, policy_loss: 0.000842
Policy train: iteration: 5000, policy_loss: 0.000845
Policy train: iteration: 5500, policy_loss: 0.000689
Policy train: iteration: 6000, policy_loss: 0.000881

Background Trial: 1, reward: -966.3676196880162
Background Trial: 2, reward: -316.5884813554254
Background Trial: 3, reward: -314.5332385687404
Background Trial: 4, reward: -806.3299965870731
Background Trial: 5, reward: -939.063220753956
Background Trial: 6, reward: -314.6719696585734
Background Trial: 7, reward: -315.55132961856356
Background Trial: 8, reward: -962.84584810246
Background Trial: 9, reward: -309.1573294065082
Iteration: 8, average_reward: -582.7898926377019

Policy train: iteration: 500, policy_loss: 0.000554
Policy train: iteration: 1000, policy_loss: 0.000900
Policy train: iteration: 1500, policy_loss: 0.000967
Policy train: iteration: 2000, policy_loss: 0.000849
Policy train: iteration: 2500, policy_loss: 0.000740
Policy train: iteration: 3000, policy_loss: 0.000751
Policy train: iteration: 3500, policy_loss: 0.000773
Policy train: iteration: 4000, policy_loss: 0.000975
Policy train: iteration: 4500, policy_loss: 0.000839
Policy train: iteration: 5000, policy_loss: 0.001089
Policy train: iteration: 5500, policy_loss: 0.000819
Policy train: iteration: 6000, policy_loss: 0.000851

Background Trial: 1, reward: -265.31454818126304
Background Trial: 2, reward: -474.85774491124874
Background Trial: 3, reward: -332.39895954929995
Background Trial: 4, reward: -767.7828369789048
Background Trial: 5, reward: -534.761124520245
Background Trial: 6, reward: -682.5925319727821
Background Trial: 7, reward: -836.7192061954207
Background Trial: 8, reward: -331.9527304429857
Background Trial: 9, reward: -331.9468109967054
Iteration: 9, average_reward: -506.48072152765053

Policy train: iteration: 500, policy_loss: 0.000771
Policy train: iteration: 1000, policy_loss: 0.000974
Policy train: iteration: 1500, policy_loss: 0.001032
Policy train: iteration: 2000, policy_loss: 0.000532
Policy train: iteration: 2500, policy_loss: 0.000599
Policy train: iteration: 3000, policy_loss: 0.000697
Policy train: iteration: 3500, policy_loss: 0.001049
Policy train: iteration: 4000, policy_loss: 0.000759
Policy train: iteration: 4500, policy_loss: 0.000843
Policy train: iteration: 5000, policy_loss: 0.000366
Policy train: iteration: 5500, policy_loss: 0.001179
Policy train: iteration: 6000, policy_loss: 0.000940

Background Trial: 1, reward: -278.91057351313077
Background Trial: 2, reward: -273.81160090938806
Background Trial: 3, reward: -927.0007434255359
Background Trial: 4, reward: -246.10588903969204
Background Trial: 5, reward: -246.6892548613448
Background Trial: 6, reward: -857.3413379765873
Background Trial: 7, reward: -277.75556060967523
Background Trial: 8, reward: -847.3920037946838
Background Trial: 9, reward: -933.8361820855255
Iteration: 10, average_reward: -543.2047940239514

Policy train: iteration: 500, policy_loss: 0.000492
Policy train: iteration: 1000, policy_loss: 0.000864
Policy train: iteration: 1500, policy_loss: 0.000768
Policy train: iteration: 2000, policy_loss: 0.000867
Policy train: iteration: 2500, policy_loss: 0.000717
Policy train: iteration: 3000, policy_loss: 0.000718
Policy train: iteration: 3500, policy_loss: 0.000606
Policy train: iteration: 4000, policy_loss: 0.000720
Policy train: iteration: 4500, policy_loss: 0.000542
Policy train: iteration: 5000, policy_loss: 0.000737
Policy train: iteration: 5500, policy_loss: 0.000954
Policy train: iteration: 6000, policy_loss: 0.001167

Background Trial: 1, reward: -334.2371513672216
Background Trial: 2, reward: -253.09747195505403
Background Trial: 3, reward: -64.61689702903345
Background Trial: 4, reward: -58.27001906147108
Background Trial: 5, reward: -65.52717651310985
Background Trial: 6, reward: -40.717297455870224
Background Trial: 7, reward: -334.6102320096497
Background Trial: 8, reward: -208.1782006396652
Background Trial: 9, reward: -58.95691904668545
Iteration: 11, average_reward: -157.57904056419565

Policy train: iteration: 500, policy_loss: 0.000625
Policy train: iteration: 1000, policy_loss: 0.000540
Policy train: iteration: 1500, policy_loss: 0.000950
Policy train: iteration: 2000, policy_loss: 0.000821
Policy train: iteration: 2500, policy_loss: 0.000489
Policy train: iteration: 3000, policy_loss: 0.000562
Policy train: iteration: 3500, policy_loss: 0.000743
Policy train: iteration: 4000, policy_loss: 0.000822
Policy train: iteration: 4500, policy_loss: 0.000425
Policy train: iteration: 5000, policy_loss: 0.000742
Policy train: iteration: 5500, policy_loss: 0.000769
Policy train: iteration: 6000, policy_loss: 0.000858

Background Trial: 1, reward: -337.3867711208474
Background Trial: 2, reward: -52.97748949719848
Background Trial: 3, reward: -201.46781054679528
Background Trial: 4, reward: -336.93250351735895
Background Trial: 5, reward: -227.03478581125265
Background Trial: 6, reward: -337.6957978532656
Background Trial: 7, reward: -316.12495470547856
Background Trial: 8, reward: -336.25672470632503
Background Trial: 9, reward: -308.7640894826239
Iteration: 12, average_reward: -272.7378808045718

Policy train: iteration: 500, policy_loss: 0.000748
Policy train: iteration: 1000, policy_loss: 0.000551
Policy train: iteration: 1500, policy_loss: 0.000852
Policy train: iteration: 2000, policy_loss: 0.000694
Policy train: iteration: 2500, policy_loss: 0.000812
Policy train: iteration: 3000, policy_loss: 0.000632
Policy train: iteration: 3500, policy_loss: 0.000714
Policy train: iteration: 4000, policy_loss: 0.000519
Policy train: iteration: 4500, policy_loss: 0.000521
Policy train: iteration: 5000, policy_loss: 0.000733
Policy train: iteration: 5500, policy_loss: 0.000776
Policy train: iteration: 6000, policy_loss: 0.000772

Background Trial: 1, reward: -319.48464427778714
Background Trial: 2, reward: -749.8795963582946
Background Trial: 3, reward: -809.9150260352067
Background Trial: 4, reward: -808.0601015013356
Background Trial: 5, reward: -432.02013608018
Background Trial: 6, reward: -713.3717983028633
Background Trial: 7, reward: -757.134354903213
Background Trial: 8, reward: -755.5403708198437
Background Trial: 9, reward: -321.751596061373
Iteration: 13, average_reward: -629.6841804822329

Policy train: iteration: 500, policy_loss: 0.000774
Policy train: iteration: 1000, policy_loss: 0.000576
Policy train: iteration: 1500, policy_loss: 0.000662
Policy train: iteration: 2000, policy_loss: 0.000796
Policy train: iteration: 2500, policy_loss: 0.000817
Policy train: iteration: 3000, policy_loss: 0.000545
Policy train: iteration: 3500, policy_loss: 0.000686
Policy train: iteration: 4000, policy_loss: 0.000442
Policy train: iteration: 4500, policy_loss: 0.000715
Policy train: iteration: 5000, policy_loss: 0.000865
Policy train: iteration: 5500, policy_loss: 0.000434
Policy train: iteration: 6000, policy_loss: 0.001162

Background Trial: 1, reward: -228.05022191395625
Background Trial: 2, reward: -132.18492678262902
Background Trial: 3, reward: -268.42266924593775
Background Trial: 4, reward: -159.1429042295954
Background Trial: 5, reward: -225.2115719007427
Background Trial: 6, reward: -313.18240601770765
Background Trial: 7, reward: -143.20007263632485
Background Trial: 8, reward: -89.79493779713374
Background Trial: 9, reward: -310.29411334476845
Iteration: 14, average_reward: -207.72042487431065

Policy train: iteration: 500, policy_loss: 0.000854
Policy train: iteration: 1000, policy_loss: 0.000881
Policy train: iteration: 1500, policy_loss: 0.000839
Policy train: iteration: 2000, policy_loss: 0.000770
Policy train: iteration: 2500, policy_loss: 0.001147
Policy train: iteration: 3000, policy_loss: 0.000471
Policy train: iteration: 3500, policy_loss: 0.000958
Policy train: iteration: 4000, policy_loss: 0.000413
Policy train: iteration: 4500, policy_loss: 0.000774
Policy train: iteration: 5000, policy_loss: 0.000487
Policy train: iteration: 5500, policy_loss: 0.000803
Policy train: iteration: 6000, policy_loss: 0.000721

Background Trial: 1, reward: -73.78367936554535
Background Trial: 2, reward: -640.2495576926688
Background Trial: 3, reward: -672.9761631238847
Background Trial: 4, reward: -70.4120521772714
Background Trial: 5, reward: -692.6994358014109
Background Trial: 6, reward: -607.1118370339739
Background Trial: 7, reward: -69.22700987606743
Background Trial: 8, reward: -61.922518531972656
Background Trial: 9, reward: -71.1820596398018
Iteration: 15, average_reward: -328.8404792491775

Policy train: iteration: 500, policy_loss: 0.000534
Policy train: iteration: 1000, policy_loss: 0.000778
Policy train: iteration: 1500, policy_loss: 0.000860
Policy train: iteration: 2000, policy_loss: 0.000493
Policy train: iteration: 2500, policy_loss: 0.000487
Policy train: iteration: 3000, policy_loss: 0.000592
Policy train: iteration: 3500, policy_loss: 0.000626
Policy train: iteration: 4000, policy_loss: 0.000549
Policy train: iteration: 4500, policy_loss: 0.000756
Policy train: iteration: 5000, policy_loss: 0.000847
Policy train: iteration: 5500, policy_loss: 0.000604
Policy train: iteration: 6000, policy_loss: 0.000700

Background Trial: 1, reward: -70.53950215172627
Background Trial: 2, reward: -64.65559397799042
Background Trial: 3, reward: -715.2204614297702
Background Trial: 4, reward: -44.9892478662325
Background Trial: 5, reward: -66.79795786037431
Background Trial: 6, reward: -46.94140091146674
Background Trial: 7, reward: -725.8988397458942
Background Trial: 8, reward: -73.32944454994387
Background Trial: 9, reward: -68.10991398493407
Iteration: 16, average_reward: -208.4980402753703

Policy train: iteration: 500, policy_loss: 0.000875
Policy train: iteration: 1000, policy_loss: 0.000636
Policy train: iteration: 1500, policy_loss: 0.000468
Policy train: iteration: 2000, policy_loss: 0.000703
Policy train: iteration: 2500, policy_loss: 0.000628
Policy train: iteration: 3000, policy_loss: 0.000813
Policy train: iteration: 3500, policy_loss: 0.000562
Policy train: iteration: 4000, policy_loss: 0.000691
Policy train: iteration: 4500, policy_loss: 0.000638
Policy train: iteration: 5000, policy_loss: 0.000688
Policy train: iteration: 5500, policy_loss: 0.000560
Policy train: iteration: 6000, policy_loss: 0.000641

Background Trial: 1, reward: -270.3850821371027
Background Trial: 2, reward: -194.34533842114783
Background Trial: 3, reward: -80.97487541392472
Background Trial: 4, reward: -278.69427734988125
Background Trial: 5, reward: -168.37016269506444
Background Trial: 6, reward: -270.29013141586034
Background Trial: 7, reward: -273.48002967393313
Background Trial: 8, reward: -46.76985780838405
Background Trial: 9, reward: -274.92029914980475
Iteration: 17, average_reward: -206.4700060072337

Policy train: iteration: 500, policy_loss: 0.000779
Policy train: iteration: 1000, policy_loss: 0.000557
Policy train: iteration: 1500, policy_loss: 0.000590
Policy train: iteration: 2000, policy_loss: 0.000540
Policy train: iteration: 2500, policy_loss: 0.000893
Policy train: iteration: 3000, policy_loss: 0.000852
Policy train: iteration: 3500, policy_loss: 0.000649
Policy train: iteration: 4000, policy_loss: 0.000463
Policy train: iteration: 4500, policy_loss: 0.000595
Policy train: iteration: 5000, policy_loss: 0.000849
Policy train: iteration: 5500, policy_loss: 0.000726
Policy train: iteration: 6000, policy_loss: 0.000852

Background Trial: 1, reward: -60.19391138844986
Background Trial: 2, reward: -645.424772091653
Background Trial: 3, reward: -272.5503470981432
Background Trial: 4, reward: -855.9641851631005
Background Trial: 5, reward: -267.3165278980524
Background Trial: 6, reward: -215.78182748836917
Background Trial: 7, reward: -258.78112946781465
Background Trial: 8, reward: -274.9256192400433
Background Trial: 9, reward: -268.39102893826947
Iteration: 18, average_reward: -346.59214986376617

Policy train: iteration: 500, policy_loss: 0.000736
Policy train: iteration: 1000, policy_loss: 0.000615
Policy train: iteration: 1500, policy_loss: 0.000502
Policy train: iteration: 2000, policy_loss: 0.000485
Policy train: iteration: 2500, policy_loss: 0.001017
Policy train: iteration: 3000, policy_loss: 0.000476
Policy train: iteration: 3500, policy_loss: 0.000402
Policy train: iteration: 4000, policy_loss: 0.000686
Policy train: iteration: 4500, policy_loss: 0.000868
Policy train: iteration: 5000, policy_loss: 0.000840
Policy train: iteration: 5500, policy_loss: 0.000403
Policy train: iteration: 6000, policy_loss: 0.000721

Background Trial: 1, reward: -249.7827074074959
Background Trial: 2, reward: -161.13994279983152
Background Trial: 3, reward: -182.05229955072542
Background Trial: 4, reward: -181.7958821648527
Background Trial: 5, reward: -170.6804075279289
Background Trial: 6, reward: -249.41671247818056
Background Trial: 7, reward: -106.56520724919152
Background Trial: 8, reward: -52.442873338885946
Background Trial: 9, reward: -105.41114256855717
Iteration: 19, average_reward: -162.14301945396105

Policy train: iteration: 500, policy_loss: 0.000505
Policy train: iteration: 1000, policy_loss: 0.000517
Policy train: iteration: 1500, policy_loss: 0.000701
Policy train: iteration: 2000, policy_loss: 0.000597
Policy train: iteration: 2500, policy_loss: 0.000860
Policy train: iteration: 3000, policy_loss: 0.000509
Policy train: iteration: 3500, policy_loss: 0.000585
Policy train: iteration: 4000, policy_loss: 0.000545
Policy train: iteration: 4500, policy_loss: 0.000516
Policy train: iteration: 5000, policy_loss: 0.000703
Policy train: iteration: 5500, policy_loss: 0.000615
Policy train: iteration: 6000, policy_loss: 0.000497

Background Trial: 1, reward: -270.66795513806386
Background Trial: 2, reward: -255.9457528086357
Background Trial: 3, reward: -265.7016358160914
Background Trial: 4, reward: -254.62024014201347
Background Trial: 5, reward: -810.9114522939714
Background Trial: 6, reward: -818.1166210853983
Background Trial: 7, reward: -284.1447307070013
Background Trial: 8, reward: -41.30025294041865
Background Trial: 9, reward: -40.7362239800586
Iteration: 20, average_reward: -338.01609610129464

