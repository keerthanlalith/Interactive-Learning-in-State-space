FDM train: iteration: 500, fdm_loss: 0.028438
FDM train: iteration: 1000, fdm_loss: 0.038749
FDM train: iteration: 1500, fdm_loss: 0.035361
FDM train: iteration: 2000, fdm_loss: 0.017723
FDM train: iteration: 2500, fdm_loss: 0.003992
FDM train: iteration: 3000, fdm_loss: 0.003333
FDM train: iteration: 3500, fdm_loss: 0.001151
FDM train: iteration: 4000, fdm_loss: 0.001113
FDM train: iteration: 4500, fdm_loss: 0.000673
FDM train: iteration: 5000, fdm_loss: 0.000819
FDM train: iteration: 5500, fdm_loss: 0.000565
FDM train: iteration: 6000, fdm_loss: 0.000916
FDM train: iteration: 6500, fdm_loss: 0.000660
FDM train: iteration: 7000, fdm_loss: 0.000568
FDM train: iteration: 7500, fdm_loss: 0.000409
FDM train: iteration: 8000, fdm_loss: 0.000489
FDM train: iteration: 8500, fdm_loss: 0.000507
FDM train: iteration: 9000, fdm_loss: 0.000268
FDM train: iteration: 9500, fdm_loss: 0.000301
FDM train: iteration: 10000, fdm_loss: 0.000308
FDM train: iteration: 10500, fdm_loss: 0.000207
FDM train: iteration: 11000, fdm_loss: 0.000265
FDM train: iteration: 11500, fdm_loss: 0.000203
FDM train: iteration: 12000, fdm_loss: 0.000179
FDM train: iteration: 12500, fdm_loss: 0.000260
FDM train: iteration: 13000, fdm_loss: 0.000233
FDM train: iteration: 13500, fdm_loss: 0.000187
FDM train: iteration: 14000, fdm_loss: 0.000139
FDM train: iteration: 14500, fdm_loss: 0.000167
FDM train: iteration: 15000, fdm_loss: 0.000190
FDM train: iteration: 15500, fdm_loss: 0.000146
FDM train: iteration: 16000, fdm_loss: 0.000203
FDM train: iteration: 16500, fdm_loss: 0.000116
FDM train: iteration: 17000, fdm_loss: 0.000137
FDM train: iteration: 17500, fdm_loss: 0.000178
FDM train: iteration: 18000, fdm_loss: 0.000136
FDM train: iteration: 18500, fdm_loss: 0.000168
FDM train: iteration: 19000, fdm_loss: 0.000128
FDM train: iteration: 19500, fdm_loss: 0.000203
FDM train: iteration: 20000, fdm_loss: 0.000209
FDM train: iteration: 20500, fdm_loss: 0.000182
FDM train: iteration: 21000, fdm_loss: 0.000171
FDM train: iteration: 21500, fdm_loss: 0.000177
FDM train: iteration: 22000, fdm_loss: 0.000117
FDM train: iteration: 22500, fdm_loss: 0.000114
FDM train: iteration: 23000, fdm_loss: 0.000167
FDM train: iteration: 23500, fdm_loss: 0.000127
FDM train: iteration: 24000, fdm_loss: 0.000116
FDM train: iteration: 24500, fdm_loss: 0.000141
FDM train: iteration: 25000, fdm_loss: 0.000165
FDM train: iteration: 25500, fdm_loss: 0.000100
FDM train: iteration: 26000, fdm_loss: 0.000131
FDM train: iteration: 26500, fdm_loss: 0.000144
FDM train: iteration: 27000, fdm_loss: 0.000177
FDM train: iteration: 27500, fdm_loss: 0.000086
FDM train: iteration: 28000, fdm_loss: 0.000114
FDM train: iteration: 28500, fdm_loss: 0.000111
FDM train: iteration: 29000, fdm_loss: 0.000091
FDM train: iteration: 29500, fdm_loss: 0.000121
FDM train: iteration: 30000, fdm_loss: 0.000133
FDM train: iteration: 30500, fdm_loss: 0.000109
FDM train: iteration: 31000, fdm_loss: 0.000103
FDM train: iteration: 31500, fdm_loss: 0.000094
FDM train: iteration: 32000, fdm_loss: 0.000097

episode_reward:  18.0
Background Trial: 1, reward: 15.0
Background Trial: 2, reward: 15.0
Background Trial: 3, reward: 15.0
Background Trial: 4, reward: 16.0
Background Trial: 5, reward: 15.0
Background Trial: 6, reward: 14.0
Background Trial: 7, reward: 15.0
Background Trial: 8, reward: 15.0
Background Trial: 9, reward: 14.0
Iteration: 1, average_reward: 14.88888888888889, feedback_rate: 0.47368421052631576


episode_reward:  23.0
Background Trial: 1, reward: 63.0
Background Trial: 2, reward: 63.0
Background Trial: 3, reward: 62.0
Background Trial: 4, reward: 63.0
Background Trial: 5, reward: 57.0
Background Trial: 6, reward: 53.0
Background Trial: 7, reward: 65.0
Background Trial: 8, reward: 79.0
Background Trial: 9, reward: 61.0
Iteration: 2, average_reward: 62.888888888888886, feedback_rate: 0.5833333333333334


episode_reward: 200.0
Background Trial: 1, reward: 81.0
Background Trial: 2, reward: 171.0
Background Trial: 3, reward: 91.0
Background Trial: 4, reward: 77.0
Background Trial: 5, reward: 108.0
Background Trial: 6, reward: 81.0
Background Trial: 7, reward: 74.0
Background Trial: 8, reward: 78.0
Background Trial: 9, reward: 96.0
Iteration: 3, average_reward: 95.22222222222223, feedback_rate: 0.30845771144278605


episode_reward: 193.0
Background Trial: 1, reward: 103.0
Background Trial: 2, reward: 107.0
Background Trial: 3, reward: 107.0
Background Trial: 4, reward: 93.0
Background Trial: 5, reward: 97.0
Background Trial: 6, reward: 102.0
Background Trial: 7, reward: 102.0
Background Trial: 8, reward: 104.0
Background Trial: 9, reward: 97.0
Iteration: 4, average_reward: 101.33333333333333, feedback_rate: 0.15979381443298968


episode_reward: 195.0
Background Trial: 1, reward: 51.0
Background Trial: 2, reward: 39.0
Background Trial: 3, reward: 21.0
Background Trial: 4, reward: 19.0
Background Trial: 5, reward: 24.0
Background Trial: 6, reward: 27.0
Background Trial: 7, reward: 52.0
Background Trial: 8, reward: 53.0
Background Trial: 9, reward: 21.0
Iteration: 5, average_reward: 34.111111111111114, feedback_rate: 0.21428571428571427


episode_reward:  30.0
Background Trial: 1, reward: 176.0
Background Trial: 2, reward: 164.0
Background Trial: 3, reward: 165.0
Background Trial: 4, reward: 164.0
Background Trial: 5, reward: 169.0
Background Trial: 6, reward: 94.0
Background Trial: 7, reward: 82.0
Background Trial: 8, reward: 163.0
Background Trial: 9, reward: 172.0
Iteration: 6, average_reward: 149.88888888888889, feedback_rate: 0.2903225806451613


episode_reward: 199.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 7, average_reward: 200.0, feedback_rate: 0.45


episode_reward: 200.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 8, average_reward: 200.0, feedback_rate: 0.0

