Policy train: iteration: 500, policy_loss: 0.343466
Policy train: iteration: 1000, policy_loss: 0.298421
Policy train: iteration: 1500, policy_loss: 0.233858
Policy train: iteration: 2000, policy_loss: 0.313186
Policy train: iteration: 2500, policy_loss: 0.238062
Policy train: iteration: 3000, policy_loss: 0.323663
Policy train: iteration: 3500, policy_loss: 0.315813
Policy train: iteration: 4000, policy_loss: 0.228254

Background Trial: 1, reward: 64.0
Background Trial: 2, reward: 89.0
Background Trial: 3, reward: 154.0
Background Trial: 4, reward: 92.0
Background Trial: 5, reward: 98.0
Background Trial: 6, reward: 92.0
Background Trial: 7, reward: 84.0
Background Trial: 8, reward: 102.0
Background Trial: 9, reward: 61.0
Iteration: 1, average_reward: 92.88888888888889

Policy train: iteration: 500, policy_loss: 0.290009
Policy train: iteration: 1000, policy_loss: 0.286006
Policy train: iteration: 1500, policy_loss: 0.248566
Policy train: iteration: 2000, policy_loss: 0.276076
Policy train: iteration: 2500, policy_loss: 0.296436
Policy train: iteration: 3000, policy_loss: 0.228811
Policy train: iteration: 3500, policy_loss: 0.201207
Policy train: iteration: 4000, policy_loss: 0.332838

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 183.0
Background Trial: 3, reward: 165.0
Background Trial: 4, reward: 134.0
Background Trial: 5, reward: 164.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 145.0
Background Trial: 9, reward: 184.0
Iteration: 2, average_reward: 175.0

Policy train: iteration: 500, policy_loss: 0.230888
Policy train: iteration: 1000, policy_loss: 0.277897
Policy train: iteration: 1500, policy_loss: 0.247845
Policy train: iteration: 2000, policy_loss: 0.250372
Policy train: iteration: 2500, policy_loss: 0.169748
Policy train: iteration: 3000, policy_loss: 0.231136
Policy train: iteration: 3500, policy_loss: 0.332682
Policy train: iteration: 4000, policy_loss: 0.320840

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 178.0
Background Trial: 3, reward: 186.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 170.0
Iteration: 3, average_reward: 192.66666666666666

Policy train: iteration: 500, policy_loss: 0.254457
Policy train: iteration: 1000, policy_loss: 0.252966
Policy train: iteration: 1500, policy_loss: 0.242461
Policy train: iteration: 2000, policy_loss: 0.341254
Policy train: iteration: 2500, policy_loss: 0.372401
Policy train: iteration: 3000, policy_loss: 0.283982
Policy train: iteration: 3500, policy_loss: 0.189005
Policy train: iteration: 4000, policy_loss: 0.253270

Background Trial: 1, reward: 107.0
Background Trial: 2, reward: 149.0
Background Trial: 3, reward: 173.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 139.0
Background Trial: 6, reward: 136.0
Background Trial: 7, reward: 152.0
Background Trial: 8, reward: 123.0
Background Trial: 9, reward: 136.0
Iteration: 4, average_reward: 146.11111111111111

Policy train: iteration: 500, policy_loss: 0.287892
Policy train: iteration: 1000, policy_loss: 0.286724
Policy train: iteration: 1500, policy_loss: 0.301472
Policy train: iteration: 2000, policy_loss: 0.205910
Policy train: iteration: 2500, policy_loss: 0.317521
Policy train: iteration: 3000, policy_loss: 0.276148
Policy train: iteration: 3500, policy_loss: 0.252043
Policy train: iteration: 4000, policy_loss: 0.379538

Background Trial: 1, reward: 126.0
Background Trial: 2, reward: 117.0
Background Trial: 3, reward: 103.0
Background Trial: 4, reward: 116.0
Background Trial: 5, reward: 93.0
Background Trial: 6, reward: 88.0
Background Trial: 7, reward: 108.0
Background Trial: 8, reward: 125.0
Background Trial: 9, reward: 107.0
Iteration: 5, average_reward: 109.22222222222223

Policy train: iteration: 500, policy_loss: 0.268008
Policy train: iteration: 1000, policy_loss: 0.258850
Policy train: iteration: 1500, policy_loss: 0.305873
Policy train: iteration: 2000, policy_loss: 0.210689
Policy train: iteration: 2500, policy_loss: 0.201554
Policy train: iteration: 3000, policy_loss: 0.267224
Policy train: iteration: 3500, policy_loss: 0.206701
Policy train: iteration: 4000, policy_loss: 0.143017

Background Trial: 1, reward: 17.0
Background Trial: 2, reward: 16.0
Background Trial: 3, reward: 17.0
Background Trial: 4, reward: 21.0
Background Trial: 5, reward: 23.0
Background Trial: 6, reward: 21.0
Background Trial: 7, reward: 16.0
Background Trial: 8, reward: 17.0
Background Trial: 9, reward: 17.0
Iteration: 6, average_reward: 18.333333333333332

Policy train: iteration: 500, policy_loss: 0.217571
Policy train: iteration: 1000, policy_loss: 0.264641
Policy train: iteration: 1500, policy_loss: 0.251123
Policy train: iteration: 2000, policy_loss: 0.236560
Policy train: iteration: 2500, policy_loss: 0.174918
Policy train: iteration: 3000, policy_loss: 0.243413
Policy train: iteration: 3500, policy_loss: 0.208143
Policy train: iteration: 4000, policy_loss: 0.265096

Background Trial: 1, reward: 69.0
Background Trial: 2, reward: 133.0
Background Trial: 3, reward: 57.0
Background Trial: 4, reward: 22.0
Background Trial: 5, reward: 58.0
Background Trial: 6, reward: 127.0
Background Trial: 7, reward: 56.0
Background Trial: 8, reward: 127.0
Background Trial: 9, reward: 56.0
Iteration: 7, average_reward: 78.33333333333333

Policy train: iteration: 500, policy_loss: 0.207077
Policy train: iteration: 1000, policy_loss: 0.227098
Policy train: iteration: 1500, policy_loss: 0.327386
Policy train: iteration: 2000, policy_loss: 0.190530
Policy train: iteration: 2500, policy_loss: 0.210234
Policy train: iteration: 3000, policy_loss: 0.174160
Policy train: iteration: 3500, policy_loss: 0.208095
Policy train: iteration: 4000, policy_loss: 0.343273

Background Trial: 1, reward: 18.0
Background Trial: 2, reward: 20.0
Background Trial: 3, reward: 129.0
Background Trial: 4, reward: 135.0
Background Trial: 5, reward: 18.0
Background Trial: 6, reward: 17.0
Background Trial: 7, reward: 20.0
Background Trial: 8, reward: 15.0
Background Trial: 9, reward: 17.0
Iteration: 8, average_reward: 43.22222222222222

Policy train: iteration: 500, policy_loss: 0.181799
Policy train: iteration: 1000, policy_loss: 0.167763
Policy train: iteration: 1500, policy_loss: 0.129373
Policy train: iteration: 2000, policy_loss: 0.224734
Policy train: iteration: 2500, policy_loss: 0.171817
Policy train: iteration: 3000, policy_loss: 0.172981
Policy train: iteration: 3500, policy_loss: 0.214837
Policy train: iteration: 4000, policy_loss: 0.092945

Background Trial: 1, reward: 154.0
Background Trial: 2, reward: 150.0
Background Trial: 3, reward: 151.0
Background Trial: 4, reward: 158.0
Background Trial: 5, reward: 154.0
Background Trial: 6, reward: 18.0
Background Trial: 7, reward: 19.0
Background Trial: 8, reward: 17.0
Background Trial: 9, reward: 147.0
Iteration: 9, average_reward: 107.55555555555556

Policy train: iteration: 500, policy_loss: 0.200298
Policy train: iteration: 1000, policy_loss: 0.249355
Policy train: iteration: 1500, policy_loss: 0.137918
Policy train: iteration: 2000, policy_loss: 0.123256
Policy train: iteration: 2500, policy_loss: 0.215963
Policy train: iteration: 3000, policy_loss: 0.147625
Policy train: iteration: 3500, policy_loss: 0.256905
Policy train: iteration: 4000, policy_loss: 0.167032

Background Trial: 1, reward: 152.0
Background Trial: 2, reward: 19.0
Background Trial: 3, reward: 133.0
Background Trial: 4, reward: 133.0
Background Trial: 5, reward: 49.0
Background Trial: 6, reward: 18.0
Background Trial: 7, reward: 134.0
Background Trial: 8, reward: 158.0
Background Trial: 9, reward: 20.0
Iteration: 10, average_reward: 90.66666666666667

Policy train: iteration: 500, policy_loss: 0.160629
Policy train: iteration: 1000, policy_loss: 0.197225
Policy train: iteration: 1500, policy_loss: 0.233237
Policy train: iteration: 2000, policy_loss: 0.163510
Policy train: iteration: 2500, policy_loss: 0.267981
Policy train: iteration: 3000, policy_loss: 0.161832
Policy train: iteration: 3500, policy_loss: 0.262169
Policy train: iteration: 4000, policy_loss: 0.174554

Background Trial: 1, reward: 15.0
Background Trial: 2, reward: 134.0
Background Trial: 3, reward: 15.0
Background Trial: 4, reward: 17.0
Background Trial: 5, reward: 141.0
Background Trial: 6, reward: 15.0
Background Trial: 7, reward: 53.0
Background Trial: 8, reward: 130.0
Background Trial: 9, reward: 16.0
Iteration: 11, average_reward: 59.55555555555556

Policy train: iteration: 500, policy_loss: 0.172681
Policy train: iteration: 1000, policy_loss: 0.210463
Policy train: iteration: 1500, policy_loss: 0.223551
