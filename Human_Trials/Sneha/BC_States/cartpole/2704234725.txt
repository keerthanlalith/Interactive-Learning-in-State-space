Policy train: iteration: 500, policy_loss: 0.406875
Policy train: iteration: 1000, policy_loss: 0.346141
Policy train: iteration: 1500, policy_loss: 0.367387
Policy train: iteration: 2000, policy_loss: 0.299374
Policy train: iteration: 2500, policy_loss: 0.266309
Policy train: iteration: 3000, policy_loss: 0.250250
Policy train: iteration: 3500, policy_loss: 0.267842
Policy train: iteration: 4000, policy_loss: 0.239738

Background Trial: 1, reward: 181.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 1, average_reward: 197.88888888888889

Policy train: iteration: 500, policy_loss: 0.242020
Policy train: iteration: 1000, policy_loss: 0.411772
Policy train: iteration: 1500, policy_loss: 0.328445
Policy train: iteration: 2000, policy_loss: 0.272436
Policy train: iteration: 2500, policy_loss: 0.301845
Policy train: iteration: 3000, policy_loss: 0.277912
Policy train: iteration: 3500, policy_loss: 0.316190
Policy train: iteration: 4000, policy_loss: 0.274507

Background Trial: 1, reward: 193.0
Background Trial: 2, reward: 159.0
Background Trial: 3, reward: 194.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 189.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 174.0
Background Trial: 9, reward: 178.0
Iteration: 2, average_reward: 187.44444444444446

Policy train: iteration: 500, policy_loss: 0.256175
Policy train: iteration: 1000, policy_loss: 0.201382
Policy train: iteration: 1500, policy_loss: 0.239572
Policy train: iteration: 2000, policy_loss: 0.174297
Policy train: iteration: 2500, policy_loss: 0.253007
Policy train: iteration: 3000, policy_loss: 0.275088
Policy train: iteration: 3500, policy_loss: 0.335408
Policy train: iteration: 4000, policy_loss: 0.261047

Background Trial: 1, reward: 121.0
Background Trial: 2, reward: 150.0
Background Trial: 3, reward: 167.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 125.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 146.0
Background Trial: 9, reward: 125.0
Iteration: 3, average_reward: 159.33333333333334

Policy train: iteration: 500, policy_loss: 0.332683
Policy train: iteration: 1000, policy_loss: 0.369494
Policy train: iteration: 1500, policy_loss: 0.305950
Policy train: iteration: 2000, policy_loss: 0.295334
Policy train: iteration: 2500, policy_loss: 0.337758
Policy train: iteration: 3000, policy_loss: 0.366364
Policy train: iteration: 3500, policy_loss: 0.282090
Policy train: iteration: 4000, policy_loss: 0.309848

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 106.0
Background Trial: 8, reward: 145.0
Background Trial: 9, reward: 137.0
Iteration: 4, average_reward: 176.44444444444446

Policy train: iteration: 500, policy_loss: 0.203511
Policy train: iteration: 1000, policy_loss: 0.350462
Policy train: iteration: 1500, policy_loss: 0.326391
Policy train: iteration: 2000, policy_loss: 0.340137
Policy train: iteration: 2500, policy_loss: 0.249578
Policy train: iteration: 3000, policy_loss: 0.240836
Policy train: iteration: 3500, policy_loss: 0.274258
Policy train: iteration: 4000, policy_loss: 0.270287

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 131.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 168.0
Background Trial: 8, reward: 111.0
Background Trial: 9, reward: 200.0
Iteration: 5, average_reward: 178.88888888888889

Policy train: iteration: 500, policy_loss: 0.199547
Policy train: iteration: 1000, policy_loss: 0.340485
Policy train: iteration: 1500, policy_loss: 0.411547
Policy train: iteration: 2000, policy_loss: 0.240231
Policy train: iteration: 2500, policy_loss: 0.326024
Policy train: iteration: 3000, policy_loss: 0.430821
Policy train: iteration: 3500, policy_loss: 0.318122
Policy train: iteration: 4000, policy_loss: 0.303817

Background Trial: 1, reward: 143.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 138.0
Background Trial: 5, reward: 189.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 146.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 6, average_reward: 179.55555555555554

Policy train: iteration: 500, policy_loss: 0.261335
Policy train: iteration: 1000, policy_loss: 0.258934
Policy train: iteration: 1500, policy_loss: 0.216026
Policy train: iteration: 2000, policy_loss: 0.286032
Policy train: iteration: 2500, policy_loss: 0.263585
Policy train: iteration: 3000, policy_loss: 0.216774
Policy train: iteration: 3500, policy_loss: 0.236569
Policy train: iteration: 4000, policy_loss: 0.416776

Background Trial: 1, reward: 156.0
Background Trial: 2, reward: 133.0
Background Trial: 3, reward: 151.0
Background Trial: 4, reward: 123.0
Background Trial: 5, reward: 18.0
Background Trial: 6, reward: 144.0
Background Trial: 7, reward: 113.0
Background Trial: 8, reward: 32.0
Background Trial: 9, reward: 15.0
Iteration: 7, average_reward: 98.33333333333333

Policy train: iteration: 500, policy_loss: 0.415010
Policy train: iteration: 1000, policy_loss: 0.225774
Policy train: iteration: 1500, policy_loss: 0.354793
Policy train: iteration: 2000, policy_loss: 0.273852
Policy train: iteration: 2500, policy_loss: 0.250860
Policy train: iteration: 3000, policy_loss: 0.301408
Policy train: iteration: 3500, policy_loss: 0.222759
Policy train: iteration: 4000, policy_loss: 0.211408

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 8, average_reward: 200.0

Policy train: iteration: 500, policy_loss: 0.380338
Policy train: iteration: 1000, policy_loss: 0.200184
Policy train: iteration: 1500, policy_loss: 0.294606
Policy train: iteration: 2000, policy_loss: 0.284335
Policy train: iteration: 2500, policy_loss: 0.282025
Policy train: iteration: 3000, policy_loss: 0.308852
Policy train: iteration: 3500, policy_loss: 0.368760
Policy train: iteration: 4000, policy_loss: 0.227283

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 138.0
Background Trial: 4, reward: 170.0
Background Trial: 5, reward: 183.0
Background Trial: 6, reward: 171.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 9, average_reward: 184.66666666666666

Policy train: iteration: 500, policy_loss: 0.240741
Policy train: iteration: 1000, policy_loss: 0.222884
Policy train: iteration: 1500, policy_loss: 0.278307
Policy train: iteration: 2000, policy_loss: 0.241090
Policy train: iteration: 2500, policy_loss: 0.262327
Policy train: iteration: 3000, policy_loss: 0.209875
Policy train: iteration: 3500, policy_loss: 0.312111
Policy train: iteration: 4000, policy_loss: 0.249286

Background Trial: 1, reward: 165.0
Background Trial: 2, reward: 162.0
Background Trial: 3, reward: 160.0
Background Trial: 4, reward: 102.0
Background Trial: 5, reward: 109.0
Background Trial: 6, reward: 106.0
Background Trial: 7, reward: 15.0
Background Trial: 8, reward: 102.0
Background Trial: 9, reward: 199.0
Iteration: 10, average_reward: 124.44444444444444

Policy train: iteration: 500, policy_loss: 0.339122
Policy train: iteration: 1000, policy_loss: 0.288172
Policy train: iteration: 1500, policy_loss: 0.291344
Policy train: iteration: 2000, policy_loss: 0.221816
Policy train: iteration: 2500, policy_loss: 0.192785
Policy train: iteration: 3000, policy_loss: 0.260090
Policy train: iteration: 3500, policy_loss: 0.215844
Policy train: iteration: 4000, policy_loss: 0.322627

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 193.0
Background Trial: 3, reward: 175.0
Background Trial: 4, reward: 131.0
Background Trial: 5, reward: 144.0
Background Trial: 6, reward: 167.0
Background Trial: 7, reward: 39.0
Background Trial: 8, reward: 181.0
Background Trial: 9, reward: 122.0
Iteration: 11, average_reward: 150.22222222222223

Policy train: iteration: 500, policy_loss: 0.252359
Policy train: iteration: 1000, policy_loss: 0.342277
Policy train: iteration: 1500, policy_loss: 0.291623
Policy train: iteration: 2000, policy_loss: 0.229194
Policy train: iteration: 2500, policy_loss: 0.219733
Policy train: iteration: 3000, policy_loss: 0.234300
Policy train: iteration: 3500, policy_loss: 0.212107
Policy train: iteration: 4000, policy_loss: 0.231224

Background Trial: 1, reward: 72.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 59.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 173.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 12, average_reward: 167.11111111111111

Policy train: iteration: 500, policy_loss: 0.283750
Policy train: iteration: 1000, policy_loss: 0.324914
Policy train: iteration: 1500, policy_loss: 0.228313
