Policy train: iteration: 500, policy_loss: 0.003082
Policy train: iteration: 1000, policy_loss: 0.003135
Policy train: iteration: 1500, policy_loss: 0.004377
Policy train: iteration: 2000, policy_loss: 0.003923
Policy train: iteration: 2500, policy_loss: 0.002484
Policy train: iteration: 3000, policy_loss: 0.006300
Policy train: iteration: 3500, policy_loss: 0.003111
Policy train: iteration: 4000, policy_loss: 0.004301
Policy train: iteration: 4500, policy_loss: 0.004686
Policy train: iteration: 5000, policy_loss: 0.003275
Policy train: iteration: 5500, policy_loss: 0.005791
Policy train: iteration: 6000, policy_loss: 0.003647

Background Trial: 1, reward: -50.337863548627745
Background Trial: 2, reward: -50.21113454027515
Background Trial: 3, reward: -52.09363482592393
Background Trial: 4, reward: -47.599589225515096
Background Trial: 5, reward: -48.45622340896629
Background Trial: 6, reward: -54.19097914535703
Background Trial: 7, reward: -53.97888913047155
Background Trial: 8, reward: -47.206315918268686
Background Trial: 9, reward: -56.180944607133426
Iteration: 1, average_reward: -51.13950826117099

Policy train: iteration: 500, policy_loss: 0.004439
Policy train: iteration: 1000, policy_loss: 0.006177
Policy train: iteration: 1500, policy_loss: 0.003339
Policy train: iteration: 2000, policy_loss: 0.002769
Policy train: iteration: 2500, policy_loss: 0.002237
Policy train: iteration: 3000, policy_loss: 0.002538
Policy train: iteration: 3500, policy_loss: 0.002923
Policy train: iteration: 4000, policy_loss: 0.003992
Policy train: iteration: 4500, policy_loss: 0.003235
Policy train: iteration: 5000, policy_loss: 0.002940
Policy train: iteration: 5500, policy_loss: 0.003829
Policy train: iteration: 6000, policy_loss: 0.001608

Background Trial: 1, reward: -135.1938743308778
Background Trial: 2, reward: -127.60445857930677
Background Trial: 3, reward: -137.21406742410136
Background Trial: 4, reward: -138.2175270322808
Background Trial: 5, reward: -138.34684764248033
Background Trial: 6, reward: -139.11597831381562
Background Trial: 7, reward: -94.61675415507509
Background Trial: 8, reward: -151.7922074244858
Background Trial: 9, reward: -93.23243678542191
Iteration: 2, average_reward: -128.3704612986495

Policy train: iteration: 500, policy_loss: 0.002514
Policy train: iteration: 1000, policy_loss: 0.002490
Policy train: iteration: 1500, policy_loss: 0.002944
Policy train: iteration: 2000, policy_loss: 0.003132
Policy train: iteration: 2500, policy_loss: 0.002922
Policy train: iteration: 3000, policy_loss: 0.002117
Policy train: iteration: 3500, policy_loss: 0.003306
Policy train: iteration: 4000, policy_loss: 0.002479
Policy train: iteration: 4500, policy_loss: 0.001464
Policy train: iteration: 5000, policy_loss: 0.004034
Policy train: iteration: 5500, policy_loss: 0.003537
Policy train: iteration: 6000, policy_loss: 0.003253

Background Trial: 1, reward: -97.32997577736793
Background Trial: 2, reward: -85.27386927142378
Background Trial: 3, reward: -101.28999778199643
Background Trial: 4, reward: -104.48128156648792
Background Trial: 5, reward: -80.9397975896594
Background Trial: 6, reward: -98.47003548885371
Background Trial: 7, reward: -98.69541438915728
Background Trial: 8, reward: -98.49118557754007
Background Trial: 9, reward: -102.31825425618463
Iteration: 3, average_reward: -96.36553463318567

Policy train: iteration: 500, policy_loss: 0.002210
Policy train: iteration: 1000, policy_loss: 0.003442
Policy train: iteration: 1500, policy_loss: 0.002701
Policy train: iteration: 2000, policy_loss: 0.002025
Policy train: iteration: 2500, policy_loss: 0.002261
Policy train: iteration: 3000, policy_loss: 0.004549
Policy train: iteration: 3500, policy_loss: 0.002781
Policy train: iteration: 4000, policy_loss: 0.003348
Policy train: iteration: 4500, policy_loss: 0.003292
Policy train: iteration: 5000, policy_loss: 0.003554
Policy train: iteration: 5500, policy_loss: 0.003697
Policy train: iteration: 6000, policy_loss: 0.002789

Background Trial: 1, reward: -96.86046352919243
Background Trial: 2, reward: -95.39189581191731
Background Trial: 3, reward: -91.33911984264279
Background Trial: 4, reward: -95.30309960978586
Background Trial: 5, reward: -93.60852603304343
Background Trial: 6, reward: -94.11199253349486
Background Trial: 7, reward: -92.01995474728294
Background Trial: 8, reward: -93.14254650631068
Background Trial: 9, reward: -94.65618956823441
Iteration: 4, average_reward: -94.0481986868783

Policy train: iteration: 500, policy_loss: 0.002295
Policy train: iteration: 1000, policy_loss: 0.002546
Policy train: iteration: 1500, policy_loss: 0.001995
Policy train: iteration: 2000, policy_loss: 0.002625
Policy train: iteration: 2500, policy_loss: 0.004448
Policy train: iteration: 3000, policy_loss: 0.002366
Policy train: iteration: 3500, policy_loss: 0.002826
Policy train: iteration: 4000, policy_loss: 0.002264
Policy train: iteration: 4500, policy_loss: 0.002293
Policy train: iteration: 5000, policy_loss: 0.001591
Policy train: iteration: 5500, policy_loss: 0.002366
Policy train: iteration: 6000, policy_loss: 0.004027

Background Trial: 1, reward: -143.69451347425183
Background Trial: 2, reward: -143.11954271755272
Background Trial: 3, reward: -140.50112865608332
Background Trial: 4, reward: -142.09030071520405
Background Trial: 5, reward: -143.14502607321137
Background Trial: 6, reward: -142.5907784351508
Background Trial: 7, reward: -145.46246336681406
Background Trial: 8, reward: -148.7365517956848
Background Trial: 9, reward: -146.12568103109368
Iteration: 5, average_reward: -143.94066514056072

Policy train: iteration: 500, policy_loss: 0.003869
Policy train: iteration: 1000, policy_loss: 0.002668
Policy train: iteration: 1500, policy_loss: 0.002553
Policy train: iteration: 2000, policy_loss: 0.001556
Policy train: iteration: 2500, policy_loss: 0.002890
Policy train: iteration: 3000, policy_loss: 0.002753
Policy train: iteration: 3500, policy_loss: 0.003913
Policy train: iteration: 4000, policy_loss: 0.002315
Policy train: iteration: 4500, policy_loss: 0.002743
Policy train: iteration: 5000, policy_loss: 0.001836
Policy train: iteration: 5500, policy_loss: 0.004414
Policy train: iteration: 6000, policy_loss: 0.003423

Background Trial: 1, reward: -157.4317959105438
Background Trial: 2, reward: -156.74372223594963
Background Trial: 3, reward: -165.67050525211687
Background Trial: 4, reward: -159.4200059525622
Background Trial: 5, reward: -156.94988520671953
Background Trial: 6, reward: -155.84034236170552
Background Trial: 7, reward: -157.38581829853038
Background Trial: 8, reward: -158.20806725426087
Background Trial: 9, reward: -166.5624178332293
Iteration: 6, average_reward: -159.35695114506868

Policy train: iteration: 500, policy_loss: 0.002977
Policy train: iteration: 1000, policy_loss: 0.002556
Policy train: iteration: 1500, policy_loss: 0.002536
Policy train: iteration: 2000, policy_loss: 0.001596
Policy train: iteration: 2500, policy_loss: 0.002391
Policy train: iteration: 3000, policy_loss: 0.003506
Policy train: iteration: 3500, policy_loss: 0.004366
Policy train: iteration: 4000, policy_loss: 0.002701
Policy train: iteration: 4500, policy_loss: 0.002012
Policy train: iteration: 5000, policy_loss: 0.002172
Policy train: iteration: 5500, policy_loss: 0.002528
Policy train: iteration: 6000, policy_loss: 0.001998

Background Trial: 1, reward: -138.99301881451325
Background Trial: 2, reward: -137.38040113237832
Background Trial: 3, reward: -156.74036585475338
Background Trial: 4, reward: -146.5862539366811
Background Trial: 5, reward: -146.8530019875442
Background Trial: 6, reward: -130.28600767882747
Background Trial: 7, reward: -156.4783152851344
Background Trial: 8, reward: -137.75619000835488
Background Trial: 9, reward: -137.31701913507482
Iteration: 7, average_reward: -143.15450820369574

Policy train: iteration: 500, policy_loss: 0.002173
Policy train: iteration: 1000, policy_loss: 0.002792
Policy train: iteration: 1500, policy_loss: 0.001782
Policy train: iteration: 2000, policy_loss: 0.001588
Policy train: iteration: 2500, policy_loss: 0.001533
Policy train: iteration: 3000, policy_loss: 0.003028
Policy train: iteration: 3500, policy_loss: 0.002007
Policy train: iteration: 4000, policy_loss: 0.002512
Policy train: iteration: 4500, policy_loss: 0.002175
Policy train: iteration: 5000, policy_loss: 0.002473
Policy train: iteration: 5500, policy_loss: 0.002838
Policy train: iteration: 6000, policy_loss: 0.001914

Background Trial: 1, reward: -166.84951118574733
Background Trial: 2, reward: -166.19129686328313
Background Trial: 3, reward: -166.71227549162342
Background Trial: 4, reward: -166.8424230721758
Background Trial: 5, reward: -166.99668036495726
Background Trial: 6, reward: -166.6772746622236
Background Trial: 7, reward: -166.713693365334
Background Trial: 8, reward: -166.8680029689237
Background Trial: 9, reward: -166.34704805642036
Iteration: 8, average_reward: -166.6886895589654

Policy train: iteration: 500, policy_loss: 0.003509
Policy train: iteration: 1000, policy_loss: 0.002615
Policy train: iteration: 1500, policy_loss: 0.001705
Policy train: iteration: 2000, policy_loss: 0.003380
Policy train: iteration: 2500, policy_loss: 0.003251
Policy train: iteration: 3000, policy_loss: 0.002141
Policy train: iteration: 3500, policy_loss: 0.001800
Policy train: iteration: 4000, policy_loss: 0.002139
Policy train: iteration: 4500, policy_loss: 0.002798
Policy train: iteration: 5000, policy_loss: 0.002431
Policy train: iteration: 5500, policy_loss: 0.001863
Policy train: iteration: 6000, policy_loss: 0.001908

Background Trial: 1, reward: -132.24754977280037
Background Trial: 2, reward: -130.79143300937383
Background Trial: 3, reward: -130.68612922606448
Background Trial: 4, reward: -156.05465614454081
Background Trial: 5, reward: -146.9902644372054
Background Trial: 6, reward: -157.24748410531748
Background Trial: 7, reward: -147.38173769266695
Background Trial: 8, reward: -142.61798417766133
Background Trial: 9, reward: -133.30672492614553
Iteration: 9, average_reward: -141.9248848324196

Policy train: iteration: 500, policy_loss: 0.002745
Policy train: iteration: 1000, policy_loss: 0.002876
Policy train: iteration: 1500, policy_loss: 0.002397
Policy train: iteration: 2000, policy_loss: 0.002559
Policy train: iteration: 2500, policy_loss: 0.002359
Policy train: iteration: 3000, policy_loss: 0.002132
Policy train: iteration: 3500, policy_loss: 0.002484
Policy train: iteration: 4000, policy_loss: 0.002100
Policy train: iteration: 4500, policy_loss: 0.002399
Policy train: iteration: 5000, policy_loss: 0.001512
Policy train: iteration: 5500, policy_loss: 0.003162
Policy train: iteration: 6000, policy_loss: 0.002183

Background Trial: 1, reward: -50.34441294865891
Background Trial: 2, reward: -47.82366189613735
Background Trial: 3, reward: -90.98527405397967
Background Trial: 4, reward: -69.37906880343623
Background Trial: 5, reward: -46.872597474350634
Background Trial: 6, reward: -47.97078463878559
Background Trial: 7, reward: -97.3290820904147
Background Trial: 8, reward: -66.51266566554268
Background Trial: 9, reward: -43.44492397216332
Iteration: 10, average_reward: -62.29583017149657

Policy train: iteration: 500, policy_loss: 0.001736
Policy train: iteration: 1000, policy_loss: 0.002519
Policy train: iteration: 1500, policy_loss: 0.002141
Policy train: iteration: 2000, policy_loss: 0.002676
Policy train: iteration: 2500, policy_loss: 0.002360
Policy train: iteration: 3000, policy_loss: 0.003830
Policy train: iteration: 3500, policy_loss: 0.003478
Policy train: iteration: 4000, policy_loss: 0.003489
Policy train: iteration: 4500, policy_loss: 0.003894
Policy train: iteration: 5000, policy_loss: 0.001725
Policy train: iteration: 5500, policy_loss: 0.003729
Policy train: iteration: 6000, policy_loss: 0.002095

Background Trial: 1, reward: -66.25689458894955
Background Trial: 2, reward: -90.2814712430487
Background Trial: 3, reward: -134.85748355347647
Background Trial: 4, reward: -86.74900626190892
Background Trial: 5, reward: -169.326984927835
Background Trial: 6, reward: -66.15026565883518
Background Trial: 7, reward: -76.69593487111914
Background Trial: 8, reward: -65.92177346787945
Background Trial: 9, reward: -64.91359825995895
Iteration: 11, average_reward: -91.23926809255681

Policy train: iteration: 500, policy_loss: 0.002379
Policy train: iteration: 1000, policy_loss: 0.002281
Policy train: iteration: 1500, policy_loss: 0.002275
Policy train: iteration: 2000, policy_loss: 0.001711
Policy train: iteration: 2500, policy_loss: 0.001874
Policy train: iteration: 3000, policy_loss: 0.002457
Policy train: iteration: 3500, policy_loss: 0.003187
Policy train: iteration: 4000, policy_loss: 0.002434
Policy train: iteration: 4500, policy_loss: 0.003544
Policy train: iteration: 5000, policy_loss: 0.002048
Policy train: iteration: 5500, policy_loss: 0.001551
Policy train: iteration: 6000, policy_loss: 0.001439

Background Trial: 1, reward: -67.76818355409917
Background Trial: 2, reward: -68.26535278686706
Background Trial: 3, reward: -71.6750548772823
Background Trial: 4, reward: -160.26175151778494
Background Trial: 5, reward: -67.94717592980112
Background Trial: 6, reward: -151.52630223317283
Background Trial: 7, reward: -165.49835305724824
Background Trial: 8, reward: -159.94178386899463
Background Trial: 9, reward: -68.08058697543095
Iteration: 12, average_reward: -108.99606053340904

Policy train: iteration: 500, policy_loss: 0.002364
Policy train: iteration: 1000, policy_loss: 0.002042
Policy train: iteration: 1500, policy_loss: 0.003911
Policy train: iteration: 2000, policy_loss: 0.001657
Policy train: iteration: 2500, policy_loss: 0.001725
Policy train: iteration: 3000, policy_loss: 0.002045
Policy train: iteration: 3500, policy_loss: 0.001156
Policy train: iteration: 4000, policy_loss: 0.004393
Policy train: iteration: 4500, policy_loss: 0.003520
Policy train: iteration: 5000, policy_loss: 0.002645
Policy train: iteration: 5500, policy_loss: 0.002233
Policy train: iteration: 6000, policy_loss: 0.002105

Background Trial: 1, reward: -168.9124545795835
Background Trial: 2, reward: -168.67455927971523
Background Trial: 3, reward: -135.90463392149567
Background Trial: 4, reward: -165.05805916428346
Background Trial: 5, reward: -168.36469762657393
Background Trial: 6, reward: -166.4516057690689
Background Trial: 7, reward: -168.53611391163176
Background Trial: 8, reward: -165.84199170074987
Background Trial: 9, reward: -163.51650398754654
Iteration: 13, average_reward: -163.47340221562763

Policy train: iteration: 500, policy_loss: 0.001747
