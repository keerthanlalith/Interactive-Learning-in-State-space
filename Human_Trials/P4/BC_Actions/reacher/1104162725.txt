Policy train: iteration: 500, policy_loss: 0.000306
Policy train: iteration: 1000, policy_loss: 0.000624
Policy train: iteration: 1500, policy_loss: 0.000470
Policy train: iteration: 2000, policy_loss: 0.000544
Policy train: iteration: 2500, policy_loss: 0.000513
Policy train: iteration: 3000, policy_loss: 0.000684
Policy train: iteration: 3500, policy_loss: 0.000438
Policy train: iteration: 4000, policy_loss: 0.000427
Policy train: iteration: 4500, policy_loss: 0.000395
Policy train: iteration: 5000, policy_loss: 0.000425
Policy train: iteration: 5500, policy_loss: 0.000786
Policy train: iteration: 6000, policy_loss: 0.000392

Background Trial: 1, reward: -64.12492389233307
Background Trial: 2, reward: -72.73143395710358
Background Trial: 3, reward: -63.41622662202307
Background Trial: 4, reward: -65.77440950231532
Background Trial: 5, reward: -71.20393990497635
Background Trial: 6, reward: -58.957249019256764
Background Trial: 7, reward: -60.37689292153213
Background Trial: 8, reward: -71.89557718973111
Background Trial: 9, reward: -69.66733027532871
Iteration: 1, average_reward: -66.46088703162224

Policy train: iteration: 500, policy_loss: 0.000327
Policy train: iteration: 1000, policy_loss: 0.000316
Policy train: iteration: 1500, policy_loss: 0.000151
Policy train: iteration: 2000, policy_loss: 0.000293
Policy train: iteration: 2500, policy_loss: 0.000623
Policy train: iteration: 3000, policy_loss: 0.000486
Policy train: iteration: 3500, policy_loss: 0.000394
Policy train: iteration: 4000, policy_loss: 0.000381
Policy train: iteration: 4500, policy_loss: 0.000315
Policy train: iteration: 5000, policy_loss: 0.000410
Policy train: iteration: 5500, policy_loss: 0.000452
Policy train: iteration: 6000, policy_loss: 0.000525

Background Trial: 1, reward: -139.856360431859
Background Trial: 2, reward: -122.10413480576555
Background Trial: 3, reward: -102.28327764049742
Background Trial: 4, reward: -106.0926425152883
Background Trial: 5, reward: -115.68281446990157
Background Trial: 6, reward: -107.66690401109024
Background Trial: 7, reward: -132.43199806867395
Background Trial: 8, reward: -113.18718557030242
Background Trial: 9, reward: -124.07054735433715
Iteration: 2, average_reward: -118.15287387419062

Policy train: iteration: 500, policy_loss: 0.000360
Policy train: iteration: 1000, policy_loss: 0.000539
Policy train: iteration: 1500, policy_loss: 0.000449
Policy train: iteration: 2000, policy_loss: 0.000444
Policy train: iteration: 2500, policy_loss: 0.000302
Policy train: iteration: 3000, policy_loss: 0.000386
Policy train: iteration: 3500, policy_loss: 0.000323
Policy train: iteration: 4000, policy_loss: 0.000701
Policy train: iteration: 4500, policy_loss: 0.000378
Policy train: iteration: 5000, policy_loss: 0.000521
Policy train: iteration: 5500, policy_loss: 0.000279
Policy train: iteration: 6000, policy_loss: 0.000431

Background Trial: 1, reward: -55.63050231440559
Background Trial: 2, reward: -156.9987742674262
Background Trial: 3, reward: -320.73218452207783
Background Trial: 4, reward: -155.06732379679144
Background Trial: 5, reward: -156.58833974902484
Background Trial: 6, reward: -320.2412595539589
Background Trial: 7, reward: -158.2902311936618
Background Trial: 8, reward: -159.27806039734855
Background Trial: 9, reward: -159.91761706011945
Iteration: 3, average_reward: -182.52714365053495

Policy train: iteration: 500, policy_loss: 0.000598
Policy train: iteration: 1000, policy_loss: 0.000421
Policy train: iteration: 1500, policy_loss: 0.000316
Policy train: iteration: 2000, policy_loss: 0.000673
Policy train: iteration: 2500, policy_loss: 0.000295
Policy train: iteration: 3000, policy_loss: 0.000570
Policy train: iteration: 3500, policy_loss: 0.000519
Policy train: iteration: 4000, policy_loss: 0.000405
Policy train: iteration: 4500, policy_loss: 0.000301
Policy train: iteration: 5000, policy_loss: 0.000528
Policy train: iteration: 5500, policy_loss: 0.000358
Policy train: iteration: 6000, policy_loss: 0.000357

Background Trial: 1, reward: -41.93463587268615
Background Trial: 2, reward: -42.13103893371773
Background Trial: 3, reward: -34.329790034271646
Background Trial: 4, reward: -43.622139837105664
Background Trial: 5, reward: -44.82006963408707
Background Trial: 6, reward: -40.72705545918666
Background Trial: 7, reward: -52.83058974677969
Background Trial: 8, reward: -35.741105864778945
Background Trial: 9, reward: -36.90244291900732
Iteration: 4, average_reward: -41.44876314462454

Policy train: iteration: 500, policy_loss: 0.000218
Policy train: iteration: 1000, policy_loss: 0.000547
Policy train: iteration: 1500, policy_loss: 0.000403
Policy train: iteration: 2000, policy_loss: 0.000535
Policy train: iteration: 2500, policy_loss: 0.000517
Policy train: iteration: 3000, policy_loss: 0.000332
Policy train: iteration: 3500, policy_loss: 0.000226
Policy train: iteration: 4000, policy_loss: 0.000524
Policy train: iteration: 4500, policy_loss: 0.000548
Policy train: iteration: 5000, policy_loss: 0.000421
Policy train: iteration: 5500, policy_loss: 0.000394
Policy train: iteration: 6000, policy_loss: 0.000301

Background Trial: 1, reward: -121.61743206671153
Background Trial: 2, reward: -75.18747735643247
Background Trial: 3, reward: -35.79145854232534
Background Trial: 4, reward: -120.49408691358661
Background Trial: 5, reward: -38.85351923387844
Background Trial: 6, reward: -43.428623590016834
Background Trial: 7, reward: -121.84704772426733
Background Trial: 8, reward: -30.088521671514478
Background Trial: 9, reward: -120.30351862289743
Iteration: 5, average_reward: -78.62352063573672

Policy train: iteration: 500, policy_loss: 0.000225
Policy train: iteration: 1000, policy_loss: 0.000594
Policy train: iteration: 1500, policy_loss: 0.000268
Policy train: iteration: 2000, policy_loss: 0.000581
Policy train: iteration: 2500, policy_loss: 0.000433
Policy train: iteration: 3000, policy_loss: 0.000443
Policy train: iteration: 3500, policy_loss: 0.000493
Policy train: iteration: 4000, policy_loss: 0.000538
Policy train: iteration: 4500, policy_loss: 0.000357
Policy train: iteration: 5000, policy_loss: 0.000151
Policy train: iteration: 5500, policy_loss: 0.000411
Policy train: iteration: 6000, policy_loss: 0.000442

Background Trial: 1, reward: -515.1985662972645
Background Trial: 2, reward: -487.9418111326024
Background Trial: 3, reward: -491.9281280833227
Background Trial: 4, reward: -511.48600862852874
Background Trial: 5, reward: -505.71866426451464
Background Trial: 6, reward: -493.61455296236295
Background Trial: 7, reward: -494.87670209016704
Background Trial: 8, reward: -502.34542279428655
Background Trial: 9, reward: -502.81840945466297
Iteration: 6, average_reward: -500.65869618974585

Policy train: iteration: 500, policy_loss: 0.000340
Policy train: iteration: 1000, policy_loss: 0.000317
Policy train: iteration: 1500, policy_loss: 0.000399
Policy train: iteration: 2000, policy_loss: 0.000224
Policy train: iteration: 2500, policy_loss: 0.000268
Policy train: iteration: 3000, policy_loss: 0.000639
Policy train: iteration: 3500, policy_loss: 0.000513
Policy train: iteration: 4000, policy_loss: 0.000592
Policy train: iteration: 4500, policy_loss: 0.000449
Policy train: iteration: 5000, policy_loss: 0.000296
Policy train: iteration: 5500, policy_loss: 0.000573
Policy train: iteration: 6000, policy_loss: 0.000448

Background Trial: 1, reward: -179.47470561101431
Background Trial: 2, reward: -27.83322304410382
Background Trial: 3, reward: -490.3071162535005
Background Trial: 4, reward: -365.14763571461395
Background Trial: 5, reward: -42.260295032272126
Background Trial: 6, reward: -26.783394528246056
Background Trial: 7, reward: -23.3408335042885
Background Trial: 8, reward: -39.433556164531005
Background Trial: 9, reward: -27.967557030229752
Iteration: 7, average_reward: -135.83870187586666

Policy train: iteration: 500, policy_loss: 0.000344
Policy train: iteration: 1000, policy_loss: 0.000399
Policy train: iteration: 1500, policy_loss: 0.000267
Policy train: iteration: 2000, policy_loss: 0.000534
Policy train: iteration: 2500, policy_loss: 0.000282
Policy train: iteration: 3000, policy_loss: 0.000254
Policy train: iteration: 3500, policy_loss: 0.000574
Policy train: iteration: 4000, policy_loss: 0.000298
Policy train: iteration: 4500, policy_loss: 0.000411
Policy train: iteration: 5000, policy_loss: 0.000487
Policy train: iteration: 5500, policy_loss: 0.000247
Policy train: iteration: 6000, policy_loss: 0.000559

Background Trial: 1, reward: -197.8535313579129
Background Trial: 2, reward: -199.66994439945228
Background Trial: 3, reward: -197.30983146795683
Background Trial: 4, reward: -199.94610038728948
Background Trial: 5, reward: -197.1779599253642
Background Trial: 6, reward: -198.2069424977339
Background Trial: 7, reward: -198.73644813945978
Background Trial: 8, reward: -201.32402291338173
Background Trial: 9, reward: -200.9354231778933
Iteration: 8, average_reward: -199.01780047404938

Policy train: iteration: 500, policy_loss: 0.000546
Policy train: iteration: 1000, policy_loss: 0.000260
Policy train: iteration: 1500, policy_loss: 0.000287
Policy train: iteration: 2000, policy_loss: 0.000582
Policy train: iteration: 2500, policy_loss: 0.000425
Policy train: iteration: 3000, policy_loss: 0.000420
Policy train: iteration: 3500, policy_loss: 0.000588
Policy train: iteration: 4000, policy_loss: 0.000449
Policy train: iteration: 4500, policy_loss: 0.000172
Policy train: iteration: 5000, policy_loss: 0.000443
Policy train: iteration: 5500, policy_loss: 0.000379
Policy train: iteration: 6000, policy_loss: 0.000255

Background Trial: 1, reward: -42.04626626756153
Background Trial: 2, reward: -42.7205088230116
Background Trial: 3, reward: -32.657547177724354
Background Trial: 4, reward: -31.79908101919528
Background Trial: 5, reward: -43.50199634227887
Background Trial: 6, reward: -32.5932472387619
Background Trial: 7, reward: -36.6114971668108
Background Trial: 8, reward: -35.54842334981452
Background Trial: 9, reward: -42.098133776772144
Iteration: 9, average_reward: -37.73074457354789

Policy train: iteration: 500, policy_loss: 0.000317
Policy train: iteration: 1000, policy_loss: 0.000432
Policy train: iteration: 1500, policy_loss: 0.000475
Policy train: iteration: 2000, policy_loss: 0.000375
Policy train: iteration: 2500, policy_loss: 0.000281
Policy train: iteration: 3000, policy_loss: 0.000634
Policy train: iteration: 3500, policy_loss: 0.000426
Policy train: iteration: 4000, policy_loss: 0.000431
Policy train: iteration: 4500, policy_loss: 0.000466
Policy train: iteration: 5000, policy_loss: 0.000375
Policy train: iteration: 5500, policy_loss: 0.000363
Policy train: iteration: 6000, policy_loss: 0.000353

Background Trial: 1, reward: -71.78765283106081
Background Trial: 2, reward: -57.20079842669865
Background Trial: 3, reward: -49.669100231400286
Background Trial: 4, reward: -49.46895919151032
Background Trial: 5, reward: -51.50277418498016
Background Trial: 6, reward: -46.407269038306964
Background Trial: 7, reward: -26.06740045030956
Background Trial: 8, reward: -69.84771183791538
Background Trial: 9, reward: -19.496864815794684
Iteration: 10, average_reward: -49.04983677866409

Policy train: iteration: 500, policy_loss: 0.000076
Policy train: iteration: 1000, policy_loss: 0.000462
Policy train: iteration: 1500, policy_loss: 0.000310
Policy train: iteration: 2000, policy_loss: 0.000213
Policy train: iteration: 2500, policy_loss: 0.000327
Policy train: iteration: 3000, policy_loss: 0.000687
Policy train: iteration: 3500, policy_loss: 0.000369
Policy train: iteration: 4000, policy_loss: 0.000330
Policy train: iteration: 4500, policy_loss: 0.000280
Policy train: iteration: 5000, policy_loss: 0.000313
Policy train: iteration: 5500, policy_loss: 0.000345
Policy train: iteration: 6000, policy_loss: 0.000490

Background Trial: 1, reward: -56.203497163617456
Background Trial: 2, reward: -58.79729354315903
Background Trial: 3, reward: -57.61742917471864
Background Trial: 4, reward: -59.27398858964811
Background Trial: 5, reward: -59.48496342599484
Background Trial: 6, reward: -57.188312562235744
Background Trial: 7, reward: -56.66145938474929
Background Trial: 8, reward: -56.69519022426568
Background Trial: 9, reward: -56.27588255600313
Iteration: 11, average_reward: -57.57755740271023

Policy train: iteration: 500, policy_loss: 0.000227
Policy train: iteration: 1000, policy_loss: 0.000336
Policy train: iteration: 1500, policy_loss: 0.000423
Policy train: iteration: 2000, policy_loss: 0.000311
Policy train: iteration: 2500, policy_loss: 0.000291
Policy train: iteration: 3000, policy_loss: 0.000299
Policy train: iteration: 3500, policy_loss: 0.000366
Policy train: iteration: 4000, policy_loss: 0.000521
Policy train: iteration: 4500, policy_loss: 0.000406
Policy train: iteration: 5000, policy_loss: 0.000387
Policy train: iteration: 5500, policy_loss: 0.000499
Policy train: iteration: 6000, policy_loss: 0.000245

Background Trial: 1, reward: -41.329043386630865
Background Trial: 2, reward: -41.85676083324207
Background Trial: 3, reward: -39.3755112507823
Background Trial: 4, reward: -41.36092856673651
Background Trial: 5, reward: -41.73448857786709
Background Trial: 6, reward: -40.34015192909639
Background Trial: 7, reward: -44.63307655889332
Background Trial: 8, reward: -43.53162646949644
Background Trial: 9, reward: -44.92238470995016
Iteration: 12, average_reward: -42.120441364743904

Policy train: iteration: 500, policy_loss: 0.000395
Policy train: iteration: 1000, policy_loss: 0.000409
Policy train: iteration: 1500, policy_loss: 0.000523
Policy train: iteration: 2000, policy_loss: 0.000554
Policy train: iteration: 2500, policy_loss: 0.000254
Policy train: iteration: 3000, policy_loss: 0.000374
Policy train: iteration: 3500, policy_loss: 0.000456
Policy train: iteration: 4000, policy_loss: 0.000189
Policy train: iteration: 4500, policy_loss: 0.000254
Policy train: iteration: 5000, policy_loss: 0.000617
Policy train: iteration: 5500, policy_loss: 0.000211
Policy train: iteration: 6000, policy_loss: 0.000342

Background Trial: 1, reward: -44.241526242602326
Background Trial: 2, reward: -40.9943089051034
Background Trial: 3, reward: -41.28320638357994
Background Trial: 4, reward: -64.96671427888766
Background Trial: 5, reward: -45.66652238317869
Background Trial: 6, reward: -41.63985699065028
Background Trial: 7, reward: -42.73204157043008
Background Trial: 8, reward: -44.95533706931344
Background Trial: 9, reward: -40.36162616292588
Iteration: 13, average_reward: -45.20457110963018

Policy train: iteration: 500, policy_loss: 0.000153
Policy train: iteration: 1000, policy_loss: 0.000484
Policy train: iteration: 1500, policy_loss: 0.000462
Policy train: iteration: 2000, policy_loss: 0.000470
Policy train: iteration: 2500, policy_loss: 0.000243
Policy train: iteration: 3000, policy_loss: 0.000536
Policy train: iteration: 3500, policy_loss: 0.000568
Policy train: iteration: 4000, policy_loss: 0.000315
Policy train: iteration: 4500, policy_loss: 0.000306
Policy train: iteration: 5000, policy_loss: 0.000181
Policy train: iteration: 5500, policy_loss: 0.000584
Policy train: iteration: 6000, policy_loss: 0.000254

Background Trial: 1, reward: -413.3088293212755
Background Trial: 2, reward: -613.1188075223909
Background Trial: 3, reward: -120.69842896636281
Background Trial: 4, reward: -615.2763564096122
Background Trial: 5, reward: -117.05095501864083
Background Trial: 6, reward: -627.2880046125473
Background Trial: 7, reward: -173.49361678992952
Background Trial: 8, reward: -636.103371047669
Background Trial: 9, reward: -545.9970679218151
Iteration: 14, average_reward: -429.14838195669364

Policy train: iteration: 500, policy_loss: 0.000281
Policy train: iteration: 1000, policy_loss: 0.000360
Policy train: iteration: 1500, policy_loss: 0.000736
Policy train: iteration: 2000, policy_loss: 0.000336
Policy train: iteration: 2500, policy_loss: 0.000335
Policy train: iteration: 3000, policy_loss: 0.000304
Policy train: iteration: 3500, policy_loss: 0.000447
Policy train: iteration: 4000, policy_loss: 0.000302
Policy train: iteration: 4500, policy_loss: 0.000334
Policy train: iteration: 5000, policy_loss: 0.000298
Policy train: iteration: 5500, policy_loss: 0.000360
Policy train: iteration: 6000, policy_loss: 0.000405

Background Trial: 1, reward: -551.8374814327143
Background Trial: 2, reward: -558.8910202364362
Background Trial: 3, reward: -561.9685267393836
Background Trial: 4, reward: -561.4686725822435
Background Trial: 5, reward: -560.755652625995
Background Trial: 6, reward: -561.8025930946383
Background Trial: 7, reward: -560.6997181806112
Background Trial: 8, reward: -542.1965663772024
Background Trial: 9, reward: -542.2198830824638
Iteration: 15, average_reward: -555.7600127057432

Policy train: iteration: 500, policy_loss: 0.000536
Policy train: iteration: 1000, policy_loss: 0.000241
Policy train: iteration: 1500, policy_loss: 0.000211
Policy train: iteration: 2000, policy_loss: 0.000585
Policy train: iteration: 2500, policy_loss: 0.000234
Policy train: iteration: 3000, policy_loss: 0.000522
Policy train: iteration: 3500, policy_loss: 0.000214
Policy train: iteration: 4000, policy_loss: 0.000111
Policy train: iteration: 4500, policy_loss: 0.000375
Policy train: iteration: 5000, policy_loss: 0.000176
Policy train: iteration: 5500, policy_loss: 0.000254
Policy train: iteration: 6000, policy_loss: 0.000209

Background Trial: 1, reward: -42.140398634310216
Background Trial: 2, reward: -595.6412955574392
Background Trial: 3, reward: -554.5443295572986
Background Trial: 4, reward: -581.1032853450249
Background Trial: 5, reward: -349.6135986359599
Background Trial: 6, reward: -40.79838194546815
Background Trial: 7, reward: -585.10368629363
Background Trial: 8, reward: -40.148433766392984
Background Trial: 9, reward: -41.645847858004856
Iteration: 16, average_reward: -314.5265841770587

Policy train: iteration: 500, policy_loss: 0.000442
Policy train: iteration: 1000, policy_loss: 0.000475
Policy train: iteration: 1500, policy_loss: 0.000189
Policy train: iteration: 2000, policy_loss: 0.000521
Policy train: iteration: 2500, policy_loss: 0.000288
Policy train: iteration: 3000, policy_loss: 0.000476
Policy train: iteration: 3500, policy_loss: 0.000661
Policy train: iteration: 4000, policy_loss: 0.000278
Policy train: iteration: 4500, policy_loss: 0.000413
Policy train: iteration: 5000, policy_loss: 0.000315
Policy train: iteration: 5500, policy_loss: 0.000432
Policy train: iteration: 6000, policy_loss: 0.000325

Background Trial: 1, reward: -589.7245161396472
Background Trial: 2, reward: -611.864817471865
Background Trial: 3, reward: -603.9565765739426
Background Trial: 4, reward: -603.0689002307764
Background Trial: 5, reward: -610.7960411025166
Background Trial: 6, reward: -615.9500391045174
Background Trial: 7, reward: -603.9353150118584
Background Trial: 8, reward: -22.527522081362736
Background Trial: 9, reward: -22.996468329615485
Iteration: 17, average_reward: -476.0911328940113

Policy train: iteration: 500, policy_loss: 0.000382
Policy train: iteration: 1000, policy_loss: 0.000528
Policy train: iteration: 1500, policy_loss: 0.000327
Policy train: iteration: 2000, policy_loss: 0.000418
Policy train: iteration: 2500, policy_loss: 0.000524
Policy train: iteration: 3000, policy_loss: 0.000649
Policy train: iteration: 3500, policy_loss: 0.000384
Policy train: iteration: 4000, policy_loss: 0.000523
Policy train: iteration: 4500, policy_loss: 0.000351
Policy train: iteration: 5000, policy_loss: 0.000469
Policy train: iteration: 5500, policy_loss: 0.000415
Policy train: iteration: 6000, policy_loss: 0.000360

Background Trial: 1, reward: -45.62856315478902
Background Trial: 2, reward: -47.26456257776145
Background Trial: 3, reward: -44.46561136625775
Background Trial: 4, reward: -47.67203814261609
Background Trial: 5, reward: -41.594224681440245
Background Trial: 6, reward: -42.44436510958855
Background Trial: 7, reward: -44.810703696487124
Background Trial: 8, reward: -52.300167543083674
Background Trial: 9, reward: -628.74727488473
Iteration: 18, average_reward: -110.54750123963932

Policy train: iteration: 500, policy_loss: 0.000265
Policy train: iteration: 1000, policy_loss: 0.000267
Policy train: iteration: 1500, policy_loss: 0.000498
Policy train: iteration: 2000, policy_loss: 0.000354
Policy train: iteration: 2500, policy_loss: 0.000288
Policy train: iteration: 3000, policy_loss: 0.000509
Policy train: iteration: 3500, policy_loss: 0.000370
Policy train: iteration: 4000, policy_loss: 0.000415
Policy train: iteration: 4500, policy_loss: 0.000572
Policy train: iteration: 5000, policy_loss: 0.000259
Policy train: iteration: 5500, policy_loss: 0.000562
Policy train: iteration: 6000, policy_loss: 0.000346

Background Trial: 1, reward: -39.86336902998794
Background Trial: 2, reward: -406.3407950306217
Background Trial: 3, reward: -42.28739485696921
Background Trial: 4, reward: -32.48415304418684
Background Trial: 5, reward: -574.2772538498951
Background Trial: 6, reward: -38.92382552720136
Background Trial: 7, reward: -364.33258530386564
Background Trial: 8, reward: -38.38331580733204
Background Trial: 9, reward: -365.03171550543004
Iteration: 19, average_reward: -211.32493421727668

Policy train: iteration: 500, policy_loss: 0.000632
Policy train: iteration: 1000, policy_loss: 0.000332
Policy train: iteration: 1500, policy_loss: 0.000380
Policy train: iteration: 2000, policy_loss: 0.000325
Policy train: iteration: 2500, policy_loss: 0.000333
Policy train: iteration: 3000, policy_loss: 0.000382
Policy train: iteration: 3500, policy_loss: 0.000271
Policy train: iteration: 4000, policy_loss: 0.000266
Policy train: iteration: 4500, policy_loss: 0.000342
Policy train: iteration: 5000, policy_loss: 0.000358
Policy train: iteration: 5500, policy_loss: 0.000471
Policy train: iteration: 6000, policy_loss: 0.000311

Background Trial: 1, reward: -53.66946254038681
Background Trial: 2, reward: -142.68456231941173
Background Trial: 3, reward: -172.80195092784334
Background Trial: 4, reward: -142.2563619407304
Background Trial: 5, reward: -52.14496450658125
Background Trial: 6, reward: -137.2270045053813
Background Trial: 7, reward: -282.5197551287798
Background Trial: 8, reward: -178.30725137967005
Background Trial: 9, reward: -142.70935103569937
Iteration: 20, average_reward: -144.92451825383156

