Policy train: iteration: 500, policy_loss: 0.294513
Policy train: iteration: 1000, policy_loss: 0.299987
Policy train: iteration: 1500, policy_loss: 0.335994
Policy train: iteration: 2000, policy_loss: 0.249884
Policy train: iteration: 2500, policy_loss: 0.284616
Policy train: iteration: 3000, policy_loss: 0.275287
Policy train: iteration: 3500, policy_loss: 0.208055
Policy train: iteration: 4000, policy_loss: 0.328641

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 118.0
Background Trial: 3, reward: 126.0
Background Trial: 4, reward: 180.0
Background Trial: 5, reward: 117.0
Background Trial: 6, reward: 150.0
Background Trial: 7, reward: 135.0
Background Trial: 8, reward: 146.0
Background Trial: 9, reward: 125.0
Iteration: 1, average_reward: 144.11111111111111

Policy train: iteration: 500, policy_loss: 0.164774
Policy train: iteration: 1000, policy_loss: 0.230408
Policy train: iteration: 1500, policy_loss: 0.170242
Policy train: iteration: 2000, policy_loss: 0.183586
Policy train: iteration: 2500, policy_loss: 0.294213
Policy train: iteration: 3000, policy_loss: 0.196958
Policy train: iteration: 3500, policy_loss: 0.208133
Policy train: iteration: 4000, policy_loss: 0.213769

Background Trial: 1, reward: 105.0
Background Trial: 2, reward: 44.0
Background Trial: 3, reward: 59.0
Background Trial: 4, reward: 111.0
Background Trial: 5, reward: 61.0
Background Trial: 6, reward: 106.0
Background Trial: 7, reward: 41.0
Background Trial: 8, reward: 55.0
Background Trial: 9, reward: 123.0
Iteration: 2, average_reward: 78.33333333333333

Policy train: iteration: 500, policy_loss: 0.239519
Policy train: iteration: 1000, policy_loss: 0.261148
Policy train: iteration: 1500, policy_loss: 0.128902
Policy train: iteration: 2000, policy_loss: 0.226416
Policy train: iteration: 2500, policy_loss: 0.201054
Policy train: iteration: 3000, policy_loss: 0.219503
Policy train: iteration: 3500, policy_loss: 0.231455
Policy train: iteration: 4000, policy_loss: 0.160116

Background Trial: 1, reward: 76.0
Background Trial: 2, reward: 110.0
Background Trial: 3, reward: 42.0
Background Trial: 4, reward: 108.0
Background Trial: 5, reward: 188.0
Background Trial: 6, reward: 111.0
Background Trial: 7, reward: 77.0
Background Trial: 8, reward: 128.0
Background Trial: 9, reward: 48.0
Iteration: 3, average_reward: 98.66666666666667

Policy train: iteration: 500, policy_loss: 0.311786
Policy train: iteration: 1000, policy_loss: 0.164757
Policy train: iteration: 1500, policy_loss: 0.112742
Policy train: iteration: 2000, policy_loss: 0.173126
Policy train: iteration: 2500, policy_loss: 0.208480
Policy train: iteration: 3000, policy_loss: 0.183453
Policy train: iteration: 3500, policy_loss: 0.250767
Policy train: iteration: 4000, policy_loss: 0.221386

Background Trial: 1, reward: 25.0
Background Trial: 2, reward: 101.0
Background Trial: 3, reward: 32.0
Background Trial: 4, reward: 89.0
Background Trial: 5, reward: 23.0
Background Trial: 6, reward: 38.0
Background Trial: 7, reward: 90.0
Background Trial: 8, reward: 48.0
Background Trial: 9, reward: 89.0
Iteration: 4, average_reward: 59.44444444444444

Policy train: iteration: 500, policy_loss: 0.127935
Policy train: iteration: 1000, policy_loss: 0.279274
Policy train: iteration: 1500, policy_loss: 0.165830
Policy train: iteration: 2000, policy_loss: 0.218892
Policy train: iteration: 2500, policy_loss: 0.183605
Policy train: iteration: 3000, policy_loss: 0.256428
Policy train: iteration: 3500, policy_loss: 0.218349
Policy train: iteration: 4000, policy_loss: 0.196196

Background Trial: 1, reward: 80.0
Background Trial: 2, reward: 183.0
Background Trial: 3, reward: 156.0
Background Trial: 4, reward: 166.0
Background Trial: 5, reward: 163.0
Background Trial: 6, reward: 158.0
Background Trial: 7, reward: 147.0
Background Trial: 8, reward: 116.0
Background Trial: 9, reward: 170.0
Iteration: 5, average_reward: 148.77777777777777

Policy train: iteration: 500, policy_loss: 0.181073
Policy train: iteration: 1000, policy_loss: 0.206906
Policy train: iteration: 1500, policy_loss: 0.183733
Policy train: iteration: 2000, policy_loss: 0.268628
Policy train: iteration: 2500, policy_loss: 0.225902
Policy train: iteration: 3000, policy_loss: 0.211208
Policy train: iteration: 3500, policy_loss: 0.253700
Policy train: iteration: 4000, policy_loss: 0.151003

Background Trial: 1, reward: 124.0
Background Trial: 2, reward: 105.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 115.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 112.0
Background Trial: 7, reward: 149.0
Background Trial: 8, reward: 99.0
Background Trial: 9, reward: 191.0
Iteration: 6, average_reward: 143.88888888888889

Policy train: iteration: 500, policy_loss: 0.170290
Policy train: iteration: 1000, policy_loss: 0.117383
Policy train: iteration: 1500, policy_loss: 0.159844
Policy train: iteration: 2000, policy_loss: 0.183594
Policy train: iteration: 2500, policy_loss: 0.157407
Policy train: iteration: 3000, policy_loss: 0.195560
Policy train: iteration: 3500, policy_loss: 0.265101
Policy train: iteration: 4000, policy_loss: 0.165149

Background Trial: 1, reward: 80.0
Background Trial: 2, reward: 151.0
Background Trial: 3, reward: 83.0
Background Trial: 4, reward: 85.0
Background Trial: 5, reward: 80.0
Background Trial: 6, reward: 117.0
Background Trial: 7, reward: 135.0
Background Trial: 8, reward: 89.0
Background Trial: 9, reward: 112.0
Iteration: 7, average_reward: 103.55555555555556

Policy train: iteration: 500, policy_loss: 0.181592
Policy train: iteration: 1000, policy_loss: 0.173353
Policy train: iteration: 1500, policy_loss: 0.146469
Policy train: iteration: 2000, policy_loss: 0.180878
Policy train: iteration: 2500, policy_loss: 0.289463
Policy train: iteration: 3000, policy_loss: 0.201951
Policy train: iteration: 3500, policy_loss: 0.183623
Policy train: iteration: 4000, policy_loss: 0.123723

Background Trial: 1, reward: 80.0
Background Trial: 2, reward: 144.0
Background Trial: 3, reward: 133.0
Background Trial: 4, reward: 83.0
Background Trial: 5, reward: 33.0
Background Trial: 6, reward: 74.0
Background Trial: 7, reward: 92.0
Background Trial: 8, reward: 76.0
Background Trial: 9, reward: 162.0
Iteration: 8, average_reward: 97.44444444444444

Policy train: iteration: 500, policy_loss: 0.134135
Policy train: iteration: 1000, policy_loss: 0.198417
Policy train: iteration: 1500, policy_loss: 0.124960
Policy train: iteration: 2000, policy_loss: 0.101807
Policy train: iteration: 2500, policy_loss: 0.186118
Policy train: iteration: 3000, policy_loss: 0.128905
Policy train: iteration: 3500, policy_loss: 0.204143
Policy train: iteration: 4000, policy_loss: 0.183626

Background Trial: 1, reward: 75.0
Background Trial: 2, reward: 154.0
Background Trial: 3, reward: 110.0
Background Trial: 4, reward: 82.0
Background Trial: 5, reward: 78.0
Background Trial: 6, reward: 199.0
Background Trial: 7, reward: 73.0
Background Trial: 8, reward: 180.0
Background Trial: 9, reward: 160.0
Iteration: 9, average_reward: 123.44444444444444

Policy train: iteration: 500, policy_loss: 0.120495
Policy train: iteration: 1000, policy_loss: 0.225995
Policy train: iteration: 1500, policy_loss: 0.216337
Policy train: iteration: 2000, policy_loss: 0.155324
Policy train: iteration: 2500, policy_loss: 0.260886
Policy train: iteration: 3000, policy_loss: 0.213694
Policy train: iteration: 3500, policy_loss: 0.145356
Policy train: iteration: 4000, policy_loss: 0.144975

Background Trial: 1, reward: 53.0
Background Trial: 2, reward: 32.0
Background Trial: 3, reward: 155.0
Background Trial: 4, reward: 81.0
Background Trial: 5, reward: 29.0
Background Trial: 6, reward: 38.0
Background Trial: 7, reward: 34.0
Background Trial: 8, reward: 38.0
Background Trial: 9, reward: 91.0
Iteration: 10, average_reward: 61.22222222222222

Policy train: iteration: 500, policy_loss: 0.129494
Policy train: iteration: 1000, policy_loss: 0.177828
Policy train: iteration: 1500, policy_loss: 0.170438
Policy train: iteration: 2000, policy_loss: 0.166882
Policy train: iteration: 2500, policy_loss: 0.153382
Policy train: iteration: 3000, policy_loss: 0.149058
Policy train: iteration: 3500, policy_loss: 0.113514
Policy train: iteration: 4000, policy_loss: 0.223087

Background Trial: 1, reward: 68.0
Background Trial: 2, reward: 131.0
Background Trial: 3, reward: 127.0
Background Trial: 4, reward: 117.0
Background Trial: 5, reward: 152.0
Background Trial: 6, reward: 87.0
Background Trial: 7, reward: 122.0
Background Trial: 8, reward: 144.0
Background Trial: 9, reward: 157.0
Iteration: 11, average_reward: 122.77777777777777

Policy train: iteration: 500, policy_loss: 0.142853
Policy train: iteration: 1000, policy_loss: 0.198559
Policy train: iteration: 1500, policy_loss: 0.184093
Policy train: iteration: 2000, policy_loss: 0.199996
Policy train: iteration: 2500, policy_loss: 0.148630
Policy train: iteration: 3000, policy_loss: 0.168514
Policy train: iteration: 3500, policy_loss: 0.094347
Policy train: iteration: 4000, policy_loss: 0.151418

Background Trial: 1, reward: 126.0
Background Trial: 2, reward: 109.0
Background Trial: 3, reward: 126.0
Background Trial: 4, reward: 92.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 86.0
Background Trial: 7, reward: 106.0
Background Trial: 8, reward: 143.0
Background Trial: 9, reward: 91.0
Iteration: 12, average_reward: 119.88888888888889

Policy train: iteration: 500, policy_loss: 0.160643
Policy train: iteration: 1000, policy_loss: 0.253663
Policy train: iteration: 1500, policy_loss: 0.300412
Policy train: iteration: 2000, policy_loss: 0.134251
Policy train: iteration: 2500, policy_loss: 0.195357
Policy train: iteration: 3000, policy_loss: 0.142679
Policy train: iteration: 3500, policy_loss: 0.119576
Policy train: iteration: 4000, policy_loss: 0.162389

Background Trial: 1, reward: 156.0
Background Trial: 2, reward: 97.0
Background Trial: 3, reward: 91.0
Background Trial: 4, reward: 100.0
Background Trial: 5, reward: 137.0
Background Trial: 6, reward: 111.0
Background Trial: 7, reward: 101.0
Background Trial: 8, reward: 127.0
Background Trial: 9, reward: 157.0
Iteration: 13, average_reward: 119.66666666666667

Policy train: iteration: 500, policy_loss: 0.102377
Policy train: iteration: 1000, policy_loss: 0.157263
Policy train: iteration: 1500, policy_loss: 0.077976
Policy train: iteration: 2000, policy_loss: 0.125872
Policy train: iteration: 2500, policy_loss: 0.166466
Policy train: iteration: 3000, policy_loss: 0.144704
Policy train: iteration: 3500, policy_loss: 0.136812
Policy train: iteration: 4000, policy_loss: 0.169381

Background Trial: 1, reward: 103.0
Background Trial: 2, reward: 28.0
Background Trial: 3, reward: 36.0
Background Trial: 4, reward: 72.0
Background Trial: 5, reward: 25.0
Background Trial: 6, reward: 74.0
Background Trial: 7, reward: 87.0
Background Trial: 8, reward: 28.0
Background Trial: 9, reward: 75.0
Iteration: 14, average_reward: 58.666666666666664

Policy train: iteration: 500, policy_loss: 0.202127
Policy train: iteration: 1000, policy_loss: 0.162549
Policy train: iteration: 1500, policy_loss: 0.136046
Policy train: iteration: 2000, policy_loss: 0.127755
Policy train: iteration: 2500, policy_loss: 0.167044
Policy train: iteration: 3000, policy_loss: 0.145403
Policy train: iteration: 3500, policy_loss: 0.172355
Policy train: iteration: 4000, policy_loss: 0.157689

Background Trial: 1, reward: 29.0
Background Trial: 2, reward: 131.0
Background Trial: 3, reward: 112.0
Background Trial: 4, reward: 69.0
Background Trial: 5, reward: 32.0
Background Trial: 6, reward: 32.0
Background Trial: 7, reward: 81.0
Background Trial: 8, reward: 120.0
Background Trial: 9, reward: 139.0
Iteration: 15, average_reward: 82.77777777777777

Policy train: iteration: 500, policy_loss: 0.098170
Policy train: iteration: 1000, policy_loss: 0.158228
Policy train: iteration: 1500, policy_loss: 0.146496
Policy train: iteration: 2000, policy_loss: 0.210234
Policy train: iteration: 2500, policy_loss: 0.183023
Policy train: iteration: 3000, policy_loss: 0.130101
Policy train: iteration: 3500, policy_loss: 0.114069
Policy train: iteration: 4000, policy_loss: 0.181184

Background Trial: 1, reward: 106.0
Background Trial: 2, reward: 62.0
Background Trial: 3, reward: 72.0
Background Trial: 4, reward: 62.0
Background Trial: 5, reward: 29.0
Background Trial: 6, reward: 156.0
Background Trial: 7, reward: 33.0
Background Trial: 8, reward: 63.0
Background Trial: 9, reward: 15.0
Iteration: 16, average_reward: 66.44444444444444

Policy train: iteration: 500, policy_loss: 0.146330
Policy train: iteration: 1000, policy_loss: 0.201639
Policy train: iteration: 1500, policy_loss: 0.148458
Policy train: iteration: 2000, policy_loss: 0.190066
Policy train: iteration: 2500, policy_loss: 0.121628
Policy train: iteration: 3000, policy_loss: 0.131622
Policy train: iteration: 3500, policy_loss: 0.152683
Policy train: iteration: 4000, policy_loss: 0.223642

Background Trial: 1, reward: 69.0
Background Trial: 2, reward: 149.0
Background Trial: 3, reward: 84.0
Background Trial: 4, reward: 119.0
Background Trial: 5, reward: 79.0
Background Trial: 6, reward: 66.0
Background Trial: 7, reward: 31.0
Background Trial: 8, reward: 75.0
Background Trial: 9, reward: 32.0
Iteration: 17, average_reward: 78.22222222222223

Policy train: iteration: 500, policy_loss: 0.118029
Policy train: iteration: 1000, policy_loss: 0.181338
Policy train: iteration: 1500, policy_loss: 0.175922
Policy train: iteration: 2000, policy_loss: 0.126978
Policy train: iteration: 2500, policy_loss: 0.144468
Policy train: iteration: 3000, policy_loss: 0.254071
Policy train: iteration: 3500, policy_loss: 0.095752
Policy train: iteration: 4000, policy_loss: 0.160178

Background Trial: 1, reward: 64.0
Background Trial: 2, reward: 127.0
Background Trial: 3, reward: 114.0
Background Trial: 4, reward: 113.0
Background Trial: 5, reward: 64.0
Background Trial: 6, reward: 75.0
Background Trial: 7, reward: 146.0
Background Trial: 8, reward: 125.0
Background Trial: 9, reward: 104.0
Iteration: 18, average_reward: 103.55555555555556

Policy train: iteration: 500, policy_loss: 0.168296
Policy train: iteration: 1000, policy_loss: 0.098125
Policy train: iteration: 1500, policy_loss: 0.137993
Policy train: iteration: 2000, policy_loss: 0.188861
Policy train: iteration: 2500, policy_loss: 0.112842
Policy train: iteration: 3000, policy_loss: 0.128242
Policy train: iteration: 3500, policy_loss: 0.173893
Policy train: iteration: 4000, policy_loss: 0.117671

Background Trial: 1, reward: 196.0
Background Trial: 2, reward: 139.0
Background Trial: 3, reward: 119.0
Background Trial: 4, reward: 105.0
Background Trial: 5, reward: 81.0
Background Trial: 6, reward: 146.0
Background Trial: 7, reward: 130.0
Background Trial: 8, reward: 149.0
Background Trial: 9, reward: 144.0
Iteration: 19, average_reward: 134.33333333333334

Policy train: iteration: 500, policy_loss: 0.175003
Policy train: iteration: 1000, policy_loss: 0.164408
Policy train: iteration: 1500, policy_loss: 0.195500
Policy train: iteration: 2000, policy_loss: 0.127492
Policy train: iteration: 2500, policy_loss: 0.152155
Policy train: iteration: 3000, policy_loss: 0.152853
Policy train: iteration: 3500, policy_loss: 0.146863
Policy train: iteration: 4000, policy_loss: 0.137864

Background Trial: 1, reward: 83.0
Background Trial: 2, reward: 161.0
Background Trial: 3, reward: 70.0
Background Trial: 4, reward: 93.0
Background Trial: 5, reward: 137.0
Background Trial: 6, reward: 85.0
Background Trial: 7, reward: 171.0
Background Trial: 8, reward: 147.0
Background Trial: 9, reward: 136.0
Iteration: 20, average_reward: 120.33333333333333

Policy train: iteration: 500, policy_loss: 0.157339
Policy train: iteration: 1000, policy_loss: 0.141484
Policy train: iteration: 1500, policy_loss: 0.165924
Policy train: iteration: 2000, policy_loss: 0.120221
Policy train: iteration: 2500, policy_loss: 0.073409
Policy train: iteration: 3000, policy_loss: 0.129906
Policy train: iteration: 3500, policy_loss: 0.109649
Policy train: iteration: 4000, policy_loss: 0.121954

Background Trial: 1, reward: 76.0
Background Trial: 2, reward: 96.0
Background Trial: 3, reward: 118.0
Background Trial: 4, reward: 90.0
Background Trial: 5, reward: 95.0
Background Trial: 6, reward: 62.0
Background Trial: 7, reward: 128.0
Background Trial: 8, reward: 112.0
Background Trial: 9, reward: 28.0
Iteration: 21, average_reward: 89.44444444444444

Policy train: iteration: 500, policy_loss: 0.106502
Policy train: iteration: 1000, policy_loss: 0.127930
Policy train: iteration: 1500, policy_loss: 0.106583
Policy train: iteration: 2000, policy_loss: 0.131850
Policy train: iteration: 2500, policy_loss: 0.127602
Policy train: iteration: 3000, policy_loss: 0.186415
Policy train: iteration: 3500, policy_loss: 0.113772
Policy train: iteration: 4000, policy_loss: 0.127613

Background Trial: 1, reward: 155.0
Background Trial: 2, reward: 155.0
Background Trial: 3, reward: 172.0
Background Trial: 4, reward: 170.0
Background Trial: 5, reward: 173.0
Background Trial: 6, reward: 152.0
Background Trial: 7, reward: 160.0
Background Trial: 8, reward: 123.0
Background Trial: 9, reward: 157.0
Iteration: 22, average_reward: 157.44444444444446

Policy train: iteration: 500, policy_loss: 0.189676
Policy train: iteration: 1000, policy_loss: 0.181360
Policy train: iteration: 1500, policy_loss: 0.114561
Policy train: iteration: 2000, policy_loss: 0.101086
Policy train: iteration: 2500, policy_loss: 0.097102
Policy train: iteration: 3000, policy_loss: 0.184863
Policy train: iteration: 3500, policy_loss: 0.086791
Policy train: iteration: 4000, policy_loss: 0.138976

Background Trial: 1, reward: 128.0
Background Trial: 2, reward: 149.0
Background Trial: 3, reward: 126.0
Background Trial: 4, reward: 103.0
Background Trial: 5, reward: 149.0
Background Trial: 6, reward: 109.0
Background Trial: 7, reward: 198.0
Background Trial: 8, reward: 94.0
Background Trial: 9, reward: 159.0
Iteration: 23, average_reward: 135.0

Policy train: iteration: 500, policy_loss: 0.148660
Policy train: iteration: 1000, policy_loss: 0.198437
Policy train: iteration: 1500, policy_loss: 0.142790
Policy train: iteration: 2000, policy_loss: 0.163948
Policy train: iteration: 2500, policy_loss: 0.175426
Policy train: iteration: 3000, policy_loss: 0.168746
Policy train: iteration: 3500, policy_loss: 0.109326
Policy train: iteration: 4000, policy_loss: 0.186689

Background Trial: 1, reward: 133.0
Background Trial: 2, reward: 108.0
Background Trial: 3, reward: 103.0
Background Trial: 4, reward: 145.0
Background Trial: 5, reward: 95.0
Background Trial: 6, reward: 129.0
Background Trial: 7, reward: 100.0
Background Trial: 8, reward: 62.0
Background Trial: 9, reward: 58.0
Iteration: 24, average_reward: 103.66666666666667

Policy train: iteration: 500, policy_loss: 0.130449
Policy train: iteration: 1000, policy_loss: 0.050446
Policy train: iteration: 1500, policy_loss: 0.122131
Policy train: iteration: 2000, policy_loss: 0.127918
Policy train: iteration: 2500, policy_loss: 0.099371
Policy train: iteration: 3000, policy_loss: 0.142446
Policy train: iteration: 3500, policy_loss: 0.144148
Policy train: iteration: 4000, policy_loss: 0.140565

Background Trial: 1, reward: 96.0
Background Trial: 2, reward: 87.0
Background Trial: 3, reward: 100.0
Background Trial: 4, reward: 58.0
Background Trial: 5, reward: 58.0
Background Trial: 6, reward: 36.0
Background Trial: 7, reward: 29.0
Background Trial: 8, reward: 85.0
Background Trial: 9, reward: 97.0
Iteration: 25, average_reward: 71.77777777777777

Policy train: iteration: 500, policy_loss: 0.108803
Policy train: iteration: 1000, policy_loss: 0.120901
Policy train: iteration: 1500, policy_loss: 0.141611
Policy train: iteration: 2000, policy_loss: 0.130314
Policy train: iteration: 2500, policy_loss: 0.148012
Policy train: iteration: 3000, policy_loss: 0.079459
Policy train: iteration: 3500, policy_loss: 0.194522
Policy train: iteration: 4000, policy_loss: 0.220394

Background Trial: 1, reward: 145.0
Background Trial: 2, reward: 75.0
Background Trial: 3, reward: 80.0
Background Trial: 4, reward: 190.0
Background Trial: 5, reward: 139.0
Background Trial: 6, reward: 131.0
Background Trial: 7, reward: 127.0
Background Trial: 8, reward: 125.0
Background Trial: 9, reward: 85.0
Iteration: 26, average_reward: 121.88888888888889

Policy train: iteration: 500, policy_loss: 0.130040
Policy train: iteration: 1000, policy_loss: 0.106277
Policy train: iteration: 1500, policy_loss: 0.129806
Policy train: iteration: 2000, policy_loss: 0.115446
Policy train: iteration: 2500, policy_loss: 0.128548
Policy train: iteration: 3000, policy_loss: 0.141180
Policy train: iteration: 3500, policy_loss: 0.144104
Policy train: iteration: 4000, policy_loss: 0.125239

Background Trial: 1, reward: 140.0
Background Trial: 2, reward: 101.0
Background Trial: 3, reward: 148.0
Background Trial: 4, reward: 103.0
Background Trial: 5, reward: 147.0
Background Trial: 6, reward: 92.0
Background Trial: 7, reward: 149.0
Background Trial: 8, reward: 96.0
Background Trial: 9, reward: 151.0
Iteration: 27, average_reward: 125.22222222222223

Policy train: iteration: 500, policy_loss: 0.146576
Policy train: iteration: 1000, policy_loss: 0.161843
Policy train: iteration: 1500, policy_loss: 0.100448
Policy train: iteration: 2000, policy_loss: 0.105303
Policy train: iteration: 2500, policy_loss: 0.106051
Policy train: iteration: 3000, policy_loss: 0.139032
Policy train: iteration: 3500, policy_loss: 0.092398
Policy train: iteration: 4000, policy_loss: 0.101646

Background Trial: 1, reward: 152.0
Background Trial: 2, reward: 109.0
Background Trial: 3, reward: 78.0
Background Trial: 4, reward: 99.0
Background Trial: 5, reward: 159.0
Background Trial: 6, reward: 90.0
Background Trial: 7, reward: 31.0
Background Trial: 8, reward: 32.0
Background Trial: 9, reward: 94.0
Iteration: 28, average_reward: 93.77777777777777

Policy train: iteration: 500, policy_loss: 0.225443
Policy train: iteration: 1000, policy_loss: 0.197695
Policy train: iteration: 1500, policy_loss: 0.164371
Policy train: iteration: 2000, policy_loss: 0.084249
Policy train: iteration: 2500, policy_loss: 0.121339
Policy train: iteration: 3000, policy_loss: 0.170034
Policy train: iteration: 3500, policy_loss: 0.149714
Policy train: iteration: 4000, policy_loss: 0.166037

Background Trial: 1, reward: 108.0
Background Trial: 2, reward: 148.0
Background Trial: 3, reward: 137.0
Background Trial: 4, reward: 90.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 126.0
Background Trial: 7, reward: 96.0
Background Trial: 8, reward: 85.0
Background Trial: 9, reward: 135.0
Iteration: 29, average_reward: 125.0

Policy train: iteration: 500, policy_loss: 0.103957
Policy train: iteration: 1000, policy_loss: 0.143711
Policy train: iteration: 1500, policy_loss: 0.087753
Policy train: iteration: 2000, policy_loss: 0.117200
Policy train: iteration: 2500, policy_loss: 0.157209
Policy train: iteration: 3000, policy_loss: 0.101621
Policy train: iteration: 3500, policy_loss: 0.130755
Policy train: iteration: 4000, policy_loss: 0.091516

Background Trial: 1, reward: 163.0
Background Trial: 2, reward: 142.0
Background Trial: 3, reward: 86.0
Background Trial: 4, reward: 140.0
Background Trial: 5, reward: 149.0
Background Trial: 6, reward: 112.0
Background Trial: 7, reward: 122.0
Background Trial: 8, reward: 137.0
Background Trial: 9, reward: 113.0
Iteration: 30, average_reward: 129.33333333333334

Policy train: iteration: 500, policy_loss: 0.062118
Policy train: iteration: 1000, policy_loss: 0.093591
Policy train: iteration: 1500, policy_loss: 0.081407
Policy train: iteration: 2000, policy_loss: 0.135444
Policy train: iteration: 2500, policy_loss: 0.091646
Policy train: iteration: 3000, policy_loss: 0.201410
Policy train: iteration: 3500, policy_loss: 0.083009
Policy train: iteration: 4000, policy_loss: 0.093080

Background Trial: 1, reward: 98.0
Background Trial: 2, reward: 197.0
Background Trial: 3, reward: 100.0
Background Trial: 4, reward: 164.0
Background Trial: 5, reward: 161.0
Background Trial: 6, reward: 181.0
Background Trial: 7, reward: 166.0
Background Trial: 8, reward: 176.0
Background Trial: 9, reward: 168.0
Iteration: 31, average_reward: 156.77777777777777

Policy train: iteration: 500, policy_loss: 0.084609
Policy train: iteration: 1000, policy_loss: 0.099231
Policy train: iteration: 1500, policy_loss: 0.101529
Policy train: iteration: 2000, policy_loss: 0.112962
Policy train: iteration: 2500, policy_loss: 0.109543
Policy train: iteration: 3000, policy_loss: 0.134344
Policy train: iteration: 3500, policy_loss: 0.106969
Policy train: iteration: 4000, policy_loss: 0.061404

Background Trial: 1, reward: 164.0
Background Trial: 2, reward: 82.0
Background Trial: 3, reward: 143.0
Background Trial: 4, reward: 162.0
Background Trial: 5, reward: 143.0
Background Trial: 6, reward: 85.0
Background Trial: 7, reward: 133.0
Background Trial: 8, reward: 133.0
Background Trial: 9, reward: 106.0
Iteration: 32, average_reward: 127.88888888888889

Policy train: iteration: 500, policy_loss: 0.169106
Policy train: iteration: 1000, policy_loss: 0.142103
Policy train: iteration: 1500, policy_loss: 0.164484
Policy train: iteration: 2000, policy_loss: 0.139987
Policy train: iteration: 2500, policy_loss: 0.117860
Policy train: iteration: 3000, policy_loss: 0.096232
Policy train: iteration: 3500, policy_loss: 0.119710
Policy train: iteration: 4000, policy_loss: 0.094242

Background Trial: 1, reward: 85.0
Background Trial: 2, reward: 169.0
Background Trial: 3, reward: 98.0
Background Trial: 4, reward: 86.0
Background Trial: 5, reward: 169.0
Background Trial: 6, reward: 94.0
Background Trial: 7, reward: 181.0
Background Trial: 8, reward: 82.0
Background Trial: 9, reward: 153.0
Iteration: 33, average_reward: 124.11111111111111

Policy train: iteration: 500, policy_loss: 0.099303
Policy train: iteration: 1000, policy_loss: 0.138097
Policy train: iteration: 1500, policy_loss: 0.142662
Policy train: iteration: 2000, policy_loss: 0.086795
Policy train: iteration: 2500, policy_loss: 0.130399
Policy train: iteration: 3000, policy_loss: 0.130808
Policy train: iteration: 3500, policy_loss: 0.121827
Policy train: iteration: 4000, policy_loss: 0.138766

Background Trial: 1, reward: 75.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 124.0
Background Trial: 4, reward: 141.0
Background Trial: 5, reward: 166.0
Background Trial: 6, reward: 138.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 61.0
Background Trial: 9, reward: 174.0
Iteration: 34, average_reward: 142.11111111111111

Policy train: iteration: 500, policy_loss: 0.109207
Policy train: iteration: 1000, policy_loss: 0.077058
Policy train: iteration: 1500, policy_loss: 0.084784
Policy train: iteration: 2000, policy_loss: 0.110073
Policy train: iteration: 2500, policy_loss: 0.074103
Policy train: iteration: 3000, policy_loss: 0.114768
Policy train: iteration: 3500, policy_loss: 0.108334
Policy train: iteration: 4000, policy_loss: 0.125847

Background Trial: 1, reward: 142.0
Background Trial: 2, reward: 140.0
Background Trial: 3, reward: 127.0
Background Trial: 4, reward: 187.0
Background Trial: 5, reward: 148.0
Background Trial: 6, reward: 161.0
Background Trial: 7, reward: 137.0
Background Trial: 8, reward: 131.0
Background Trial: 9, reward: 123.0
Iteration: 35, average_reward: 144.0

Policy train: iteration: 500, policy_loss: 0.167145
Policy train: iteration: 1000, policy_loss: 0.195928
Policy train: iteration: 1500, policy_loss: 0.092373
Policy train: iteration: 2000, policy_loss: 0.102550
Policy train: iteration: 2500, policy_loss: 0.098128
Policy train: iteration: 3000, policy_loss: 0.075747
Policy train: iteration: 3500, policy_loss: 0.114651
Policy train: iteration: 4000, policy_loss: 0.186298

Background Trial: 1, reward: 153.0
Background Trial: 2, reward: 135.0
Background Trial: 3, reward: 138.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 152.0
Background Trial: 6, reward: 97.0
Background Trial: 7, reward: 145.0
Background Trial: 8, reward: 138.0
Background Trial: 9, reward: 76.0
Iteration: 36, average_reward: 137.11111111111111

Policy train: iteration: 500, policy_loss: 0.123314
Policy train: iteration: 1000, policy_loss: 0.100563
Policy train: iteration: 1500, policy_loss: 0.168631
Policy train: iteration: 2000, policy_loss: 0.116782
Policy train: iteration: 2500, policy_loss: 0.108288
Policy train: iteration: 3000, policy_loss: 0.117011
Policy train: iteration: 3500, policy_loss: 0.077626
Policy train: iteration: 4000, policy_loss: 0.116839

Background Trial: 1, reward: 147.0
Background Trial: 2, reward: 75.0
Background Trial: 3, reward: 145.0
Background Trial: 4, reward: 190.0
Background Trial: 5, reward: 145.0
Background Trial: 6, reward: 146.0
Background Trial: 7, reward: 164.0
Background Trial: 8, reward: 153.0
Background Trial: 9, reward: 144.0
Iteration: 37, average_reward: 145.44444444444446

Policy train: iteration: 500, policy_loss: 0.053604
Policy train: iteration: 1000, policy_loss: 0.173350
Policy train: iteration: 1500, policy_loss: 0.082211
Policy train: iteration: 2000, policy_loss: 0.118896
Policy train: iteration: 2500, policy_loss: 0.144488
Policy train: iteration: 3000, policy_loss: 0.139292
Policy train: iteration: 3500, policy_loss: 0.150462
Policy train: iteration: 4000, policy_loss: 0.109018

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 68.0
Background Trial: 5, reward: 153.0
Background Trial: 6, reward: 147.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 146.0
Background Trial: 9, reward: 117.0
Iteration: 38, average_reward: 159.0

Policy train: iteration: 500, policy_loss: 0.161414
Policy train: iteration: 1000, policy_loss: 0.098008
Policy train: iteration: 1500, policy_loss: 0.096710
Policy train: iteration: 2000, policy_loss: 0.077170
Policy train: iteration: 2500, policy_loss: 0.090287
Policy train: iteration: 3000, policy_loss: 0.163993
Policy train: iteration: 3500, policy_loss: 0.099978
Policy train: iteration: 4000, policy_loss: 0.094667

Background Trial: 1, reward: 141.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 86.0
Background Trial: 4, reward: 150.0
Background Trial: 5, reward: 168.0
Background Trial: 6, reward: 152.0
Background Trial: 7, reward: 84.0
Background Trial: 8, reward: 163.0
Background Trial: 9, reward: 113.0
Iteration: 39, average_reward: 139.66666666666666

Policy train: iteration: 500, policy_loss: 0.144117
Policy train: iteration: 1000, policy_loss: 0.103574
Policy train: iteration: 1500, policy_loss: 0.107571
Policy train: iteration: 2000, policy_loss: 0.147176
Policy train: iteration: 2500, policy_loss: 0.143442
Policy train: iteration: 3000, policy_loss: 0.089499
Policy train: iteration: 3500, policy_loss: 0.083329
Policy train: iteration: 4000, policy_loss: 0.178994

Background Trial: 1, reward: 135.0
Background Trial: 2, reward: 118.0
Background Trial: 3, reward: 149.0
Background Trial: 4, reward: 164.0
Background Trial: 5, reward: 152.0
Background Trial: 6, reward: 129.0
Background Trial: 7, reward: 156.0
Background Trial: 8, reward: 130.0
Background Trial: 9, reward: 86.0
Iteration: 40, average_reward: 135.44444444444446

Policy train: iteration: 500, policy_loss: 0.142052
Policy train: iteration: 1000, policy_loss: 0.095513
Policy train: iteration: 1500, policy_loss: 0.143809
Policy train: iteration: 2000, policy_loss: 0.115459
Policy train: iteration: 2500, policy_loss: 0.080102
Policy train: iteration: 3000, policy_loss: 0.120418
Policy train: iteration: 3500, policy_loss: 0.112985
Policy train: iteration: 4000, policy_loss: 0.147498

Background Trial: 1, reward: 130.0
Background Trial: 2, reward: 113.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 171.0
Background Trial: 6, reward: 197.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 166.0
Iteration: 41, average_reward: 175.22222222222223

Policy train: iteration: 500, policy_loss: 0.131069
Policy train: iteration: 1000, policy_loss: 0.064758
Policy train: iteration: 1500, policy_loss: 0.109790
Policy train: iteration: 2000, policy_loss: 0.120686
Policy train: iteration: 2500, policy_loss: 0.052029
Policy train: iteration: 3000, policy_loss: 0.082820
Policy train: iteration: 3500, policy_loss: 0.195611
Policy train: iteration: 4000, policy_loss: 0.107269

Background Trial: 1, reward: 198.0
Background Trial: 2, reward: 162.0
Background Trial: 3, reward: 161.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 193.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 165.0
Background Trial: 9, reward: 200.0
Iteration: 42, average_reward: 186.55555555555554

Policy train: iteration: 500, policy_loss: 0.068571
Policy train: iteration: 1000, policy_loss: 0.095952
Policy train: iteration: 1500, policy_loss: 0.095604
Policy train: iteration: 2000, policy_loss: 0.093705
Policy train: iteration: 2500, policy_loss: 0.093265
Policy train: iteration: 3000, policy_loss: 0.150051
Policy train: iteration: 3500, policy_loss: 0.094681
Policy train: iteration: 4000, policy_loss: 0.110436

Background Trial: 1, reward: 148.0
Background Trial: 2, reward: 187.0
Background Trial: 3, reward: 152.0
Background Trial: 4, reward: 91.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 84.0
Background Trial: 7, reward: 104.0
Background Trial: 8, reward: 138.0
Background Trial: 9, reward: 158.0
Iteration: 43, average_reward: 140.22222222222223

Policy train: iteration: 500, policy_loss: 0.102406
Policy train: iteration: 1000, policy_loss: 0.094409
Policy train: iteration: 1500, policy_loss: 0.137826
Policy train: iteration: 2000, policy_loss: 0.067253
Policy train: iteration: 2500, policy_loss: 0.081810
Policy train: iteration: 3000, policy_loss: 0.060333
Policy train: iteration: 3500, policy_loss: 0.067325
Policy train: iteration: 4000, policy_loss: 0.091854

Background Trial: 1, reward: 161.0
Background Trial: 2, reward: 157.0
Background Trial: 3, reward: 147.0
Background Trial: 4, reward: 73.0
Background Trial: 5, reward: 152.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 157.0
Background Trial: 8, reward: 148.0
Background Trial: 9, reward: 200.0
Iteration: 44, average_reward: 155.0

Policy train: iteration: 500, policy_loss: 0.078543
Policy train: iteration: 1000, policy_loss: 0.124574
Policy train: iteration: 1500, policy_loss: 0.146617
Policy train: iteration: 2000, policy_loss: 0.124239
Policy train: iteration: 2500, policy_loss: 0.069746
Policy train: iteration: 3000, policy_loss: 0.079697
Policy train: iteration: 3500, policy_loss: 0.049325
Policy train: iteration: 4000, policy_loss: 0.090535

Background Trial: 1, reward: 56.0
Background Trial: 2, reward: 41.0
Background Trial: 3, reward: 196.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 150.0
Background Trial: 6, reward: 155.0
Background Trial: 7, reward: 131.0
Background Trial: 8, reward: 188.0
Background Trial: 9, reward: 173.0
Iteration: 45, average_reward: 143.33333333333334

Policy train: iteration: 500, policy_loss: 0.104261
Policy train: iteration: 1000, policy_loss: 0.104751
Policy train: iteration: 1500, policy_loss: 0.141177
Policy train: iteration: 2000, policy_loss: 0.104506
Policy train: iteration: 2500, policy_loss: 0.060171
Policy train: iteration: 3000, policy_loss: 0.105212
Policy train: iteration: 3500, policy_loss: 0.066529
Policy train: iteration: 4000, policy_loss: 0.119770

Background Trial: 1, reward: 183.0
Background Trial: 2, reward: 139.0
Background Trial: 3, reward: 157.0
Background Trial: 4, reward: 165.0
Background Trial: 5, reward: 70.0
Background Trial: 6, reward: 102.0
Background Trial: 7, reward: 152.0
Background Trial: 8, reward: 70.0
Background Trial: 9, reward: 200.0
Iteration: 46, average_reward: 137.55555555555554

Policy train: iteration: 500, policy_loss: 0.089943
Policy train: iteration: 1000, policy_loss: 0.077722
Policy train: iteration: 1500, policy_loss: 0.119045
Policy train: iteration: 2000, policy_loss: 0.112713
Policy train: iteration: 2500, policy_loss: 0.107243
Policy train: iteration: 3000, policy_loss: 0.065823
Policy train: iteration: 3500, policy_loss: 0.108167
Policy train: iteration: 4000, policy_loss: 0.100056

Background Trial: 1, reward: 56.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 154.0
Background Trial: 4, reward: 160.0
Background Trial: 5, reward: 177.0
Background Trial: 6, reward: 162.0
Background Trial: 7, reward: 181.0
Background Trial: 8, reward: 81.0
Background Trial: 9, reward: 70.0
Iteration: 47, average_reward: 137.88888888888889

Policy train: iteration: 500, policy_loss: 0.078902
Policy train: iteration: 1000, policy_loss: 0.108621
Policy train: iteration: 1500, policy_loss: 0.065551
Policy train: iteration: 2000, policy_loss: 0.074886
Policy train: iteration: 2500, policy_loss: 0.060212
Policy train: iteration: 3000, policy_loss: 0.086808
Policy train: iteration: 3500, policy_loss: 0.134539
Policy train: iteration: 4000, policy_loss: 0.062471

Background Trial: 1, reward: 147.0
Background Trial: 2, reward: 106.0
Background Trial: 3, reward: 160.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 158.0
Background Trial: 6, reward: 68.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 150.0
Iteration: 48, average_reward: 154.33333333333334

Policy train: iteration: 500, policy_loss: 0.110037
Policy train: iteration: 1000, policy_loss: 0.135731
Policy train: iteration: 1500, policy_loss: 0.099199
Policy train: iteration: 2000, policy_loss: 0.096240
Policy train: iteration: 2500, policy_loss: 0.090874
Policy train: iteration: 3000, policy_loss: 0.033179
Policy train: iteration: 3500, policy_loss: 0.085117
Policy train: iteration: 4000, policy_loss: 0.097274

Background Trial: 1, reward: 68.0
Background Trial: 2, reward: 142.0
Background Trial: 3, reward: 170.0
Background Trial: 4, reward: 166.0
Background Trial: 5, reward: 170.0
Background Trial: 6, reward: 62.0
Background Trial: 7, reward: 151.0
Background Trial: 8, reward: 74.0
Background Trial: 9, reward: 157.0
Iteration: 49, average_reward: 128.88888888888889

Policy train: iteration: 500, policy_loss: 0.095681
Policy train: iteration: 1000, policy_loss: 0.074621
Policy train: iteration: 1500, policy_loss: 0.086947
Policy train: iteration: 2000, policy_loss: 0.073475
Policy train: iteration: 2500, policy_loss: 0.072998
Policy train: iteration: 3000, policy_loss: 0.097374
Policy train: iteration: 3500, policy_loss: 0.094492
Policy train: iteration: 4000, policy_loss: 0.103757

Background Trial: 1, reward: 25.0
Background Trial: 2, reward: 64.0
Background Trial: 3, reward: 20.0
Background Trial: 4, reward: 54.0
Background Trial: 5, reward: 87.0
Background Trial: 6, reward: 94.0
Background Trial: 7, reward: 29.0
Background Trial: 8, reward: 100.0
Background Trial: 9, reward: 102.0
Iteration: 50, average_reward: 63.888888888888886

