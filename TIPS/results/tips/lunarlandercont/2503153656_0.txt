Policy train: iteration: 500, policy_loss: 0.311393
Policy train: iteration: 1000, policy_loss: 0.262968
Policy train: iteration: 1500, policy_loss: 0.198463
Policy train: iteration: 2000, policy_loss: 0.195986
Policy train: iteration: 2500, policy_loss: 0.274647
Policy train: iteration: 3000, policy_loss: 0.171814
Policy train: iteration: 3500, policy_loss: 0.202757
Policy train: iteration: 4000, policy_loss: 0.211772
Policy train: iteration: 4500, policy_loss: 0.172188
Policy train: iteration: 5000, policy_loss: 0.227140
Policy train: iteration: 5500, policy_loss: 0.200363
Policy train: iteration: 6000, policy_loss: 0.173848
Policy train: iteration: 6500, policy_loss: 0.217629
Policy train: iteration: 7000, policy_loss: 0.172238
Policy train: iteration: 7500, policy_loss: 0.164444
Policy train: iteration: 8000, policy_loss: 0.185885
Policy train: iteration: 8500, policy_loss: 0.154485
Policy train: iteration: 9000, policy_loss: 0.172483
Policy train: iteration: 9500, policy_loss: 0.181975
Policy train: iteration: 10000, policy_loss: 0.209731
Policy train: iteration: 10500, policy_loss: 0.189174
Policy train: iteration: 11000, policy_loss: 0.183093
Policy train: iteration: 11500, policy_loss: 0.178521
Policy train: iteration: 12000, policy_loss: 0.148266
Policy train: iteration: 12500, policy_loss: 0.142221
Policy train: iteration: 13000, policy_loss: 0.195352
Policy train: iteration: 13500, policy_loss: 0.167915
Policy train: iteration: 14000, policy_loss: 0.193214
Policy train: iteration: 14500, policy_loss: 0.156919
Policy train: iteration: 15000, policy_loss: 0.214264
Policy train: iteration: 15500, policy_loss: 0.145730
Policy train: iteration: 16000, policy_loss: 0.168245
Policy train: iteration: 16500, policy_loss: 0.151689
Policy train: iteration: 17000, policy_loss: 0.190510
Policy train: iteration: 17500, policy_loss: 0.169226
Policy train: iteration: 18000, policy_loss: 0.159924
Policy train: iteration: 18500, policy_loss: 0.170125
Policy train: iteration: 19000, policy_loss: 0.160436
Policy train: iteration: 19500, policy_loss: 0.181607
Policy train: iteration: 20000, policy_loss: 0.158153
Policy train: iteration: 20500, policy_loss: 0.159637
Policy train: iteration: 21000, policy_loss: 0.175848
Policy train: iteration: 21500, policy_loss: 0.183583
Policy train: iteration: 22000, policy_loss: 0.185327
Policy train: iteration: 22500, policy_loss: 0.151689
Policy train: iteration: 23000, policy_loss: 0.162042
Policy train: iteration: 23500, policy_loss: 0.137459
Policy train: iteration: 24000, policy_loss: 0.132015
Policy train: iteration: 24500, policy_loss: 0.132362
Policy train: iteration: 25000, policy_loss: 0.130853
Policy train: iteration: 25500, policy_loss: 0.142609
Policy train: iteration: 26000, policy_loss: 0.143025
Policy train: iteration: 26500, policy_loss: 0.145254
Policy train: iteration: 27000, policy_loss: 0.160425
Policy train: iteration: 27500, policy_loss: 0.124320
Policy train: iteration: 28000, policy_loss: 0.174872
Policy train: iteration: 28500, policy_loss: 0.139646
Policy train: iteration: 29000, policy_loss: 0.142979
Policy train: iteration: 29500, policy_loss: 0.151378
Policy train: iteration: 30000, policy_loss: 0.145121
Policy train: iteration: 30500, policy_loss: 0.163114
Policy train: iteration: 31000, policy_loss: 0.156048
Policy train: iteration: 31500, policy_loss: 0.127540
Policy train: iteration: 32000, policy_loss: 0.128246
Policy train: iteration: 32500, policy_loss: 0.155350
Policy train: iteration: 33000, policy_loss: 0.115026
