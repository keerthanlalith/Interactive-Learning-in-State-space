Collecting idm training data 1000
Collecting idm training data 2000
Collecting idm training data 3000
Collecting idm training data 4000
Collecting idm training data 5000
Collecting idm training data 6000
Collecting idm training data 7000
Collecting idm training data 8000
Collecting idm training data 9000
Collecting idm training data 10000
Collecting idm training data 11000
Collecting idm training data 12000
Collecting idm training data 13000
Collecting idm training data 14000
Collecting idm training data 15000
Collecting idm training data 16000
Collecting idm training data 17000
Collecting idm training data 18000
Collecting idm training data 19000
Collecting idm training data 20000
Collecting idm training data 21000
Collecting idm training data 22000
Collecting idm training data 23000
Collecting idm training data 24000
Collecting idm training data 25000
Collecting idm training data 26000
Collecting idm training data 27000
Collecting idm training data 28000
Collecting idm training data 29000
Collecting idm training data 30000
Collecting idm training data 31000
Collecting idm training data 32000
Collecting idm training data 33000
Collecting idm training data 34000
Collecting idm training data 35000
Collecting idm training data 36000
Collecting idm training data 37000
Collecting idm training data 38000
Collecting idm training data 39000
Collecting idm training data 40000
Collecting idm training data 41000
Collecting idm training data 42000
Collecting idm training data 43000
Collecting idm training data 44000
Collecting idm training data 45000
Collecting idm training data 46000
Collecting idm training data 47000
Collecting idm training data 48000
Collecting idm training data 49000
Collecting idm training data 50000
IDM train: iteration: 500, idm_loss: 0.16505808
IDM train: iteration: 1000, idm_loss: 0.17926121
IDM train: iteration: 1500, idm_loss: 0.18458009
IDM train: iteration: 2000, idm_loss: 0.1761624
IDM train: iteration: 2500, idm_loss: 0.15113568
IDM train: iteration: 3000, idm_loss: 0.16655636
IDM train: iteration: 3500, idm_loss: 0.14421031
IDM train: iteration: 4000, idm_loss: 0.17865509
IDM train: iteration: 4500, idm_loss: 0.1875984
IDM train: iteration: 5000, idm_loss: 0.15260504
IDM train: iteration: 5500, idm_loss: 0.13461167
IDM train: iteration: 6000, idm_loss: 0.13183817
IDM train: iteration: 6500, idm_loss: 0.13054596
IDM train: iteration: 7000, idm_loss: 0.16961205
IDM train: iteration: 7500, idm_loss: 0.13433197
IDM train: iteration: 8000, idm_loss: 0.10056951
IDM train: iteration: 8500, idm_loss: 0.12642604
IDM train: iteration: 9000, idm_loss: 0.13309747
IDM train: iteration: 9500, idm_loss: 0.14439708
IDM train: iteration: 10000, idm_loss: 0.087064356
Policy train: iteration: 500, policy_loss: 0.13673724
Policy train: iteration: 1000, policy_loss: 0.086294845
Policy train: iteration: 1500, policy_loss: 0.0749758
Policy train: iteration: 2000, policy_loss: 0.06295371
Policy train: iteration: 2500, policy_loss: 0.06601815
Policy train: iteration: 3000, policy_loss: 0.09194644
Policy train: iteration: 3500, policy_loss: 0.039206848
Policy train: iteration: 4000, policy_loss: 0.056843754
Policy train: iteration: 4500, policy_loss: 0.079034254
Policy train: iteration: 5000, policy_loss: 0.057674583
Policy train: iteration: 5500, policy_loss: 0.04953969
Policy train: iteration: 6000, policy_loss: 0.051302213
Policy train: iteration: 6500, policy_loss: 0.056573294
Policy train: iteration: 7000, policy_loss: 0.03155245
Policy train: iteration: 7500, policy_loss: 0.052264374
Policy train: iteration: 8000, policy_loss: 0.059120554
Policy train: iteration: 8500, policy_loss: 0.035188686
Policy train: iteration: 9000, policy_loss: 0.040993057
Policy train: iteration: 9500, policy_loss: 0.040197607
Policy train: iteration: 10000, policy_loss: 0.05076677
IDM train: iteration: 500, idm_loss: 0.1350393
IDM train: iteration: 1000, idm_loss: 0.1444493
IDM train: iteration: 1500, idm_loss: 0.124124855
IDM train: iteration: 2000, idm_loss: 0.106041536
IDM train: iteration: 2500, idm_loss: 0.107188195
IDM train: iteration: 3000, idm_loss: 0.10734063
IDM train: iteration: 3500, idm_loss: 0.14745021
IDM train: iteration: 4000, idm_loss: 0.12796617
IDM train: iteration: 4500, idm_loss: 0.11475366
IDM train: iteration: 5000, idm_loss: 0.110861376
IDM train: iteration: 5500, idm_loss: 0.13824716
IDM train: iteration: 6000, idm_loss: 0.09698446
IDM train: iteration: 6500, idm_loss: 0.13615112
IDM train: iteration: 7000, idm_loss: 0.12974928
IDM train: iteration: 7500, idm_loss: 0.14385095
IDM train: iteration: 8000, idm_loss: 0.11011823
IDM train: iteration: 8500, idm_loss: 0.11234715
IDM train: iteration: 9000, idm_loss: 0.11585851
IDM train: iteration: 9500, idm_loss: 0.12919867
IDM train: iteration: 10000, idm_loss: 0.12266595

iteration: 1, total_reward: -22.029836850971538, policy_loss: 0.09002128, idm_loss: 0.056402985

Policy train: iteration: 500, policy_loss: 0.04121071
Policy train: iteration: 1000, policy_loss: 0.04858304
Policy train: iteration: 1500, policy_loss: 0.043493494
Policy train: iteration: 2000, policy_loss: 0.038421884
Policy train: iteration: 2500, policy_loss: 0.041539088
Policy train: iteration: 3000, policy_loss: 0.039473116
Policy train: iteration: 3500, policy_loss: 0.026790341
Policy train: iteration: 4000, policy_loss: 0.04343886
Policy train: iteration: 4500, policy_loss: 0.029123833
Policy train: iteration: 5000, policy_loss: 0.044669047
Policy train: iteration: 5500, policy_loss: 0.035643637
Policy train: iteration: 6000, policy_loss: 0.049361322
Policy train: iteration: 6500, policy_loss: 0.0361946
Policy train: iteration: 7000, policy_loss: 0.05267055
Policy train: iteration: 7500, policy_loss: 0.050056793
Policy train: iteration: 8000, policy_loss: 0.028616562
Policy train: iteration: 8500, policy_loss: 0.03523229
Policy train: iteration: 9000, policy_loss: 0.038425103
Policy train: iteration: 9500, policy_loss: 0.03458357
Policy train: iteration: 10000, policy_loss: 0.0457754
IDM train: iteration: 500, idm_loss: 0.09166461
IDM train: iteration: 1000, idm_loss: 0.096194535
IDM train: iteration: 1500, idm_loss: 0.16646507
IDM train: iteration: 2000, idm_loss: 0.111741945
IDM train: iteration: 2500, idm_loss: 0.09586126
IDM train: iteration: 3000, idm_loss: 0.11395885
IDM train: iteration: 3500, idm_loss: 0.11874466
IDM train: iteration: 4000, idm_loss: 0.12606075
IDM train: iteration: 4500, idm_loss: 0.11845728
IDM train: iteration: 5000, idm_loss: 0.098894805
IDM train: iteration: 5500, idm_loss: 0.132373
IDM train: iteration: 6000, idm_loss: 0.12759164
IDM train: iteration: 6500, idm_loss: 0.12787801
IDM train: iteration: 7000, idm_loss: 0.107255235
IDM train: iteration: 7500, idm_loss: 0.118337676
IDM train: iteration: 8000, idm_loss: 0.11006394
IDM train: iteration: 8500, idm_loss: 0.097303316
IDM train: iteration: 9000, idm_loss: 0.09926231
IDM train: iteration: 9500, idm_loss: 0.121820174
IDM train: iteration: 10000, idm_loss: 0.10677296

iteration: 2, total_reward: -78.12702584458172, policy_loss: 0.056544136, idm_loss: 0.05313087

Policy train: iteration: 500, policy_loss: 0.046375837
Policy train: iteration: 1000, policy_loss: 0.05151862
Policy train: iteration: 1500, policy_loss: 0.04651866
Policy train: iteration: 2000, policy_loss: 0.04696636
Policy train: iteration: 2500, policy_loss: 0.04759381
Policy train: iteration: 3000, policy_loss: 0.04186423
Policy train: iteration: 3500, policy_loss: 0.04442974
Policy train: iteration: 4000, policy_loss: 0.045459244
Policy train: iteration: 4500, policy_loss: 0.035058096
Policy train: iteration: 5000, policy_loss: 0.048779055
Policy train: iteration: 5500, policy_loss: 0.03265571
Policy train: iteration: 6000, policy_loss: 0.030998066
Policy train: iteration: 6500, policy_loss: 0.05009436
Policy train: iteration: 7000, policy_loss: 0.033125624
Policy train: iteration: 7500, policy_loss: 0.030967077
Policy train: iteration: 8000, policy_loss: 0.028405778
Policy train: iteration: 8500, policy_loss: 0.04043501
Policy train: iteration: 9000, policy_loss: 0.053469844
Policy train: iteration: 9500, policy_loss: 0.03367851
Policy train: iteration: 10000, policy_loss: 0.031997204
IDM train: iteration: 500, idm_loss: 0.15682471
IDM train: iteration: 1000, idm_loss: 0.09013839
IDM train: iteration: 1500, idm_loss: 0.1054839
IDM train: iteration: 2000, idm_loss: 0.11324635
IDM train: iteration: 2500, idm_loss: 0.07419488
IDM train: iteration: 3000, idm_loss: 0.116868764
IDM train: iteration: 3500, idm_loss: 0.090690784
IDM train: iteration: 4000, idm_loss: 0.12338197
IDM train: iteration: 4500, idm_loss: 0.08590858
IDM train: iteration: 5000, idm_loss: 0.098358616
IDM train: iteration: 5500, idm_loss: 0.092348434
IDM train: iteration: 6000, idm_loss: 0.11806925
IDM train: iteration: 6500, idm_loss: 0.10214777
IDM train: iteration: 7000, idm_loss: 0.081451274
IDM train: iteration: 7500, idm_loss: 0.10065631
IDM train: iteration: 8000, idm_loss: 0.09063627
IDM train: iteration: 8500, idm_loss: 0.11249088
IDM train: iteration: 9000, idm_loss: 0.08927002
IDM train: iteration: 9500, idm_loss: 0.15683652
IDM train: iteration: 10000, idm_loss: 0.11682393

iteration: 3, total_reward: -126.3084121743776, policy_loss: 0.05166112, idm_loss: 0.11189906

Policy train: iteration: 500, policy_loss: 0.036985178
Policy train: iteration: 1000, policy_loss: 0.029027052
Policy train: iteration: 1500, policy_loss: 0.049055144
Policy train: iteration: 2000, policy_loss: 0.03672587
Policy train: iteration: 2500, policy_loss: 0.029732667
Policy train: iteration: 3000, policy_loss: 0.024832472
Policy train: iteration: 3500, policy_loss: 0.031864874
Policy train: iteration: 4000, policy_loss: 0.03938763
Policy train: iteration: 4500, policy_loss: 0.024440559
Policy train: iteration: 5000, policy_loss: 0.031449758
Policy train: iteration: 5500, policy_loss: 0.05587438
Policy train: iteration: 6000, policy_loss: 0.028884578
Policy train: iteration: 6500, policy_loss: 0.03632819
Policy train: iteration: 7000, policy_loss: 0.030203957
Policy train: iteration: 7500, policy_loss: 0.039119482
Policy train: iteration: 8000, policy_loss: 0.018914703
Policy train: iteration: 8500, policy_loss: 0.03374233
Policy train: iteration: 9000, policy_loss: 0.03809578
Policy train: iteration: 9500, policy_loss: 0.02511138
Policy train: iteration: 10000, policy_loss: 0.02435973
IDM train: iteration: 500, idm_loss: 0.12316783
IDM train: iteration: 1000, idm_loss: 0.08891854
IDM train: iteration: 1500, idm_loss: 0.12763336
IDM train: iteration: 2000, idm_loss: 0.09704275
IDM train: iteration: 2500, idm_loss: 0.106998615
IDM train: iteration: 3000, idm_loss: 0.09679733
IDM train: iteration: 3500, idm_loss: 0.10942172
IDM train: iteration: 4000, idm_loss: 0.093607925
IDM train: iteration: 4500, idm_loss: 0.10283364
IDM train: iteration: 5000, idm_loss: 0.13686301
IDM train: iteration: 5500, idm_loss: 0.0861903
IDM train: iteration: 6000, idm_loss: 0.116805404
IDM train: iteration: 6500, idm_loss: 0.077981964
IDM train: iteration: 7000, idm_loss: 0.118422866
IDM train: iteration: 7500, idm_loss: 0.116124295
IDM train: iteration: 8000, idm_loss: 0.10775107
IDM train: iteration: 8500, idm_loss: 0.0900356
IDM train: iteration: 9000, idm_loss: 0.098895565
IDM train: iteration: 9500, idm_loss: 0.06723268
IDM train: iteration: 10000, idm_loss: 0.099731505

iteration: 4, total_reward: -122.2893905924037, policy_loss: 0.06666391, idm_loss: 0.080345124

Policy train: iteration: 500, policy_loss: 0.030022878
Policy train: iteration: 1000, policy_loss: 0.028207084
Policy train: iteration: 1500, policy_loss: 0.024927374
Policy train: iteration: 2000, policy_loss: 0.029061712
Policy train: iteration: 2500, policy_loss: 0.022521935
Policy train: iteration: 3000, policy_loss: 0.036288258
Policy train: iteration: 3500, policy_loss: 0.03615572
Policy train: iteration: 4000, policy_loss: 0.025795648
Policy train: iteration: 4500, policy_loss: 0.027388815
Policy train: iteration: 5000, policy_loss: 0.03982617
Policy train: iteration: 5500, policy_loss: 0.028046189
Policy train: iteration: 6000, policy_loss: 0.026893675
Policy train: iteration: 6500, policy_loss: 0.032870196
Policy train: iteration: 7000, policy_loss: 0.028403139
Policy train: iteration: 7500, policy_loss: 0.030161966
Policy train: iteration: 8000, policy_loss: 0.027118932
Policy train: iteration: 8500, policy_loss: 0.036509357
Policy train: iteration: 9000, policy_loss: 0.0202385
Policy train: iteration: 9500, policy_loss: 0.03797119
Policy train: iteration: 10000, policy_loss: 0.03590232
IDM train: iteration: 500, idm_loss: 0.10153049
IDM train: iteration: 1000, idm_loss: 0.09870862
IDM train: iteration: 1500, idm_loss: 0.08067094
IDM train: iteration: 2000, idm_loss: 0.10184845
IDM train: iteration: 2500, idm_loss: 0.09554385
IDM train: iteration: 3000, idm_loss: 0.11977316
IDM train: iteration: 3500, idm_loss: 0.085093275
IDM train: iteration: 4000, idm_loss: 0.10387173
IDM train: iteration: 4500, idm_loss: 0.11197357
IDM train: iteration: 5000, idm_loss: 0.13267758
IDM train: iteration: 5500, idm_loss: 0.09496125
IDM train: iteration: 6000, idm_loss: 0.09944339
IDM train: iteration: 6500, idm_loss: 0.08493213
IDM train: iteration: 7000, idm_loss: 0.081590295
IDM train: iteration: 7500, idm_loss: 0.0823101
IDM train: iteration: 8000, idm_loss: 0.114081636
IDM train: iteration: 8500, idm_loss: 0.11193888
IDM train: iteration: 9000, idm_loss: 0.12817675
IDM train: iteration: 9500, idm_loss: 0.13509086
IDM train: iteration: 10000, idm_loss: 0.093983084

iteration: 5, total_reward: -110.16125054005285, policy_loss: 0.075182, idm_loss: 0.11922832

Policy train: iteration: 500, policy_loss: 0.03485596
Policy train: iteration: 1000, policy_loss: 0.038572505
Policy train: iteration: 1500, policy_loss: 0.029627897
Policy train: iteration: 2000, policy_loss: 0.027269885
Policy train: iteration: 2500, policy_loss: 0.035327718
Policy train: iteration: 3000, policy_loss: 0.025879677
Policy train: iteration: 3500, policy_loss: 0.021732025
Policy train: iteration: 4000, policy_loss: 0.024668664
Policy train: iteration: 4500, policy_loss: 0.035842527
Policy train: iteration: 5000, policy_loss: 0.038405515
Policy train: iteration: 5500, policy_loss: 0.0421032
Policy train: iteration: 6000, policy_loss: 0.028110784
Policy train: iteration: 6500, policy_loss: 0.026298733
Policy train: iteration: 7000, policy_loss: 0.03550842
Policy train: iteration: 7500, policy_loss: 0.027528668
Policy train: iteration: 8000, policy_loss: 0.033530846
Policy train: iteration: 8500, policy_loss: 0.02969177
Policy train: iteration: 9000, policy_loss: 0.04803538
Policy train: iteration: 9500, policy_loss: 0.045882
Policy train: iteration: 10000, policy_loss: 0.033833586
IDM train: iteration: 500, idm_loss: 0.061477438
IDM train: iteration: 1000, idm_loss: 0.11216074
IDM train: iteration: 1500, idm_loss: 0.09225215
IDM train: iteration: 2000, idm_loss: 0.10365131
IDM train: iteration: 2500, idm_loss: 0.13131396
IDM train: iteration: 3000, idm_loss: 0.10178673
IDM train: iteration: 3500, idm_loss: 0.100530766
IDM train: iteration: 4000, idm_loss: 0.09241791
IDM train: iteration: 4500, idm_loss: 0.11385783
IDM train: iteration: 5000, idm_loss: 0.090931304
IDM train: iteration: 5500, idm_loss: 0.10732681
IDM train: iteration: 6000, idm_loss: 0.08542508
IDM train: iteration: 6500, idm_loss: 0.092926845
IDM train: iteration: 7000, idm_loss: 0.104137965
IDM train: iteration: 7500, idm_loss: 0.08638732
IDM train: iteration: 8000, idm_loss: 0.111881986
IDM train: iteration: 8500, idm_loss: 0.089665644
IDM train: iteration: 9000, idm_loss: 0.10593415
IDM train: iteration: 9500, idm_loss: 0.07383491
IDM train: iteration: 10000, idm_loss: 0.0967648

iteration: 6, total_reward: -130.60433955422045, policy_loss: 0.056790356, idm_loss: 0.06041987

Policy train: iteration: 500, policy_loss: 0.025232527
Policy train: iteration: 1000, policy_loss: 0.021500869
Policy train: iteration: 1500, policy_loss: 0.027753375
Policy train: iteration: 2000, policy_loss: 0.023742417
Policy train: iteration: 2500, policy_loss: 0.022407947
Policy train: iteration: 3000, policy_loss: 0.030994888
Policy train: iteration: 3500, policy_loss: 0.04033034
Policy train: iteration: 4000, policy_loss: 0.026005074
Policy train: iteration: 4500, policy_loss: 0.024286646
Policy train: iteration: 5000, policy_loss: 0.027631156
Policy train: iteration: 5500, policy_loss: 0.02478671
Policy train: iteration: 6000, policy_loss: 0.024868123
Policy train: iteration: 6500, policy_loss: 0.025884451
Policy train: iteration: 7000, policy_loss: 0.026782047
Policy train: iteration: 7500, policy_loss: 0.027296111
Policy train: iteration: 8000, policy_loss: 0.020460855
Policy train: iteration: 8500, policy_loss: 0.024867784
Policy train: iteration: 9000, policy_loss: 0.028075743
Policy train: iteration: 9500, policy_loss: 0.026114644
Policy train: iteration: 10000, policy_loss: 0.03195755
IDM train: iteration: 500, idm_loss: 0.10432984
IDM train: iteration: 1000, idm_loss: 0.10814037
IDM train: iteration: 1500, idm_loss: 0.104264915
IDM train: iteration: 2000, idm_loss: 0.09505494
IDM train: iteration: 2500, idm_loss: 0.12013129
IDM train: iteration: 3000, idm_loss: 0.095439285
IDM train: iteration: 3500, idm_loss: 0.113210574
IDM train: iteration: 4000, idm_loss: 0.078866884
IDM train: iteration: 4500, idm_loss: 0.07577311
IDM train: iteration: 5000, idm_loss: 0.085287094
IDM train: iteration: 5500, idm_loss: 0.10135768
IDM train: iteration: 6000, idm_loss: 0.09788136
IDM train: iteration: 6500, idm_loss: 0.09851615
IDM train: iteration: 7000, idm_loss: 0.09904349
IDM train: iteration: 7500, idm_loss: 0.107280806
IDM train: iteration: 8000, idm_loss: 0.089659914
IDM train: iteration: 8500, idm_loss: 0.071544796
IDM train: iteration: 9000, idm_loss: 0.0940018
IDM train: iteration: 9500, idm_loss: 0.08130959
IDM train: iteration: 10000, idm_loss: 0.1050364

iteration: 7, total_reward: -46.115746728726286, policy_loss: 0.06802042, idm_loss: 0.10799718

Policy train: iteration: 500, policy_loss: 0.03186627
Policy train: iteration: 1000, policy_loss: 0.02492556
Policy train: iteration: 1500, policy_loss: 0.031055331
Policy train: iteration: 2000, policy_loss: 0.024403911
Policy train: iteration: 2500, policy_loss: 0.023381846
Policy train: iteration: 3000, policy_loss: 0.02571695
Policy train: iteration: 3500, policy_loss: 0.027918328
Policy train: iteration: 4000, policy_loss: 0.032020472
Policy train: iteration: 4500, policy_loss: 0.025726497
Policy train: iteration: 5000, policy_loss: 0.03881525
Policy train: iteration: 5500, policy_loss: 0.02941172
Policy train: iteration: 6000, policy_loss: 0.023979917
Policy train: iteration: 6500, policy_loss: 0.024389429
Policy train: iteration: 7000, policy_loss: 0.025394367
Policy train: iteration: 7500, policy_loss: 0.02274382
Policy train: iteration: 8000, policy_loss: 0.025657833
Policy train: iteration: 8500, policy_loss: 0.020127267
Policy train: iteration: 9000, policy_loss: 0.031012274
Policy train: iteration: 9500, policy_loss: 0.02467344
Policy train: iteration: 10000, policy_loss: 0.031885933
IDM train: iteration: 500, idm_loss: 0.07904871
IDM train: iteration: 1000, idm_loss: 0.067755386
IDM train: iteration: 1500, idm_loss: 0.08227667
IDM train: iteration: 2000, idm_loss: 0.09353147
IDM train: iteration: 2500, idm_loss: 0.12568861
IDM train: iteration: 3000, idm_loss: 0.122607395
IDM train: iteration: 3500, idm_loss: 0.1058212
IDM train: iteration: 4000, idm_loss: 0.106080756
IDM train: iteration: 4500, idm_loss: 0.102141984
IDM train: iteration: 5000, idm_loss: 0.17562076
IDM train: iteration: 5500, idm_loss: 0.08005432
IDM train: iteration: 6000, idm_loss: 0.07990128
IDM train: iteration: 6500, idm_loss: 0.087367475
IDM train: iteration: 7000, idm_loss: 0.078895144
IDM train: iteration: 7500, idm_loss: 0.100781694
IDM train: iteration: 8000, idm_loss: 0.098222524
IDM train: iteration: 8500, idm_loss: 0.10420058
IDM train: iteration: 9000, idm_loss: 0.085163325
IDM train: iteration: 9500, idm_loss: 0.07709967
IDM train: iteration: 10000, idm_loss: 0.08084795

iteration: 8, total_reward: -142.25228533180928, policy_loss: 0.047906585, idm_loss: 0.06914372

Policy train: iteration: 500, policy_loss: 0.031598173
Policy train: iteration: 1000, policy_loss: 0.016446803
Policy train: iteration: 1500, policy_loss: 0.02848531
Policy train: iteration: 2000, policy_loss: 0.024587162
Policy train: iteration: 2500, policy_loss: 0.037475627
Policy train: iteration: 3000, policy_loss: 0.018239632
Policy train: iteration: 3500, policy_loss: 0.027730528
Policy train: iteration: 4000, policy_loss: 0.012589667
Policy train: iteration: 4500, policy_loss: 0.023516145
Policy train: iteration: 5000, policy_loss: 0.017259162
Policy train: iteration: 5500, policy_loss: 0.017626496
Policy train: iteration: 6000, policy_loss: 0.021289065
Policy train: iteration: 6500, policy_loss: 0.024447815
Policy train: iteration: 7000, policy_loss: 0.020108007
Policy train: iteration: 7500, policy_loss: 0.020125084
Policy train: iteration: 8000, policy_loss: 0.014986542
Policy train: iteration: 8500, policy_loss: 0.015722618
Policy train: iteration: 9000, policy_loss: 0.024739783
Policy train: iteration: 9500, policy_loss: 0.027174218
Policy train: iteration: 10000, policy_loss: 0.018033324
IDM train: iteration: 500, idm_loss: 0.10753605
IDM train: iteration: 1000, idm_loss: 0.11878195
IDM train: iteration: 1500, idm_loss: 0.13003191
IDM train: iteration: 2000, idm_loss: 0.08988741
IDM train: iteration: 2500, idm_loss: 0.12535019
IDM train: iteration: 3000, idm_loss: 0.07204637
IDM train: iteration: 3500, idm_loss: 0.08961396
IDM train: iteration: 4000, idm_loss: 0.157101
IDM train: iteration: 4500, idm_loss: 0.081807315
IDM train: iteration: 5000, idm_loss: 0.101122744
IDM train: iteration: 5500, idm_loss: 0.09987648
IDM train: iteration: 6000, idm_loss: 0.097226396
IDM train: iteration: 6500, idm_loss: 0.08791845
IDM train: iteration: 7000, idm_loss: 0.08002998
IDM train: iteration: 7500, idm_loss: 0.100346014
IDM train: iteration: 8000, idm_loss: 0.096164964
IDM train: iteration: 8500, idm_loss: 0.080775425
IDM train: iteration: 9000, idm_loss: 0.10389221
IDM train: iteration: 9500, idm_loss: 0.099396616
IDM train: iteration: 10000, idm_loss: 0.09745456

iteration: 9, total_reward: -125.57757701566442, policy_loss: 0.052157503, idm_loss: 0.12361911

Policy train: iteration: 500, policy_loss: 0.027414901
Policy train: iteration: 1000, policy_loss: 0.018768556
Policy train: iteration: 1500, policy_loss: 0.029751584
Policy train: iteration: 2000, policy_loss: 0.025303636
Policy train: iteration: 2500, policy_loss: 0.02332268
Policy train: iteration: 3000, policy_loss: 0.020277746
Policy train: iteration: 3500, policy_loss: 0.030131757
Policy train: iteration: 4000, policy_loss: 0.021204183
Policy train: iteration: 4500, policy_loss: 0.017864656
Policy train: iteration: 5000, policy_loss: 0.021492828
Policy train: iteration: 5500, policy_loss: 0.016876673
Policy train: iteration: 6000, policy_loss: 0.016122714
Policy train: iteration: 6500, policy_loss: 0.023162723
Policy train: iteration: 7000, policy_loss: 0.017916227
Policy train: iteration: 7500, policy_loss: 0.029035196
Policy train: iteration: 8000, policy_loss: 0.018664336
Policy train: iteration: 8500, policy_loss: 0.019921055
Policy train: iteration: 9000, policy_loss: 0.023781206
Policy train: iteration: 9500, policy_loss: 0.029020797
Policy train: iteration: 10000, policy_loss: 0.016138356
IDM train: iteration: 500, idm_loss: 0.09518029
IDM train: iteration: 1000, idm_loss: 0.10417874
IDM train: iteration: 1500, idm_loss: 0.08338131
IDM train: iteration: 2000, idm_loss: 0.076887056
IDM train: iteration: 2500, idm_loss: 0.08063807
IDM train: iteration: 3000, idm_loss: 0.09204078
IDM train: iteration: 3500, idm_loss: 0.115631536
IDM train: iteration: 4000, idm_loss: 0.10106389
IDM train: iteration: 4500, idm_loss: 0.10089862
IDM train: iteration: 5000, idm_loss: 0.10289657
IDM train: iteration: 5500, idm_loss: 0.08153558
IDM train: iteration: 6000, idm_loss: 0.09040478
IDM train: iteration: 6500, idm_loss: 0.09121983
IDM train: iteration: 7000, idm_loss: 0.09573911
IDM train: iteration: 7500, idm_loss: 0.11079157
IDM train: iteration: 8000, idm_loss: 0.086739525
IDM train: iteration: 8500, idm_loss: 0.098922454
IDM train: iteration: 9000, idm_loss: 0.10713689
IDM train: iteration: 9500, idm_loss: 0.09420143
IDM train: iteration: 10000, idm_loss: 0.0999995

iteration: 10, total_reward: -120.58154385672758, policy_loss: 0.058171533, idm_loss: 0.12161606

Policy train: iteration: 500, policy_loss: 0.028029934
Policy train: iteration: 1000, policy_loss: 0.020437727
Policy train: iteration: 1500, policy_loss: 0.024503183
Policy train: iteration: 2000, policy_loss: 0.015850669
Policy train: iteration: 2500, policy_loss: 0.037533514
Policy train: iteration: 3000, policy_loss: 0.021507375
Policy train: iteration: 3500, policy_loss: 0.01815436
Policy train: iteration: 4000, policy_loss: 0.021769308
Policy train: iteration: 4500, policy_loss: 0.019069277
Policy train: iteration: 5000, policy_loss: 0.022028213
Policy train: iteration: 5500, policy_loss: 0.025986137
Policy train: iteration: 6000, policy_loss: 0.017160812
Policy train: iteration: 6500, policy_loss: 0.021253522
Policy train: iteration: 7000, policy_loss: 0.021955512
Policy train: iteration: 7500, policy_loss: 0.021074686
Policy train: iteration: 8000, policy_loss: 0.019416505
Policy train: iteration: 8500, policy_loss: 0.016581044
Policy train: iteration: 9000, policy_loss: 0.022519626
Policy train: iteration: 9500, policy_loss: 0.023957767
Policy train: iteration: 10000, policy_loss: 0.04469766
IDM train: iteration: 500, idm_loss: 0.08271864
IDM train: iteration: 1000, idm_loss: 0.10036176
IDM train: iteration: 1500, idm_loss: 0.10929482
IDM train: iteration: 2000, idm_loss: 0.068337634
IDM train: iteration: 2500, idm_loss: 0.09789683
IDM train: iteration: 3000, idm_loss: 0.070889756
IDM train: iteration: 3500, idm_loss: 0.08597824
IDM train: iteration: 4000, idm_loss: 0.08845112
IDM train: iteration: 4500, idm_loss: 0.10793908
IDM train: iteration: 5000, idm_loss: 0.095626146
IDM train: iteration: 5500, idm_loss: 0.06766893
IDM train: iteration: 6000, idm_loss: 0.070681125
IDM train: iteration: 6500, idm_loss: 0.075454056
IDM train: iteration: 7000, idm_loss: 0.10517219
IDM train: iteration: 7500, idm_loss: 0.069308825
IDM train: iteration: 8000, idm_loss: 0.08043352
IDM train: iteration: 8500, idm_loss: 0.09080305
IDM train: iteration: 9000, idm_loss: 0.12750973
IDM train: iteration: 9500, idm_loss: 0.10983737
IDM train: iteration: 10000, idm_loss: 0.06706396

iteration: 11, total_reward: -120.48212364917933, policy_loss: 0.055948365, idm_loss: 0.14898147

Policy train: iteration: 500, policy_loss: 0.027128918
Policy train: iteration: 1000, policy_loss: 0.019364387
Policy train: iteration: 1500, policy_loss: 0.026621435
Policy train: iteration: 2000, policy_loss: 0.021898355
Policy train: iteration: 2500, policy_loss: 0.018901723
Policy train: iteration: 3000, policy_loss: 0.020507097
Policy train: iteration: 3500, policy_loss: 0.027399305
Policy train: iteration: 4000, policy_loss: 0.027267551
Policy train: iteration: 4500, policy_loss: 0.024257954
Policy train: iteration: 5000, policy_loss: 0.023452923
Policy train: iteration: 5500, policy_loss: 0.017910726
Policy train: iteration: 6000, policy_loss: 0.017290823
Policy train: iteration: 6500, policy_loss: 0.015490031
Policy train: iteration: 7000, policy_loss: 0.018234896
Policy train: iteration: 7500, policy_loss: 0.023348875
Policy train: iteration: 8000, policy_loss: 0.03292959
Policy train: iteration: 8500, policy_loss: 0.01340006
Policy train: iteration: 9000, policy_loss: 0.018009484
Policy train: iteration: 9500, policy_loss: 0.02003602
Policy train: iteration: 10000, policy_loss: 0.01954252
IDM train: iteration: 500, idm_loss: 0.084577635
IDM train: iteration: 1000, idm_loss: 0.09858469
IDM train: iteration: 1500, idm_loss: 0.095272124
IDM train: iteration: 2000, idm_loss: 0.087398864
IDM train: iteration: 2500, idm_loss: 0.10198298
IDM train: iteration: 3000, idm_loss: 0.06500933
IDM train: iteration: 3500, idm_loss: 0.09241822
IDM train: iteration: 4000, idm_loss: 0.09305591
IDM train: iteration: 4500, idm_loss: 0.12479529
IDM train: iteration: 5000, idm_loss: 0.113305956
IDM train: iteration: 5500, idm_loss: 0.06940294
IDM train: iteration: 6000, idm_loss: 0.09625235
IDM train: iteration: 6500, idm_loss: 0.06918839
IDM train: iteration: 7000, idm_loss: 0.09020278
IDM train: iteration: 7500, idm_loss: 0.08518298
IDM train: iteration: 8000, idm_loss: 0.08729243
IDM train: iteration: 8500, idm_loss: 0.070796534
IDM train: iteration: 9000, idm_loss: 0.06988379
IDM train: iteration: 9500, idm_loss: 0.0869825
IDM train: iteration: 10000, idm_loss: 0.08573917

iteration: 12, total_reward: -121.06034856865617, policy_loss: 0.050355136, idm_loss: 0.022072643

Policy train: iteration: 500, policy_loss: 0.040515542
Policy train: iteration: 1000, policy_loss: 0.022718813
Policy train: iteration: 1500, policy_loss: 0.023635907
Policy train: iteration: 2000, policy_loss: 0.019850114
Policy train: iteration: 2500, policy_loss: 0.020707147
Policy train: iteration: 3000, policy_loss: 0.019420918
Policy train: iteration: 3500, policy_loss: 0.012609222
Policy train: iteration: 4000, policy_loss: 0.016327538
Policy train: iteration: 4500, policy_loss: 0.011368643
Policy train: iteration: 5000, policy_loss: 0.015070062
Policy train: iteration: 5500, policy_loss: 0.018927842
Policy train: iteration: 6000, policy_loss: 0.01893646
Policy train: iteration: 6500, policy_loss: 0.014933998
Policy train: iteration: 7000, policy_loss: 0.01765316
Policy train: iteration: 7500, policy_loss: 0.019754311
Policy train: iteration: 8000, policy_loss: 0.016853008
Policy train: iteration: 8500, policy_loss: 0.025511205
Policy train: iteration: 9000, policy_loss: 0.018196896
Policy train: iteration: 9500, policy_loss: 0.013362827
Policy train: iteration: 10000, policy_loss: 0.021098875
IDM train: iteration: 500, idm_loss: 0.09815696
IDM train: iteration: 1000, idm_loss: 0.098697305
IDM train: iteration: 1500, idm_loss: 0.098138556
IDM train: iteration: 2000, idm_loss: 0.110922374
IDM train: iteration: 2500, idm_loss: 0.1064975
IDM train: iteration: 3000, idm_loss: 0.07743548
IDM train: iteration: 3500, idm_loss: 0.10657939
IDM train: iteration: 4000, idm_loss: 0.089159444
IDM train: iteration: 4500, idm_loss: 0.13300267
IDM train: iteration: 5000, idm_loss: 0.10762995
IDM train: iteration: 5500, idm_loss: 0.0756423
IDM train: iteration: 6000, idm_loss: 0.073419765
IDM train: iteration: 6500, idm_loss: 0.097690225
IDM train: iteration: 7000, idm_loss: 0.11848669
IDM train: iteration: 7500, idm_loss: 0.10497147
IDM train: iteration: 8000, idm_loss: 0.08968011
IDM train: iteration: 8500, idm_loss: 0.112664
IDM train: iteration: 9000, idm_loss: 0.11328919
IDM train: iteration: 9500, idm_loss: 0.08992384
IDM train: iteration: 10000, idm_loss: 0.0914983

iteration: 13, total_reward: -47.154607318555996, policy_loss: 0.080722034, idm_loss: 0.08547697

Policy train: iteration: 500, policy_loss: 0.025089275
Policy train: iteration: 1000, policy_loss: 0.015126538
Policy train: iteration: 1500, policy_loss: 0.023226153
Policy train: iteration: 2000, policy_loss: 0.018607762
Policy train: iteration: 2500, policy_loss: 0.022972576
Policy train: iteration: 3000, policy_loss: 0.017346755
Policy train: iteration: 3500, policy_loss: 0.016680535
Policy train: iteration: 4000, policy_loss: 0.014714841
Policy train: iteration: 4500, policy_loss: 0.014959844
Policy train: iteration: 5000, policy_loss: 0.017283525
Policy train: iteration: 5500, policy_loss: 0.016019555
Policy train: iteration: 6000, policy_loss: 0.012495684
Policy train: iteration: 6500, policy_loss: 0.021485727
Policy train: iteration: 7000, policy_loss: 0.015328523
Policy train: iteration: 7500, policy_loss: 0.0178089
Policy train: iteration: 8000, policy_loss: 0.012252569
Policy train: iteration: 8500, policy_loss: 0.011137809
Policy train: iteration: 9000, policy_loss: 0.018064443
Policy train: iteration: 9500, policy_loss: 0.016638782
Policy train: iteration: 10000, policy_loss: 0.012761472
IDM train: iteration: 500, idm_loss: 0.08411276
IDM train: iteration: 1000, idm_loss: 0.0884359
IDM train: iteration: 1500, idm_loss: 0.10383858
IDM train: iteration: 2000, idm_loss: 0.08695525
IDM train: iteration: 2500, idm_loss: 0.0895227
IDM train: iteration: 3000, idm_loss: 0.0972819
IDM train: iteration: 3500, idm_loss: 0.10742901
IDM train: iteration: 4000, idm_loss: 0.09378812
IDM train: iteration: 4500, idm_loss: 0.07762919
IDM train: iteration: 5000, idm_loss: 0.084497884
IDM train: iteration: 5500, idm_loss: 0.071841046
IDM train: iteration: 6000, idm_loss: 0.092623204
IDM train: iteration: 6500, idm_loss: 0.091607556
IDM train: iteration: 7000, idm_loss: 0.07922607
IDM train: iteration: 7500, idm_loss: 0.10016225
IDM train: iteration: 8000, idm_loss: 0.078184254
IDM train: iteration: 8500, idm_loss: 0.06182556
IDM train: iteration: 9000, idm_loss: 0.10933503
IDM train: iteration: 9500, idm_loss: 0.07444109
IDM train: iteration: 10000, idm_loss: 0.07824107

iteration: 14, total_reward: 181.98212632523177, policy_loss: 0.038048204, idm_loss: 0.08313443

Policy train: iteration: 500, policy_loss: 0.026818424
Policy train: iteration: 1000, policy_loss: 0.012741987
Policy train: iteration: 1500, policy_loss: 0.0059705367
Policy train: iteration: 2000, policy_loss: 0.012593225
Policy train: iteration: 2500, policy_loss: 0.012440672
Policy train: iteration: 3000, policy_loss: 0.013559587
Policy train: iteration: 3500, policy_loss: 0.014998277
Policy train: iteration: 4000, policy_loss: 0.010725175
Policy train: iteration: 4500, policy_loss: 0.017969077
Policy train: iteration: 5000, policy_loss: 0.016931966
Policy train: iteration: 5500, policy_loss: 0.035210602
Policy train: iteration: 6000, policy_loss: 0.0093064625
Policy train: iteration: 6500, policy_loss: 0.016752431
Policy train: iteration: 7000, policy_loss: 0.010808281
Policy train: iteration: 7500, policy_loss: 0.014147963
Policy train: iteration: 8000, policy_loss: 0.03274643
Policy train: iteration: 8500, policy_loss: 0.011980881
Policy train: iteration: 9000, policy_loss: 0.009843847
Policy train: iteration: 9500, policy_loss: 0.012851121
Policy train: iteration: 10000, policy_loss: 0.0112306755
IDM train: iteration: 500, idm_loss: 0.0888128
IDM train: iteration: 1000, idm_loss: 0.066734955
IDM train: iteration: 1500, idm_loss: 0.09564772
IDM train: iteration: 2000, idm_loss: 0.10216832
IDM train: iteration: 2500, idm_loss: 0.08096942
IDM train: iteration: 3000, idm_loss: 0.08497971
IDM train: iteration: 3500, idm_loss: 0.100927345
IDM train: iteration: 4000, idm_loss: 0.10602836
IDM train: iteration: 4500, idm_loss: 0.07816118
IDM train: iteration: 5000, idm_loss: 0.09670786
IDM train: iteration: 5500, idm_loss: 0.09452025
IDM train: iteration: 6000, idm_loss: 0.095664814
IDM train: iteration: 6500, idm_loss: 0.07830444
IDM train: iteration: 7000, idm_loss: 0.0937278
IDM train: iteration: 7500, idm_loss: 0.106232
IDM train: iteration: 8000, idm_loss: 0.0963469
IDM train: iteration: 8500, idm_loss: 0.087195575
IDM train: iteration: 9000, idm_loss: 0.08297475
IDM train: iteration: 9500, idm_loss: 0.086426444
IDM train: iteration: 10000, idm_loss: 0.0652792

iteration: 15, total_reward: -60.57891336710626, policy_loss: 0.049193986, idm_loss: 0.08984576

Policy train: iteration: 500, policy_loss: 0.016683005
Policy train: iteration: 1000, policy_loss: 0.017860845
Policy train: iteration: 1500, policy_loss: 0.009091938
Policy train: iteration: 2000, policy_loss: 0.014229656
Policy train: iteration: 2500, policy_loss: 0.014299586
Policy train: iteration: 3000, policy_loss: 0.013067301
Policy train: iteration: 3500, policy_loss: 0.013235411
Policy train: iteration: 4000, policy_loss: 0.018147325
Policy train: iteration: 4500, policy_loss: 0.008974429
Policy train: iteration: 5000, policy_loss: 0.014462523
Policy train: iteration: 5500, policy_loss: 0.01820628
Policy train: iteration: 6000, policy_loss: 0.01951497
Policy train: iteration: 6500, policy_loss: 0.01614525
Policy train: iteration: 7000, policy_loss: 0.021395572
Policy train: iteration: 7500, policy_loss: 0.02070243
Policy train: iteration: 8000, policy_loss: 0.015879424
Policy train: iteration: 8500, policy_loss: 0.012082417
Policy train: iteration: 9000, policy_loss: 0.01208498
Policy train: iteration: 9500, policy_loss: 0.020758957
Policy train: iteration: 10000, policy_loss: 0.01635449
IDM train: iteration: 500, idm_loss: 0.090033725
IDM train: iteration: 1000, idm_loss: 0.09216732
IDM train: iteration: 1500, idm_loss: 0.11457196
IDM train: iteration: 2000, idm_loss: 0.086980134
IDM train: iteration: 2500, idm_loss: 0.088312276
IDM train: iteration: 3000, idm_loss: 0.08312157
IDM train: iteration: 3500, idm_loss: 0.09857543
IDM train: iteration: 4000, idm_loss: 0.08142139
IDM train: iteration: 4500, idm_loss: 0.07904362
IDM train: iteration: 5000, idm_loss: 0.07795976
IDM train: iteration: 5500, idm_loss: 0.11537495
IDM train: iteration: 6000, idm_loss: 0.10988183
IDM train: iteration: 6500, idm_loss: 0.09124757
IDM train: iteration: 7000, idm_loss: 0.078518495
IDM train: iteration: 7500, idm_loss: 0.06321108
IDM train: iteration: 8000, idm_loss: 0.07686117
IDM train: iteration: 8500, idm_loss: 0.07526897
IDM train: iteration: 9000, idm_loss: 0.08324748
IDM train: iteration: 9500, idm_loss: 0.08947694
IDM train: iteration: 10000, idm_loss: 0.08795859

iteration: 16, total_reward: -83.41877023852244, policy_loss: 0.062197953, idm_loss: 0.07452077

Policy train: iteration: 500, policy_loss: 0.017087981
Policy train: iteration: 1000, policy_loss: 0.019079085
Policy train: iteration: 1500, policy_loss: 0.014284442
Policy train: iteration: 2000, policy_loss: 0.014408729
Policy train: iteration: 2500, policy_loss: 0.019086735
Policy train: iteration: 3000, policy_loss: 0.015415629
Policy train: iteration: 3500, policy_loss: 0.008752051
Policy train: iteration: 4000, policy_loss: 0.013132896
Policy train: iteration: 4500, policy_loss: 0.021464337
Policy train: iteration: 5000, policy_loss: 0.010241936
Policy train: iteration: 5500, policy_loss: 0.014559411
Policy train: iteration: 6000, policy_loss: 0.013877344
Policy train: iteration: 6500, policy_loss: 0.013737325
Policy train: iteration: 7000, policy_loss: 0.016742585
Policy train: iteration: 7500, policy_loss: 0.0133722965
Policy train: iteration: 8000, policy_loss: 0.010208304
Policy train: iteration: 8500, policy_loss: 0.011147866
Policy train: iteration: 9000, policy_loss: 0.014906433
Policy train: iteration: 9500, policy_loss: 0.012737242
Policy train: iteration: 10000, policy_loss: 0.012070727
IDM train: iteration: 500, idm_loss: 0.12128198
IDM train: iteration: 1000, idm_loss: 0.089316875
IDM train: iteration: 1500, idm_loss: 0.07730369
IDM train: iteration: 2000, idm_loss: 0.09027959
IDM train: iteration: 2500, idm_loss: 0.09271559
IDM train: iteration: 3000, idm_loss: 0.07318946
IDM train: iteration: 3500, idm_loss: 0.09560086
IDM train: iteration: 4000, idm_loss: 0.10757236
IDM train: iteration: 4500, idm_loss: 0.09119162
IDM train: iteration: 5000, idm_loss: 0.07577459
IDM train: iteration: 5500, idm_loss: 0.12029478
IDM train: iteration: 6000, idm_loss: 0.105449885
IDM train: iteration: 6500, idm_loss: 0.083927706
IDM train: iteration: 7000, idm_loss: 0.086063705
IDM train: iteration: 7500, idm_loss: 0.07213154
IDM train: iteration: 8000, idm_loss: 0.077794984
IDM train: iteration: 8500, idm_loss: 0.0767934
IDM train: iteration: 9000, idm_loss: 0.09197876
IDM train: iteration: 9500, idm_loss: 0.10445993
IDM train: iteration: 10000, idm_loss: 0.08727883

iteration: 17, total_reward: -76.00022683274373, policy_loss: 0.048820607, idm_loss: 0.065178335

Policy train: iteration: 500, policy_loss: 0.019655842
Policy train: iteration: 1000, policy_loss: 0.015549558
Policy train: iteration: 1500, policy_loss: 0.015783273
Policy train: iteration: 2000, policy_loss: 0.018934838
Policy train: iteration: 2500, policy_loss: 0.013483049
Policy train: iteration: 3000, policy_loss: 0.014206889
Policy train: iteration: 3500, policy_loss: 0.01618781
Policy train: iteration: 4000, policy_loss: 0.014502219
Policy train: iteration: 4500, policy_loss: 0.013747566
Policy train: iteration: 5000, policy_loss: 0.016984116
Policy train: iteration: 5500, policy_loss: 0.0102767795
Policy train: iteration: 6000, policy_loss: 0.014719926
Policy train: iteration: 6500, policy_loss: 0.016814679
Policy train: iteration: 7000, policy_loss: 0.015977241
Policy train: iteration: 7500, policy_loss: 0.01171812
Policy train: iteration: 8000, policy_loss: 0.014382396
Policy train: iteration: 8500, policy_loss: 0.010813622
Policy train: iteration: 9000, policy_loss: 0.007975178
Policy train: iteration: 9500, policy_loss: 0.015608467
Policy train: iteration: 10000, policy_loss: 0.015535334
IDM train: iteration: 500, idm_loss: 0.08261823
IDM train: iteration: 1000, idm_loss: 0.08537783
IDM train: iteration: 1500, idm_loss: 0.09616615
IDM train: iteration: 2000, idm_loss: 0.068291634
IDM train: iteration: 2500, idm_loss: 0.12351809
IDM train: iteration: 3000, idm_loss: 0.089143835
IDM train: iteration: 3500, idm_loss: 0.10217355
IDM train: iteration: 4000, idm_loss: 0.06327177
IDM train: iteration: 4500, idm_loss: 0.08802883
IDM train: iteration: 5000, idm_loss: 0.10397439
IDM train: iteration: 5500, idm_loss: 0.09633823
IDM train: iteration: 6000, idm_loss: 0.09123014
IDM train: iteration: 6500, idm_loss: 0.083621174
IDM train: iteration: 7000, idm_loss: 0.081608176
IDM train: iteration: 7500, idm_loss: 0.09182953
IDM train: iteration: 8000, idm_loss: 0.0990603
IDM train: iteration: 8500, idm_loss: 0.071881674
IDM train: iteration: 9000, idm_loss: 0.09071805
IDM train: iteration: 9500, idm_loss: 0.0927009
IDM train: iteration: 10000, idm_loss: 0.08733332

iteration: 18, total_reward: -15.520285769389947, policy_loss: 0.052705467, idm_loss: 0.08717604

Policy train: iteration: 500, policy_loss: 0.013359007
Policy train: iteration: 1000, policy_loss: 0.013167346
Policy train: iteration: 1500, policy_loss: 0.010232898
Policy train: iteration: 2000, policy_loss: 0.011261688
Policy train: iteration: 2500, policy_loss: 0.010145807
Policy train: iteration: 3000, policy_loss: 0.013244644
Policy train: iteration: 3500, policy_loss: 0.021489229
Policy train: iteration: 4000, policy_loss: 0.011873686
Policy train: iteration: 4500, policy_loss: 0.013280468
Policy train: iteration: 5000, policy_loss: 0.009582999
Policy train: iteration: 5500, policy_loss: 0.0128777865
Policy train: iteration: 6000, policy_loss: 0.013267035
Policy train: iteration: 6500, policy_loss: 0.012593897
Policy train: iteration: 7000, policy_loss: 0.0106921345
Policy train: iteration: 7500, policy_loss: 0.011644709
Policy train: iteration: 8000, policy_loss: 0.0115179885
Policy train: iteration: 8500, policy_loss: 0.013930301
Policy train: iteration: 9000, policy_loss: 0.009968482
Policy train: iteration: 9500, policy_loss: 0.009501681
Policy train: iteration: 10000, policy_loss: 0.021348003
IDM train: iteration: 500, idm_loss: 0.08033362
IDM train: iteration: 1000, idm_loss: 0.07639829
IDM train: iteration: 1500, idm_loss: 0.09544398
IDM train: iteration: 2000, idm_loss: 0.10053259
IDM train: iteration: 2500, idm_loss: 0.07622949
IDM train: iteration: 3000, idm_loss: 0.08675105
IDM train: iteration: 3500, idm_loss: 0.06568533
IDM train: iteration: 4000, idm_loss: 0.072764486
IDM train: iteration: 4500, idm_loss: 0.06985323
IDM train: iteration: 5000, idm_loss: 0.07971764
IDM train: iteration: 5500, idm_loss: 0.061352145
IDM train: iteration: 6000, idm_loss: 0.078769915
IDM train: iteration: 6500, idm_loss: 0.060909428
IDM train: iteration: 7000, idm_loss: 0.09607747
IDM train: iteration: 7500, idm_loss: 0.09366826
IDM train: iteration: 8000, idm_loss: 0.069626205
IDM train: iteration: 8500, idm_loss: 0.07161612
IDM train: iteration: 9000, idm_loss: 0.078710504
IDM train: iteration: 9500, idm_loss: 0.09743718
IDM train: iteration: 10000, idm_loss: 0.08678658

iteration: 19, total_reward: -98.83513843553264, policy_loss: 0.032607164, idm_loss: 0.09851721

Policy train: iteration: 500, policy_loss: 0.014461387
Policy train: iteration: 1000, policy_loss: 0.010932073
Policy train: iteration: 1500, policy_loss: 0.011647705
Policy train: iteration: 2000, policy_loss: 0.011503367
Policy train: iteration: 2500, policy_loss: 0.016628666
Policy train: iteration: 3000, policy_loss: 0.009606749
Policy train: iteration: 3500, policy_loss: 0.011863871
Policy train: iteration: 4000, policy_loss: 0.011224249
Policy train: iteration: 4500, policy_loss: 0.012690789
Policy train: iteration: 5000, policy_loss: 0.0109466445
Policy train: iteration: 5500, policy_loss: 0.016208187
Policy train: iteration: 6000, policy_loss: 0.010460587
Policy train: iteration: 6500, policy_loss: 0.013035186
Policy train: iteration: 7000, policy_loss: 0.009827288
Policy train: iteration: 7500, policy_loss: 0.01064375
Policy train: iteration: 8000, policy_loss: 0.017826786
Policy train: iteration: 8500, policy_loss: 0.011922868
Policy train: iteration: 9000, policy_loss: 0.013789246
Policy train: iteration: 9500, policy_loss: 0.01248197
Policy train: iteration: 10000, policy_loss: 0.009236435
IDM train: iteration: 500, idm_loss: 0.09387304
IDM train: iteration: 1000, idm_loss: 0.08139351
IDM train: iteration: 1500, idm_loss: 0.100708656
IDM train: iteration: 2000, idm_loss: 0.09876932
IDM train: iteration: 2500, idm_loss: 0.10065867
IDM train: iteration: 3000, idm_loss: 0.0866602
IDM train: iteration: 3500, idm_loss: 0.10219876
IDM train: iteration: 4000, idm_loss: 0.09000192
IDM train: iteration: 4500, idm_loss: 0.07730306
IDM train: iteration: 5000, idm_loss: 0.08033042
IDM train: iteration: 5500, idm_loss: 0.06221781
IDM train: iteration: 6000, idm_loss: 0.106025055
IDM train: iteration: 6500, idm_loss: 0.086911105
IDM train: iteration: 7000, idm_loss: 0.112432055
IDM train: iteration: 7500, idm_loss: 0.10526147
IDM train: iteration: 8000, idm_loss: 0.109334216
IDM train: iteration: 8500, idm_loss: 0.0906021
IDM train: iteration: 9000, idm_loss: 0.06964815
IDM train: iteration: 9500, idm_loss: 0.09214783
IDM train: iteration: 10000, idm_loss: 0.07360489

iteration: 20, total_reward: -89.24784592216525, policy_loss: 0.043574173, idm_loss: 0.06999571

Policy train: iteration: 500, policy_loss: 0.014413843
Policy train: iteration: 1000, policy_loss: 0.009604514
Policy train: iteration: 1500, policy_loss: 0.010190219
Policy train: iteration: 2000, policy_loss: 0.016550621
Policy train: iteration: 2500, policy_loss: 0.009286312
Policy train: iteration: 3000, policy_loss: 0.010489338
Policy train: iteration: 3500, policy_loss: 0.012440364
Policy train: iteration: 4000, policy_loss: 0.013281647
Policy train: iteration: 4500, policy_loss: 0.01586472
Policy train: iteration: 5000, policy_loss: 0.0101449825
Policy train: iteration: 5500, policy_loss: 0.011875159
Policy train: iteration: 6000, policy_loss: 0.010313733
Policy train: iteration: 6500, policy_loss: 0.011205109
Policy train: iteration: 7000, policy_loss: 0.014078535
Policy train: iteration: 7500, policy_loss: 0.009222086
Policy train: iteration: 8000, policy_loss: 0.011614757
Policy train: iteration: 8500, policy_loss: 0.016746238
Policy train: iteration: 9000, policy_loss: 0.0152870435
Policy train: iteration: 9500, policy_loss: 0.012410889
Policy train: iteration: 10000, policy_loss: 0.015933298
IDM train: iteration: 500, idm_loss: 0.059823833
IDM train: iteration: 1000, idm_loss: 0.08393916
IDM train: iteration: 1500, idm_loss: 0.08183116
IDM train: iteration: 2000, idm_loss: 0.08773318
IDM train: iteration: 2500, idm_loss: 0.057383277
IDM train: iteration: 3000, idm_loss: 0.09623851
IDM train: iteration: 3500, idm_loss: 0.08884606
IDM train: iteration: 4000, idm_loss: 0.097721785
IDM train: iteration: 4500, idm_loss: 0.082049705
IDM train: iteration: 5000, idm_loss: 0.07450229
IDM train: iteration: 5500, idm_loss: 0.09899423
IDM train: iteration: 6000, idm_loss: 0.07969688
IDM train: iteration: 6500, idm_loss: 0.094003335
IDM train: iteration: 7000, idm_loss: 0.102205195
IDM train: iteration: 7500, idm_loss: 0.090637386
IDM train: iteration: 8000, idm_loss: 0.08872783
IDM train: iteration: 8500, idm_loss: 0.062675476
IDM train: iteration: 9000, idm_loss: 0.07023351
IDM train: iteration: 9500, idm_loss: 0.09500731
IDM train: iteration: 10000, idm_loss: 0.11593442

iteration: 21, total_reward: -30.603776533378237, policy_loss: 0.03702623, idm_loss: 0.0842695

Policy train: iteration: 500, policy_loss: 0.015652508
Policy train: iteration: 1000, policy_loss: 0.01148719
Policy train: iteration: 1500, policy_loss: 0.013725929
Policy train: iteration: 2000, policy_loss: 0.009954871
Policy train: iteration: 2500, policy_loss: 0.016231015
Policy train: iteration: 3000, policy_loss: 0.00992468
Policy train: iteration: 3500, policy_loss: 0.012180818
Policy train: iteration: 4000, policy_loss: 0.008448496
Policy train: iteration: 4500, policy_loss: 0.01456102
Policy train: iteration: 5000, policy_loss: 0.025993258
Policy train: iteration: 5500, policy_loss: 0.013948736
Policy train: iteration: 6000, policy_loss: 0.010626785
Policy train: iteration: 6500, policy_loss: 0.013193332
Policy train: iteration: 7000, policy_loss: 0.010626841
Policy train: iteration: 7500, policy_loss: 0.014331413
Policy train: iteration: 8000, policy_loss: 0.009953003
Policy train: iteration: 8500, policy_loss: 0.013817491
Policy train: iteration: 9000, policy_loss: 0.013734207
Policy train: iteration: 9500, policy_loss: 0.011085609
Policy train: iteration: 10000, policy_loss: 0.010298135
IDM train: iteration: 500, idm_loss: 0.10423134
IDM train: iteration: 1000, idm_loss: 0.10249418
IDM train: iteration: 1500, idm_loss: 0.09055546
IDM train: iteration: 2000, idm_loss: 0.07411141
IDM train: iteration: 2500, idm_loss: 0.09021494
IDM train: iteration: 3000, idm_loss: 0.09750052
IDM train: iteration: 3500, idm_loss: 0.10583757
IDM train: iteration: 4000, idm_loss: 0.065039635
IDM train: iteration: 4500, idm_loss: 0.10503611
IDM train: iteration: 5000, idm_loss: 0.071759775
IDM train: iteration: 5500, idm_loss: 0.07046233
IDM train: iteration: 6000, idm_loss: 0.10316764
IDM train: iteration: 6500, idm_loss: 0.093751736
IDM train: iteration: 7000, idm_loss: 0.08543566
IDM train: iteration: 7500, idm_loss: 0.062445078
IDM train: iteration: 8000, idm_loss: 0.09997225
IDM train: iteration: 8500, idm_loss: 0.08451261
IDM train: iteration: 9000, idm_loss: 0.07932637
IDM train: iteration: 9500, idm_loss: 0.09697941
IDM train: iteration: 10000, idm_loss: 0.06573328

iteration: 22, total_reward: -117.57884859857771, policy_loss: 0.055329718, idm_loss: 0.11855586

Policy train: iteration: 500, policy_loss: 0.018735237
Policy train: iteration: 1000, policy_loss: 0.013251973
Policy train: iteration: 1500, policy_loss: 0.012527014
Policy train: iteration: 2000, policy_loss: 0.015179092
Policy train: iteration: 2500, policy_loss: 0.0217433
Policy train: iteration: 3000, policy_loss: 0.01066159
Policy train: iteration: 3500, policy_loss: 0.02388293
Policy train: iteration: 4000, policy_loss: 0.012744483
Policy train: iteration: 4500, policy_loss: 0.01112639
Policy train: iteration: 5000, policy_loss: 0.016173385
Policy train: iteration: 5500, policy_loss: 0.021086328
Policy train: iteration: 6000, policy_loss: 0.013473834
Policy train: iteration: 6500, policy_loss: 0.02181055
Policy train: iteration: 7000, policy_loss: 0.015710311
Policy train: iteration: 7500, policy_loss: 0.015127515
Policy train: iteration: 8000, policy_loss: 0.015100222
Policy train: iteration: 8500, policy_loss: 0.01713289
Policy train: iteration: 9000, policy_loss: 0.011218179
Policy train: iteration: 9500, policy_loss: 0.0141704
Policy train: iteration: 10000, policy_loss: 0.013292838
IDM train: iteration: 500, idm_loss: 0.09318231
IDM train: iteration: 1000, idm_loss: 0.106413454
IDM train: iteration: 1500, idm_loss: 0.083331615
IDM train: iteration: 2000, idm_loss: 0.08284347
IDM train: iteration: 2500, idm_loss: 0.11466333
IDM train: iteration: 3000, idm_loss: 0.08942711
IDM train: iteration: 3500, idm_loss: 0.07973191
IDM train: iteration: 4000, idm_loss: 0.0874098
IDM train: iteration: 4500, idm_loss: 0.10312548
IDM train: iteration: 5000, idm_loss: 0.069223255
IDM train: iteration: 5500, idm_loss: 0.09886561
IDM train: iteration: 6000, idm_loss: 0.06153671
IDM train: iteration: 6500, idm_loss: 0.0918767
IDM train: iteration: 7000, idm_loss: 0.06549758
IDM train: iteration: 7500, idm_loss: 0.092900366
IDM train: iteration: 8000, idm_loss: 0.09426205
IDM train: iteration: 8500, idm_loss: 0.0704811
IDM train: iteration: 9000, idm_loss: 0.078227565
IDM train: iteration: 9500, idm_loss: 0.08962288
IDM train: iteration: 10000, idm_loss: 0.10870664

iteration: 23, total_reward: -61.84935575762821, policy_loss: 0.030440668, idm_loss: 0.058418557

Policy train: iteration: 500, policy_loss: 0.011779355
Policy train: iteration: 1000, policy_loss: 0.01047637
Policy train: iteration: 1500, policy_loss: 0.015066191
Policy train: iteration: 2000, policy_loss: 0.011938298
Policy train: iteration: 2500, policy_loss: 0.015292347
Policy train: iteration: 3000, policy_loss: 0.020024076
Policy train: iteration: 3500, policy_loss: 0.0119796395
Policy train: iteration: 4000, policy_loss: 0.01291525
Policy train: iteration: 4500, policy_loss: 0.011434188
Policy train: iteration: 5000, policy_loss: 0.015510792
Policy train: iteration: 5500, policy_loss: 0.013233045
Policy train: iteration: 6000, policy_loss: 0.012498165
Policy train: iteration: 6500, policy_loss: 0.010661746
Policy train: iteration: 7000, policy_loss: 0.015149541
Policy train: iteration: 7500, policy_loss: 0.011219153
Policy train: iteration: 8000, policy_loss: 0.012487406
Policy train: iteration: 8500, policy_loss: 0.009883084
Policy train: iteration: 9000, policy_loss: 0.01699392
Policy train: iteration: 9500, policy_loss: 0.011555357
Policy train: iteration: 10000, policy_loss: 0.011732109
IDM train: iteration: 500, idm_loss: 0.09837009
IDM train: iteration: 1000, idm_loss: 0.080649115
IDM train: iteration: 1500, idm_loss: 0.08476601
IDM train: iteration: 2000, idm_loss: 0.08983034
IDM train: iteration: 2500, idm_loss: 0.10939468
IDM train: iteration: 3000, idm_loss: 0.066251084
IDM train: iteration: 3500, idm_loss: 0.07172019
IDM train: iteration: 4000, idm_loss: 0.09005111
IDM train: iteration: 4500, idm_loss: 0.103871234
IDM train: iteration: 5000, idm_loss: 0.08915512
IDM train: iteration: 5500, idm_loss: 0.094302155
IDM train: iteration: 6000, idm_loss: 0.08724497
IDM train: iteration: 6500, idm_loss: 0.062648974
IDM train: iteration: 7000, idm_loss: 0.09162799
IDM train: iteration: 7500, idm_loss: 0.08086311
IDM train: iteration: 8000, idm_loss: 0.08139694
IDM train: iteration: 8500, idm_loss: 0.08469817
IDM train: iteration: 9000, idm_loss: 0.072160214
IDM train: iteration: 9500, idm_loss: 0.071442485
IDM train: iteration: 10000, idm_loss: 0.071577966

iteration: 24, total_reward: -79.26883616718527, policy_loss: 0.04244101, idm_loss: 0.07823012

Policy train: iteration: 500, policy_loss: 0.01730776
Policy train: iteration: 1000, policy_loss: 0.011706053
Policy train: iteration: 1500, policy_loss: 0.013279378
Policy train: iteration: 2000, policy_loss: 0.013550563
Policy train: iteration: 2500, policy_loss: 0.013340124
Policy train: iteration: 3000, policy_loss: 0.00847427
Policy train: iteration: 3500, policy_loss: 0.017092347
Policy train: iteration: 4000, policy_loss: 0.012600899
Policy train: iteration: 4500, policy_loss: 0.010563004
Policy train: iteration: 5000, policy_loss: 0.011979701
Policy train: iteration: 5500, policy_loss: 0.010787755
Policy train: iteration: 6000, policy_loss: 0.012625437
Policy train: iteration: 6500, policy_loss: 0.010797016
Policy train: iteration: 7000, policy_loss: 0.011205981
Policy train: iteration: 7500, policy_loss: 0.009703042
Policy train: iteration: 8000, policy_loss: 0.009927526
Policy train: iteration: 8500, policy_loss: 0.0075791636
Policy train: iteration: 9000, policy_loss: 0.011659719
Policy train: iteration: 9500, policy_loss: 0.012691121
Policy train: iteration: 10000, policy_loss: 0.011083608
IDM train: iteration: 500, idm_loss: 0.07772763
IDM train: iteration: 1000, idm_loss: 0.09923104
IDM train: iteration: 1500, idm_loss: 0.089593746
IDM train: iteration: 2000, idm_loss: 0.1013417
IDM train: iteration: 2500, idm_loss: 0.07868349
IDM train: iteration: 3000, idm_loss: 0.06797245
IDM train: iteration: 3500, idm_loss: 0.08114459
IDM train: iteration: 4000, idm_loss: 0.07105221
IDM train: iteration: 4500, idm_loss: 0.12472498
IDM train: iteration: 5000, idm_loss: 0.07404401
IDM train: iteration: 5500, idm_loss: 0.073273495
IDM train: iteration: 6000, idm_loss: 0.082029656
IDM train: iteration: 6500, idm_loss: 0.09318499
IDM train: iteration: 7000, idm_loss: 0.09261198
IDM train: iteration: 7500, idm_loss: 0.072694786
IDM train: iteration: 8000, idm_loss: 0.10412057
IDM train: iteration: 8500, idm_loss: 0.07177985
IDM train: iteration: 9000, idm_loss: 0.069854386
IDM train: iteration: 9500, idm_loss: 0.084024794
IDM train: iteration: 10000, idm_loss: 0.0815472

iteration: 25, total_reward: 95.32258061054361, policy_loss: 0.041034997, idm_loss: 0.08703996

Policy train: iteration: 500, policy_loss: 0.013428433
Policy train: iteration: 1000, policy_loss: 0.017377619
Policy train: iteration: 1500, policy_loss: 0.013681175
Policy train: iteration: 2000, policy_loss: 0.016181074
Policy train: iteration: 2500, policy_loss: 0.012665769
Policy train: iteration: 3000, policy_loss: 0.018930327
Policy train: iteration: 3500, policy_loss: 0.01606264
Policy train: iteration: 4000, policy_loss: 0.014415626
Policy train: iteration: 4500, policy_loss: 0.008158876
Policy train: iteration: 5000, policy_loss: 0.014896903
Policy train: iteration: 5500, policy_loss: 0.01786481
Policy train: iteration: 6000, policy_loss: 0.011527669
Policy train: iteration: 6500, policy_loss: 0.010027066
Policy train: iteration: 7000, policy_loss: 0.010058518
Policy train: iteration: 7500, policy_loss: 0.01571931
Policy train: iteration: 8000, policy_loss: 0.009363322
Policy train: iteration: 8500, policy_loss: 0.009557018
Policy train: iteration: 9000, policy_loss: 0.013158162
Policy train: iteration: 9500, policy_loss: 0.010533312
Policy train: iteration: 10000, policy_loss: 0.0114340875
IDM train: iteration: 500, idm_loss: 0.07463276
IDM train: iteration: 1000, idm_loss: 0.083586305
IDM train: iteration: 1500, idm_loss: 0.08647189
IDM train: iteration: 2000, idm_loss: 0.09667009
IDM train: iteration: 2500, idm_loss: 0.07888442
IDM train: iteration: 3000, idm_loss: 0.057370797
IDM train: iteration: 3500, idm_loss: 0.087505236
IDM train: iteration: 4000, idm_loss: 0.06827218
IDM train: iteration: 4500, idm_loss: 0.066823974
IDM train: iteration: 5000, idm_loss: 0.10978896
IDM train: iteration: 5500, idm_loss: 0.08678926
IDM train: iteration: 6000, idm_loss: 0.10845536
IDM train: iteration: 6500, idm_loss: 0.088609114
IDM train: iteration: 7000, idm_loss: 0.068923704
IDM train: iteration: 7500, idm_loss: 0.09508329
IDM train: iteration: 8000, idm_loss: 0.11137244
IDM train: iteration: 8500, idm_loss: 0.09112485
IDM train: iteration: 9000, idm_loss: 0.072738156
IDM train: iteration: 9500, idm_loss: 0.09956457
IDM train: iteration: 10000, idm_loss: 0.100722134

iteration: 26, total_reward: -88.25904939931942, policy_loss: 0.041238654, idm_loss: 0.09102385

Policy train: iteration: 500, policy_loss: 0.017283853
Policy train: iteration: 1000, policy_loss: 0.015430343
Policy train: iteration: 1500, policy_loss: 0.015536586
Policy train: iteration: 2000, policy_loss: 0.011727192
Policy train: iteration: 2500, policy_loss: 0.013201762
Policy train: iteration: 3000, policy_loss: 0.012686515
Policy train: iteration: 3500, policy_loss: 0.00849661
Policy train: iteration: 4000, policy_loss: 0.013284678
Policy train: iteration: 4500, policy_loss: 0.014057361
Policy train: iteration: 5000, policy_loss: 0.01708788
Policy train: iteration: 5500, policy_loss: 0.01028101
Policy train: iteration: 6000, policy_loss: 0.011857858
Policy train: iteration: 6500, policy_loss: 0.013745112
Policy train: iteration: 7000, policy_loss: 0.0210264
Policy train: iteration: 7500, policy_loss: 0.012642993
Policy train: iteration: 8000, policy_loss: 0.016980765
Policy train: iteration: 8500, policy_loss: 0.013271756
Policy train: iteration: 9000, policy_loss: 0.015703224
Policy train: iteration: 9500, policy_loss: 0.011799282
Policy train: iteration: 10000, policy_loss: 0.012707137
IDM train: iteration: 500, idm_loss: 0.07152828
IDM train: iteration: 1000, idm_loss: 0.06986578
IDM train: iteration: 1500, idm_loss: 0.08890192
IDM train: iteration: 2000, idm_loss: 0.10653918
IDM train: iteration: 2500, idm_loss: 0.08398218
IDM train: iteration: 3000, idm_loss: 0.08249362
IDM train: iteration: 3500, idm_loss: 0.08487223
IDM train: iteration: 4000, idm_loss: 0.0829669
IDM train: iteration: 4500, idm_loss: 0.080604255
IDM train: iteration: 5000, idm_loss: 0.0685384
IDM train: iteration: 5500, idm_loss: 0.07889822
IDM train: iteration: 6000, idm_loss: 0.077131204
IDM train: iteration: 6500, idm_loss: 0.058442708
IDM train: iteration: 7000, idm_loss: 0.083129436
IDM train: iteration: 7500, idm_loss: 0.08076768
IDM train: iteration: 8000, idm_loss: 0.08981774
IDM train: iteration: 8500, idm_loss: 0.08483747
IDM train: iteration: 9000, idm_loss: 0.07645242
IDM train: iteration: 9500, idm_loss: 0.07266271
IDM train: iteration: 10000, idm_loss: 0.08455698

iteration: 27, total_reward: -87.56019693017502, policy_loss: 0.0358194, idm_loss: 0.12019667

Policy train: iteration: 500, policy_loss: 0.012166858
Policy train: iteration: 1000, policy_loss: 0.018093012
Policy train: iteration: 1500, policy_loss: 0.01731445
Policy train: iteration: 2000, policy_loss: 0.014407031
Policy train: iteration: 2500, policy_loss: 0.012712106
Policy train: iteration: 3000, policy_loss: 0.013269516
Policy train: iteration: 3500, policy_loss: 0.009984797
Policy train: iteration: 4000, policy_loss: 0.014648807
Policy train: iteration: 4500, policy_loss: 0.014325444
Policy train: iteration: 5000, policy_loss: 0.012486841
Policy train: iteration: 5500, policy_loss: 0.015646808
Policy train: iteration: 6000, policy_loss: 0.017763093
Policy train: iteration: 6500, policy_loss: 0.017298777
Policy train: iteration: 7000, policy_loss: 0.016693385
Policy train: iteration: 7500, policy_loss: 0.01418093
Policy train: iteration: 8000, policy_loss: 0.012471781
Policy train: iteration: 8500, policy_loss: 0.013833321
Policy train: iteration: 9000, policy_loss: 0.009089805
Policy train: iteration: 9500, policy_loss: 0.012973903
Policy train: iteration: 10000, policy_loss: 0.010250574
IDM train: iteration: 500, idm_loss: 0.082259454
IDM train: iteration: 1000, idm_loss: 0.10555358
IDM train: iteration: 1500, idm_loss: 0.07807509
IDM train: iteration: 2000, idm_loss: 0.06411372
IDM train: iteration: 2500, idm_loss: 0.092089236
IDM train: iteration: 3000, idm_loss: 0.08047342
IDM train: iteration: 3500, idm_loss: 0.08003789
IDM train: iteration: 4000, idm_loss: 0.082042485
IDM train: iteration: 4500, idm_loss: 0.09383006
IDM train: iteration: 5000, idm_loss: 0.09800896
IDM train: iteration: 5500, idm_loss: 0.099260524
IDM train: iteration: 6000, idm_loss: 0.07165496
IDM train: iteration: 6500, idm_loss: 0.08044289
IDM train: iteration: 7000, idm_loss: 0.08386179
IDM train: iteration: 7500, idm_loss: 0.083424166
IDM train: iteration: 8000, idm_loss: 0.105289936
IDM train: iteration: 8500, idm_loss: 0.08189624
IDM train: iteration: 9000, idm_loss: 0.071875095
IDM train: iteration: 9500, idm_loss: 0.07224748
IDM train: iteration: 10000, idm_loss: 0.08986248

iteration: 28, total_reward: -75.64246195844316, policy_loss: 0.04373236, idm_loss: 0.052901015

Policy train: iteration: 500, policy_loss: 0.009472848
Policy train: iteration: 1000, policy_loss: 0.012532541
Policy train: iteration: 1500, policy_loss: 0.0185972
Policy train: iteration: 2000, policy_loss: 0.012566617
Policy train: iteration: 2500, policy_loss: 0.007511168
Policy train: iteration: 3000, policy_loss: 0.011930954
Policy train: iteration: 3500, policy_loss: 0.010166304
Policy train: iteration: 4000, policy_loss: 0.008240997
Policy train: iteration: 4500, policy_loss: 0.0071644476
Policy train: iteration: 5000, policy_loss: 0.00883388
Policy train: iteration: 5500, policy_loss: 0.011294701
Policy train: iteration: 6000, policy_loss: 0.010389922
Policy train: iteration: 6500, policy_loss: 0.007685289
Policy train: iteration: 7000, policy_loss: 0.010871364
Policy train: iteration: 7500, policy_loss: 0.007373568
Policy train: iteration: 8000, policy_loss: 0.011886106
Policy train: iteration: 8500, policy_loss: 0.008785487
Policy train: iteration: 9000, policy_loss: 0.014197921
Policy train: iteration: 9500, policy_loss: 0.0074558677
Policy train: iteration: 10000, policy_loss: 0.007823147
IDM train: iteration: 500, idm_loss: 0.097128406
IDM train: iteration: 1000, idm_loss: 0.07863556
IDM train: iteration: 1500, idm_loss: 0.08120319
IDM train: iteration: 2000, idm_loss: 0.056459628
IDM train: iteration: 2500, idm_loss: 0.07661648
IDM train: iteration: 3000, idm_loss: 0.0715323
IDM train: iteration: 3500, idm_loss: 0.083866574
IDM train: iteration: 4000, idm_loss: 0.112569466
IDM train: iteration: 4500, idm_loss: 0.10512996
IDM train: iteration: 5000, idm_loss: 0.09481393
IDM train: iteration: 5500, idm_loss: 0.080415145
IDM train: iteration: 6000, idm_loss: 0.118830845
IDM train: iteration: 6500, idm_loss: 0.101336375
IDM train: iteration: 7000, idm_loss: 0.0775579
IDM train: iteration: 7500, idm_loss: 0.068330415
IDM train: iteration: 8000, idm_loss: 0.07459499
IDM train: iteration: 8500, idm_loss: 0.0811788
IDM train: iteration: 9000, idm_loss: 0.0604707
IDM train: iteration: 9500, idm_loss: 0.087637216
IDM train: iteration: 10000, idm_loss: 0.08327505

iteration: 29, total_reward: -53.73471103364787, policy_loss: 0.06540143, idm_loss: 0.072988324

Policy train: iteration: 500, policy_loss: 0.009104322
Policy train: iteration: 1000, policy_loss: 0.020324793
Policy train: iteration: 1500, policy_loss: 0.013013339
Policy train: iteration: 2000, policy_loss: 0.023215689
Policy train: iteration: 2500, policy_loss: 0.012218962
Policy train: iteration: 3000, policy_loss: 0.014691638
Policy train: iteration: 3500, policy_loss: 0.012574652
Policy train: iteration: 4000, policy_loss: 0.014183133
Policy train: iteration: 4500, policy_loss: 0.016038276
Policy train: iteration: 5000, policy_loss: 0.02129605
Policy train: iteration: 5500, policy_loss: 0.015605032
Policy train: iteration: 6000, policy_loss: 0.010407973
Policy train: iteration: 6500, policy_loss: 0.012915004
Policy train: iteration: 7000, policy_loss: 0.008516079
Policy train: iteration: 7500, policy_loss: 0.008446215
Policy train: iteration: 8000, policy_loss: 0.017408945
Policy train: iteration: 8500, policy_loss: 0.01791428
Policy train: iteration: 9000, policy_loss: 0.010342607
Policy train: iteration: 9500, policy_loss: 0.014189416
Policy train: iteration: 10000, policy_loss: 0.011739735
IDM train: iteration: 500, idm_loss: 0.092750944
IDM train: iteration: 1000, idm_loss: 0.10817516
IDM train: iteration: 1500, idm_loss: 0.07930588
IDM train: iteration: 2000, idm_loss: 0.08050138
IDM train: iteration: 2500, idm_loss: 0.09440788
IDM train: iteration: 3000, idm_loss: 0.084753945
IDM train: iteration: 3500, idm_loss: 0.093837604
IDM train: iteration: 4000, idm_loss: 0.08681451
IDM train: iteration: 4500, idm_loss: 0.07030783
IDM train: iteration: 5000, idm_loss: 0.08882308
IDM train: iteration: 5500, idm_loss: 0.081643865
IDM train: iteration: 6000, idm_loss: 0.077316254
IDM train: iteration: 6500, idm_loss: 0.075456366
IDM train: iteration: 7000, idm_loss: 0.08231533
IDM train: iteration: 7500, idm_loss: 0.09657693
IDM train: iteration: 8000, idm_loss: 0.06150423
IDM train: iteration: 8500, idm_loss: 0.060119957
IDM train: iteration: 9000, idm_loss: 0.083528064
IDM train: iteration: 9500, idm_loss: 0.05696859
IDM train: iteration: 10000, idm_loss: 0.09573703

iteration: 30, total_reward: -29.329116300291005, policy_loss: 0.05462924, idm_loss: 0.0893017

Policy train: iteration: 500, policy_loss: 0.015091466
