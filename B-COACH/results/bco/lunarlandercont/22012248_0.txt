Collecting idm training data 1000
Collecting idm training data 2000
Collecting idm training data 3000
Collecting idm training data 4000
Collecting idm training data 5000
Collecting idm training data 6000
Collecting idm training data 7000
Collecting idm training data 8000
Collecting idm training data 9000
Collecting idm training data 10000
IDM train: iteration: 500, idm_loss: 0.330562
IDM train: iteration: 1000, idm_loss: 0.401897
IDM train: iteration: 1500, idm_loss: 0.236756
IDM train: iteration: 2000, idm_loss: 0.243337
IDM train: iteration: 2500, idm_loss: 0.181477
IDM train: iteration: 3000, idm_loss: 0.163530
IDM train: iteration: 3500, idm_loss: 0.140948
IDM train: iteration: 4000, idm_loss: 0.123970
IDM train: iteration: 4500, idm_loss: 0.132165
IDM train: iteration: 5000, idm_loss: 0.131097
Policy train: iteration: 500, policy_loss: 0.022824865
Policy train: iteration: 1000, policy_loss: 0.041333787
Policy train: iteration: 1500, policy_loss: 0.025640104
Policy train: iteration: 2000, policy_loss: 0.054701373
Policy train: iteration: 2500, policy_loss: 0.02010291
Policy train: iteration: 3000, policy_loss: 0.036626987
Policy train: iteration: 3500, policy_loss: 0.015812537
Policy train: iteration: 4000, policy_loss: 0.024715126
Policy train: iteration: 4500, policy_loss: 0.024218008
Policy train: iteration: 5000, policy_loss: 0.029709607
IDM train: iteration: 500, idm_loss: 0.087696
IDM train: iteration: 1000, idm_loss: 0.084446
IDM train: iteration: 1500, idm_loss: 0.103126
IDM train: iteration: 2000, idm_loss: 0.090687
IDM train: iteration: 2500, idm_loss: 0.116888
IDM train: iteration: 3000, idm_loss: 0.067523
IDM train: iteration: 3500, idm_loss: 0.096588
IDM train: iteration: 4000, idm_loss: 0.131910
IDM train: iteration: 4500, idm_loss: 0.082951
IDM train: iteration: 5000, idm_loss: 0.091002

iteration: 1, total_reward: 41.920393799683836, policy_loss: 0.046094183, idm_loss: 0.032829747

Policy train: iteration: 500, policy_loss: 0.018910354
Policy train: iteration: 1000, policy_loss: 0.024088025
Policy train: iteration: 1500, policy_loss: 0.07293546
Policy train: iteration: 2000, policy_loss: 0.027344955
Policy train: iteration: 2500, policy_loss: 0.016970979
Policy train: iteration: 3000, policy_loss: 0.0428936
Policy train: iteration: 3500, policy_loss: 0.03864274
Policy train: iteration: 4000, policy_loss: 0.059427947
Policy train: iteration: 4500, policy_loss: 0.032209076
Policy train: iteration: 5000, policy_loss: 0.05386438
IDM train: iteration: 500, idm_loss: 0.074218
IDM train: iteration: 1000, idm_loss: 0.092882
IDM train: iteration: 1500, idm_loss: 0.066903
IDM train: iteration: 2000, idm_loss: 0.129292
IDM train: iteration: 2500, idm_loss: 0.064818
IDM train: iteration: 3000, idm_loss: 0.081148
IDM train: iteration: 3500, idm_loss: 0.124975
IDM train: iteration: 4000, idm_loss: 0.060589
IDM train: iteration: 4500, idm_loss: 0.074723
IDM train: iteration: 5000, idm_loss: 0.065751

iteration: 2, total_reward: -38.18571109813487, policy_loss: 0.03491668, idm_loss: 0.107589096

Policy train: iteration: 500, policy_loss: 0.024627397
Policy train: iteration: 1000, policy_loss: 0.01784918
Policy train: iteration: 1500, policy_loss: 0.026373371
Policy train: iteration: 2000, policy_loss: 0.025328802
Policy train: iteration: 2500, policy_loss: 0.018345535
Policy train: iteration: 3000, policy_loss: 0.029289462
Policy train: iteration: 3500, policy_loss: 0.023004217
Policy train: iteration: 4000, policy_loss: 0.033181783
Policy train: iteration: 4500, policy_loss: 0.030979251
Policy train: iteration: 5000, policy_loss: 0.026106145
IDM train: iteration: 500, idm_loss: 0.075558
IDM train: iteration: 1000, idm_loss: 0.077593
IDM train: iteration: 1500, idm_loss: 0.094724
IDM train: iteration: 2000, idm_loss: 0.062564
IDM train: iteration: 2500, idm_loss: 0.075307
IDM train: iteration: 3000, idm_loss: 0.079194
IDM train: iteration: 3500, idm_loss: 0.074464
IDM train: iteration: 4000, idm_loss: 0.072720
IDM train: iteration: 4500, idm_loss: 0.140478
IDM train: iteration: 5000, idm_loss: 0.088710

iteration: 3, total_reward: -1.125490281856699, policy_loss: 0.034200635, idm_loss: 0.053615678

Policy train: iteration: 500, policy_loss: 0.005371278
Policy train: iteration: 1000, policy_loss: 0.018941432
Policy train: iteration: 1500, policy_loss: 0.022904478
Policy train: iteration: 2000, policy_loss: 0.018026263
Policy train: iteration: 2500, policy_loss: 0.019708628
Policy train: iteration: 3000, policy_loss: 0.031050734
Policy train: iteration: 3500, policy_loss: 0.020639133
Policy train: iteration: 4000, policy_loss: 0.02941298
Policy train: iteration: 4500, policy_loss: 0.030804776
Policy train: iteration: 5000, policy_loss: 0.013707168
IDM train: iteration: 500, idm_loss: 0.080649
IDM train: iteration: 1000, idm_loss: 0.071570
IDM train: iteration: 1500, idm_loss: 0.085638
IDM train: iteration: 2000, idm_loss: 0.064300
IDM train: iteration: 2500, idm_loss: 0.054585
IDM train: iteration: 3000, idm_loss: 0.060505
IDM train: iteration: 3500, idm_loss: 0.081041
IDM train: iteration: 4000, idm_loss: 0.109715
IDM train: iteration: 4500, idm_loss: 0.108019
IDM train: iteration: 5000, idm_loss: 0.069274

iteration: 4, total_reward: -38.10123061211799, policy_loss: 0.028636886, idm_loss: 0.08254572

Policy train: iteration: 500, policy_loss: 0.019825228
Policy train: iteration: 1000, policy_loss: 0.018185634
Policy train: iteration: 1500, policy_loss: 0.030612253
Policy train: iteration: 2000, policy_loss: 0.017015401
Policy train: iteration: 2500, policy_loss: 0.028435087
Policy train: iteration: 3000, policy_loss: 0.031019684
Policy train: iteration: 3500, policy_loss: 0.017348524
Policy train: iteration: 4000, policy_loss: 0.02201949
Policy train: iteration: 4500, policy_loss: 0.01922207
Policy train: iteration: 5000, policy_loss: 0.025879579
IDM train: iteration: 500, idm_loss: 0.146653
IDM train: iteration: 1000, idm_loss: 0.095377
IDM train: iteration: 1500, idm_loss: 0.069162
IDM train: iteration: 2000, idm_loss: 0.069888
IDM train: iteration: 2500, idm_loss: 0.055146
IDM train: iteration: 3000, idm_loss: 0.081457
IDM train: iteration: 3500, idm_loss: 0.057713
IDM train: iteration: 4000, idm_loss: 0.078560
IDM train: iteration: 4500, idm_loss: 0.088319
IDM train: iteration: 5000, idm_loss: 0.095261

iteration: 5, total_reward: -55.840685562056706, policy_loss: 0.032093905, idm_loss: 0.08901164

Policy train: iteration: 500, policy_loss: 0.012826413
Policy train: iteration: 1000, policy_loss: 0.036924113
Policy train: iteration: 1500, policy_loss: 0.015529015
Policy train: iteration: 2000, policy_loss: 0.020793216
Policy train: iteration: 2500, policy_loss: 0.014704018
Policy train: iteration: 3000, policy_loss: 0.021391485
Policy train: iteration: 3500, policy_loss: 0.02479226
Policy train: iteration: 4000, policy_loss: 0.012733255
Policy train: iteration: 4500, policy_loss: 0.023026302
Policy train: iteration: 5000, policy_loss: 0.015799917
IDM train: iteration: 500, idm_loss: 0.064573
IDM train: iteration: 1000, idm_loss: 0.118751
IDM train: iteration: 1500, idm_loss: 0.070265
IDM train: iteration: 2000, idm_loss: 0.080199
IDM train: iteration: 2500, idm_loss: 0.057751
IDM train: iteration: 3000, idm_loss: 0.084083
IDM train: iteration: 3500, idm_loss: 0.048753
IDM train: iteration: 4000, idm_loss: 0.072725
IDM train: iteration: 4500, idm_loss: 0.087973
IDM train: iteration: 5000, idm_loss: 0.056031

iteration: 6, total_reward: 10.771462711308686, policy_loss: 0.055516373, idm_loss: 0.063796066

Policy train: iteration: 500, policy_loss: 0.026893578
Policy train: iteration: 1000, policy_loss: 0.03479401
Policy train: iteration: 1500, policy_loss: 0.027550027
Policy train: iteration: 2000, policy_loss: 0.02086934
Policy train: iteration: 2500, policy_loss: 0.015477605
Policy train: iteration: 3000, policy_loss: 0.017047035
Policy train: iteration: 3500, policy_loss: 0.014616049
Policy train: iteration: 4000, policy_loss: 0.02422483
Policy train: iteration: 4500, policy_loss: 0.025556693
Policy train: iteration: 5000, policy_loss: 0.014303256
IDM train: iteration: 500, idm_loss: 0.081907
IDM train: iteration: 1000, idm_loss: 0.066522
IDM train: iteration: 1500, idm_loss: 0.088475
IDM train: iteration: 2000, idm_loss: 0.164530
IDM train: iteration: 2500, idm_loss: 0.043246
IDM train: iteration: 3000, idm_loss: 0.045119
IDM train: iteration: 3500, idm_loss: 0.090556
IDM train: iteration: 4000, idm_loss: 0.085903
IDM train: iteration: 4500, idm_loss: 0.070320
IDM train: iteration: 5000, idm_loss: 0.062130

iteration: 7, total_reward: -20.247130873271033, policy_loss: 0.037359025, idm_loss: 0.07061321

Policy train: iteration: 500, policy_loss: 0.014161091
Policy train: iteration: 1000, policy_loss: 0.0142777935
Policy train: iteration: 1500, policy_loss: 0.008835791
Policy train: iteration: 2000, policy_loss: 0.01686321
Policy train: iteration: 2500, policy_loss: 0.02800088
Policy train: iteration: 3000, policy_loss: 0.021624926
Policy train: iteration: 3500, policy_loss: 0.023917014
Policy train: iteration: 4000, policy_loss: 0.01932466
Policy train: iteration: 4500, policy_loss: 0.018829957
Policy train: iteration: 5000, policy_loss: 0.011968528
IDM train: iteration: 500, idm_loss: 0.097876
IDM train: iteration: 1000, idm_loss: 0.071995
IDM train: iteration: 1500, idm_loss: 0.065915
IDM train: iteration: 2000, idm_loss: 0.066894
IDM train: iteration: 2500, idm_loss: 0.065372
IDM train: iteration: 3000, idm_loss: 0.060400
IDM train: iteration: 3500, idm_loss: 0.161051
IDM train: iteration: 4000, idm_loss: 0.071308
IDM train: iteration: 4500, idm_loss: 0.087208
IDM train: iteration: 5000, idm_loss: 0.096764

iteration: 8, total_reward: 48.97283772234576, policy_loss: 0.035832435, idm_loss: 0.09583071

Policy train: iteration: 500, policy_loss: 0.02221861
Policy train: iteration: 1000, policy_loss: 0.022158809
Policy train: iteration: 1500, policy_loss: 0.028623542
Policy train: iteration: 2000, policy_loss: 0.041680768
Policy train: iteration: 2500, policy_loss: 0.017190143
Policy train: iteration: 3000, policy_loss: 0.023831453
Policy train: iteration: 3500, policy_loss: 0.01915276
Policy train: iteration: 4000, policy_loss: 0.02440482
Policy train: iteration: 4500, policy_loss: 0.015319536
Policy train: iteration: 5000, policy_loss: 0.015109685
IDM train: iteration: 500, idm_loss: 0.062822
IDM train: iteration: 1000, idm_loss: 0.055494
IDM train: iteration: 1500, idm_loss: 0.147418
IDM train: iteration: 2000, idm_loss: 0.105335
IDM train: iteration: 2500, idm_loss: 0.054850
IDM train: iteration: 3000, idm_loss: 0.064761
IDM train: iteration: 3500, idm_loss: 0.100836
IDM train: iteration: 4000, idm_loss: 0.092421
IDM train: iteration: 4500, idm_loss: 0.046822
IDM train: iteration: 5000, idm_loss: 0.065825

iteration: 9, total_reward: -14.349550928724412, policy_loss: 0.035626613, idm_loss: 0.08704655

Policy train: iteration: 500, policy_loss: 0.017368544
Policy train: iteration: 1000, policy_loss: 0.017810352
Policy train: iteration: 1500, policy_loss: 0.024309216
Policy train: iteration: 2000, policy_loss: 0.013849847
Policy train: iteration: 2500, policy_loss: 0.021730661
Policy train: iteration: 3000, policy_loss: 0.019965135
Policy train: iteration: 3500, policy_loss: 0.021966595
Policy train: iteration: 4000, policy_loss: 0.025917374
Policy train: iteration: 4500, policy_loss: 0.02047873
Policy train: iteration: 5000, policy_loss: 0.01317616
IDM train: iteration: 500, idm_loss: 0.071360
IDM train: iteration: 1000, idm_loss: 0.085261
IDM train: iteration: 1500, idm_loss: 0.075670
IDM train: iteration: 2000, idm_loss: 0.092648
IDM train: iteration: 2500, idm_loss: 0.114068
IDM train: iteration: 3000, idm_loss: 0.098906
IDM train: iteration: 3500, idm_loss: 0.053769
IDM train: iteration: 4000, idm_loss: 0.091509
IDM train: iteration: 4500, idm_loss: 0.054144
IDM train: iteration: 5000, idm_loss: 0.077532

iteration: 10, total_reward: -80.24081275611432, policy_loss: 0.02763388, idm_loss: 0.11366596

Policy train: iteration: 500, policy_loss: 0.028369242
Policy train: iteration: 1000, policy_loss: 0.017245077
Policy train: iteration: 1500, policy_loss: 0.022040457
Policy train: iteration: 2000, policy_loss: 0.024939075
Policy train: iteration: 2500, policy_loss: 0.023369296
Policy train: iteration: 3000, policy_loss: 0.02650394
Policy train: iteration: 3500, policy_loss: 0.020024661
Policy train: iteration: 4000, policy_loss: 0.015768452
Policy train: iteration: 4500, policy_loss: 0.008616286
Policy train: iteration: 5000, policy_loss: 0.0138405375
IDM train: iteration: 500, idm_loss: 0.063632
IDM train: iteration: 1000, idm_loss: 0.146902
IDM train: iteration: 1500, idm_loss: 0.066820
IDM train: iteration: 2000, idm_loss: 0.066557
IDM train: iteration: 2500, idm_loss: 0.059504
IDM train: iteration: 3000, idm_loss: 0.059693
IDM train: iteration: 3500, idm_loss: 0.088009
IDM train: iteration: 4000, idm_loss: 0.115510
IDM train: iteration: 4500, idm_loss: 0.078847
IDM train: iteration: 5000, idm_loss: 0.061741

iteration: 11, total_reward: 22.458137757813176, policy_loss: 0.038333558, idm_loss: 0.13401541

Policy train: iteration: 500, policy_loss: 0.019409914
Policy train: iteration: 1000, policy_loss: 0.022238534
Policy train: iteration: 1500, policy_loss: 0.02352476
Policy train: iteration: 2000, policy_loss: 0.01719025
Policy train: iteration: 2500, policy_loss: 0.017174667
Policy train: iteration: 3000, policy_loss: 0.016060041
Policy train: iteration: 3500, policy_loss: 0.019662183
Policy train: iteration: 4000, policy_loss: 0.008980505
Policy train: iteration: 4500, policy_loss: 0.012540428
Policy train: iteration: 5000, policy_loss: 0.008244572
IDM train: iteration: 500, idm_loss: 0.088916
IDM train: iteration: 1000, idm_loss: 0.082060
IDM train: iteration: 1500, idm_loss: 0.094897
IDM train: iteration: 2000, idm_loss: 0.074387
IDM train: iteration: 2500, idm_loss: 0.054182
IDM train: iteration: 3000, idm_loss: 0.047879
IDM train: iteration: 3500, idm_loss: 0.100612
IDM train: iteration: 4000, idm_loss: 0.069827
IDM train: iteration: 4500, idm_loss: 0.083413
IDM train: iteration: 5000, idm_loss: 0.058154

iteration: 12, total_reward: 254.95067786732793, policy_loss: 0.02671505, idm_loss: 0.05885616

Policy train: iteration: 500, policy_loss: 0.022191156
Policy train: iteration: 1000, policy_loss: 0.022937274
Policy train: iteration: 1500, policy_loss: 0.020365901
Policy train: iteration: 2000, policy_loss: 0.01221795
Policy train: iteration: 2500, policy_loss: 0.022407312
Policy train: iteration: 3000, policy_loss: 0.024421567
Policy train: iteration: 3500, policy_loss: 0.02364676
Policy train: iteration: 4000, policy_loss: 0.009944043
Policy train: iteration: 4500, policy_loss: 0.019452963
Policy train: iteration: 5000, policy_loss: 0.017903747
IDM train: iteration: 500, idm_loss: 0.055541
IDM train: iteration: 1000, idm_loss: 0.052424
IDM train: iteration: 1500, idm_loss: 0.130405
IDM train: iteration: 2000, idm_loss: 0.073380
IDM train: iteration: 2500, idm_loss: 0.077095
IDM train: iteration: 3000, idm_loss: 0.087100
IDM train: iteration: 3500, idm_loss: 0.058403
IDM train: iteration: 4000, idm_loss: 0.072296
IDM train: iteration: 4500, idm_loss: 0.098838
IDM train: iteration: 5000, idm_loss: 0.049072

iteration: 13, total_reward: -69.20049241295618, policy_loss: 0.037235055, idm_loss: 0.080271505

Policy train: iteration: 500, policy_loss: 0.016632576
Policy train: iteration: 1000, policy_loss: 0.01574836
Policy train: iteration: 1500, policy_loss: 0.024064977
Policy train: iteration: 2000, policy_loss: 0.014266528
Policy train: iteration: 2500, policy_loss: 0.017341137
Policy train: iteration: 3000, policy_loss: 0.016689433
Policy train: iteration: 3500, policy_loss: 0.017515711
Policy train: iteration: 4000, policy_loss: 0.023585044
Policy train: iteration: 4500, policy_loss: 0.019837297
Policy train: iteration: 5000, policy_loss: 0.01180813
IDM train: iteration: 500, idm_loss: 0.108000
IDM train: iteration: 1000, idm_loss: 0.116120
IDM train: iteration: 1500, idm_loss: 0.060012
IDM train: iteration: 2000, idm_loss: 0.063937
IDM train: iteration: 2500, idm_loss: 0.080811
IDM train: iteration: 3000, idm_loss: 0.088089
IDM train: iteration: 3500, idm_loss: 0.086064
IDM train: iteration: 4000, idm_loss: 0.065333
IDM train: iteration: 4500, idm_loss: 0.063402
IDM train: iteration: 5000, idm_loss: 0.082871

iteration: 14, total_reward: -251.1155495158213, policy_loss: 0.02577256, idm_loss: 0.10430485

Policy train: iteration: 500, policy_loss: 0.030702759
Policy train: iteration: 1000, policy_loss: 0.014118688
Policy train: iteration: 1500, policy_loss: 0.010259902
Policy train: iteration: 2000, policy_loss: 0.02131472
Policy train: iteration: 2500, policy_loss: 0.013744449
Policy train: iteration: 3000, policy_loss: 0.02118975
Policy train: iteration: 3500, policy_loss: 0.013999333
Policy train: iteration: 4000, policy_loss: 0.02170614
Policy train: iteration: 4500, policy_loss: 0.012413979
Policy train: iteration: 5000, policy_loss: 0.010386696
IDM train: iteration: 500, idm_loss: 0.044744
IDM train: iteration: 1000, idm_loss: 0.111690
IDM train: iteration: 1500, idm_loss: 0.068263
IDM train: iteration: 2000, idm_loss: 0.059889
IDM train: iteration: 2500, idm_loss: 0.072791
IDM train: iteration: 3000, idm_loss: 0.072395
IDM train: iteration: 3500, idm_loss: 0.066222
IDM train: iteration: 4000, idm_loss: 0.048760
IDM train: iteration: 4500, idm_loss: 0.055059
IDM train: iteration: 5000, idm_loss: 0.070147

iteration: 15, total_reward: -145.22115764515559, policy_loss: 0.023968434, idm_loss: 0.110376246

Policy train: iteration: 500, policy_loss: 0.012440428
Policy train: iteration: 1000, policy_loss: 0.021564357
Policy train: iteration: 1500, policy_loss: 0.025306698
Policy train: iteration: 2000, policy_loss: 0.010947071
Policy train: iteration: 2500, policy_loss: 0.014266293
Policy train: iteration: 3000, policy_loss: 0.02893586
Policy train: iteration: 3500, policy_loss: 0.01783808
Policy train: iteration: 4000, policy_loss: 0.010718408
Policy train: iteration: 4500, policy_loss: 0.020787388
Policy train: iteration: 5000, policy_loss: 0.018009152
IDM train: iteration: 500, idm_loss: 0.070866
IDM train: iteration: 1000, idm_loss: 0.042731
IDM train: iteration: 1500, idm_loss: 0.063871
IDM train: iteration: 2000, idm_loss: 0.063601
IDM train: iteration: 2500, idm_loss: 0.067478
IDM train: iteration: 3000, idm_loss: 0.079262
IDM train: iteration: 3500, idm_loss: 0.091110
IDM train: iteration: 4000, idm_loss: 0.065778
IDM train: iteration: 4500, idm_loss: 0.053867
IDM train: iteration: 5000, idm_loss: 0.077816

iteration: 16, total_reward: -36.84067323314348, policy_loss: 0.020366583, idm_loss: 0.07989488

Policy train: iteration: 500, policy_loss: 0.015429366
Policy train: iteration: 1000, policy_loss: 0.008484534
Policy train: iteration: 1500, policy_loss: 0.0070544323
Policy train: iteration: 2000, policy_loss: 0.023680583
Policy train: iteration: 2500, policy_loss: 0.0136108
Policy train: iteration: 3000, policy_loss: 0.008938085
Policy train: iteration: 3500, policy_loss: 0.01495545
Policy train: iteration: 4000, policy_loss: 0.015138146
Policy train: iteration: 4500, policy_loss: 0.01858469
Policy train: iteration: 5000, policy_loss: 0.028505884
IDM train: iteration: 500, idm_loss: 0.068427
IDM train: iteration: 1000, idm_loss: 0.093671
IDM train: iteration: 1500, idm_loss: 0.103147
IDM train: iteration: 2000, idm_loss: 0.067264
IDM train: iteration: 2500, idm_loss: 0.054966
IDM train: iteration: 3000, idm_loss: 0.059527
IDM train: iteration: 3500, idm_loss: 0.043498
IDM train: iteration: 4000, idm_loss: 0.050340
IDM train: iteration: 4500, idm_loss: 0.068174
IDM train: iteration: 5000, idm_loss: 0.063699

iteration: 17, total_reward: -71.89657503486055, policy_loss: 0.031691413, idm_loss: 0.057766184

Policy train: iteration: 500, policy_loss: 0.018027306
Policy train: iteration: 1000, policy_loss: 0.013176335
Policy train: iteration: 1500, policy_loss: 0.015690478
Policy train: iteration: 2000, policy_loss: 0.008391841
Policy train: iteration: 2500, policy_loss: 0.013303973
Policy train: iteration: 3000, policy_loss: 0.012658969
Policy train: iteration: 3500, policy_loss: 0.010793805
Policy train: iteration: 4000, policy_loss: 0.010830751
Policy train: iteration: 4500, policy_loss: 0.009552035
Policy train: iteration: 5000, policy_loss: 0.021854078
IDM train: iteration: 500, idm_loss: 0.101130
IDM train: iteration: 1000, idm_loss: 0.069007
IDM train: iteration: 1500, idm_loss: 0.049812
IDM train: iteration: 2000, idm_loss: 0.068749
IDM train: iteration: 2500, idm_loss: 0.095972
IDM train: iteration: 3000, idm_loss: 0.063859
IDM train: iteration: 3500, idm_loss: 0.115933
IDM train: iteration: 4000, idm_loss: 0.072629
IDM train: iteration: 4500, idm_loss: 0.056191
IDM train: iteration: 5000, idm_loss: 0.066709

iteration: 18, total_reward: 192.35368442550623, policy_loss: 0.032333147, idm_loss: 0.05875785

Policy train: iteration: 500, policy_loss: 0.02013165
Policy train: iteration: 1000, policy_loss: 0.012789408
Policy train: iteration: 1500, policy_loss: 0.021398917
Policy train: iteration: 2000, policy_loss: 0.012667765
Policy train: iteration: 2500, policy_loss: 0.018593721
Policy train: iteration: 3000, policy_loss: 0.023297625
Policy train: iteration: 3500, policy_loss: 0.016669728
Policy train: iteration: 4000, policy_loss: 0.021543134
Policy train: iteration: 4500, policy_loss: 0.016465614
Policy train: iteration: 5000, policy_loss: 0.012767881
IDM train: iteration: 500, idm_loss: 0.054382
IDM train: iteration: 1000, idm_loss: 0.076861
IDM train: iteration: 1500, idm_loss: 0.068752
IDM train: iteration: 2000, idm_loss: 0.077445
IDM train: iteration: 2500, idm_loss: 0.084859
IDM train: iteration: 3000, idm_loss: 0.125260
IDM train: iteration: 3500, idm_loss: 0.129387
IDM train: iteration: 4000, idm_loss: 0.048547
IDM train: iteration: 4500, idm_loss: 0.133315
IDM train: iteration: 5000, idm_loss: 0.061557

iteration: 19, total_reward: 42.41572208261039, policy_loss: 0.036651, idm_loss: 0.10002016

Policy train: iteration: 500, policy_loss: 0.014387043
Policy train: iteration: 1000, policy_loss: 0.012298861
Policy train: iteration: 1500, policy_loss: 0.016057916
Policy train: iteration: 2000, policy_loss: 0.00842311
Policy train: iteration: 2500, policy_loss: 0.0100495145
Policy train: iteration: 3000, policy_loss: 0.013865529
Policy train: iteration: 3500, policy_loss: 0.0147134885
Policy train: iteration: 4000, policy_loss: 0.01088383
Policy train: iteration: 4500, policy_loss: 0.012885666
Policy train: iteration: 5000, policy_loss: 0.0138297975
IDM train: iteration: 500, idm_loss: 0.069775
IDM train: iteration: 1000, idm_loss: 0.058579
IDM train: iteration: 1500, idm_loss: 0.074648
IDM train: iteration: 2000, idm_loss: 0.078813
IDM train: iteration: 2500, idm_loss: 0.072222
IDM train: iteration: 3000, idm_loss: 0.099307
IDM train: iteration: 3500, idm_loss: 0.068331
IDM train: iteration: 4000, idm_loss: 0.093513
IDM train: iteration: 4500, idm_loss: 0.064717
IDM train: iteration: 5000, idm_loss: 0.101568

iteration: 20, total_reward: -11.39097844091377, policy_loss: 0.022521485, idm_loss: 0.040613852

Policy train: iteration: 500, policy_loss: 0.009775932
Policy train: iteration: 1000, policy_loss: 0.0051267175
Policy train: iteration: 1500, policy_loss: 0.013301279
Policy train: iteration: 2000, policy_loss: 0.012695703
Policy train: iteration: 2500, policy_loss: 0.0061508575
Policy train: iteration: 3000, policy_loss: 0.008310178
Policy train: iteration: 3500, policy_loss: 0.016443653
Policy train: iteration: 4000, policy_loss: 0.019118307
Policy train: iteration: 4500, policy_loss: 0.014531349
Policy train: iteration: 5000, policy_loss: 0.013400253
IDM train: iteration: 500, idm_loss: 0.120491
IDM train: iteration: 1000, idm_loss: 0.137878
IDM train: iteration: 1500, idm_loss: 0.059849
IDM train: iteration: 2000, idm_loss: 0.085827
IDM train: iteration: 2500, idm_loss: 0.067319
IDM train: iteration: 3000, idm_loss: 0.046525
IDM train: iteration: 3500, idm_loss: 0.070520
IDM train: iteration: 4000, idm_loss: 0.075519
IDM train: iteration: 4500, idm_loss: 0.052944
IDM train: iteration: 5000, idm_loss: 0.091057

iteration: 21, total_reward: 60.20326606285931, policy_loss: 0.02306591, idm_loss: 0.042939957

Policy train: iteration: 500, policy_loss: 0.01810494
Policy train: iteration: 1000, policy_loss: 0.010929201
Policy train: iteration: 1500, policy_loss: 0.015190776
Policy train: iteration: 2000, policy_loss: 0.0115544945
Policy train: iteration: 2500, policy_loss: 0.014738869
Policy train: iteration: 3000, policy_loss: 0.006665893
Policy train: iteration: 3500, policy_loss: 0.01854168
Policy train: iteration: 4000, policy_loss: 0.010691671
Policy train: iteration: 4500, policy_loss: 0.014957704
Policy train: iteration: 5000, policy_loss: 0.011372679
IDM train: iteration: 500, idm_loss: 0.081123
IDM train: iteration: 1000, idm_loss: 0.062569
IDM train: iteration: 1500, idm_loss: 0.068459
IDM train: iteration: 2000, idm_loss: 0.079757
IDM train: iteration: 2500, idm_loss: 0.092084
IDM train: iteration: 3000, idm_loss: 0.050058
IDM train: iteration: 3500, idm_loss: 0.060907
IDM train: iteration: 4000, idm_loss: 0.051172
IDM train: iteration: 4500, idm_loss: 0.089445
IDM train: iteration: 5000, idm_loss: 0.050414

iteration: 22, total_reward: 14.33053657482668, policy_loss: 0.021283831, idm_loss: 0.11459171

Policy train: iteration: 500, policy_loss: 0.009421516
Policy train: iteration: 1000, policy_loss: 0.0037105042
Policy train: iteration: 1500, policy_loss: 0.00921846
Policy train: iteration: 2000, policy_loss: 0.017270742
Policy train: iteration: 2500, policy_loss: 0.026141219
Policy train: iteration: 3000, policy_loss: 0.025715142
Policy train: iteration: 3500, policy_loss: 0.00655704
Policy train: iteration: 4000, policy_loss: 0.010286388
Policy train: iteration: 4500, policy_loss: 0.016029779
Policy train: iteration: 5000, policy_loss: 0.0120492205
IDM train: iteration: 500, idm_loss: 0.042552
IDM train: iteration: 1000, idm_loss: 0.058131
IDM train: iteration: 1500, idm_loss: 0.059820
IDM train: iteration: 2000, idm_loss: 0.079951
IDM train: iteration: 2500, idm_loss: 0.053736
IDM train: iteration: 3000, idm_loss: 0.050028
IDM train: iteration: 3500, idm_loss: 0.060884
IDM train: iteration: 4000, idm_loss: 0.109790
IDM train: iteration: 4500, idm_loss: 0.050900
IDM train: iteration: 5000, idm_loss: 0.056725

iteration: 23, total_reward: 63.64604334901472, policy_loss: 0.034484092, idm_loss: 0.059071586

Policy train: iteration: 500, policy_loss: 0.014207186
Policy train: iteration: 1000, policy_loss: 0.016400997
Policy train: iteration: 1500, policy_loss: 0.018531062
Policy train: iteration: 2000, policy_loss: 0.015988268
Policy train: iteration: 2500, policy_loss: 0.008839605
Policy train: iteration: 3000, policy_loss: 0.0077303187
Policy train: iteration: 3500, policy_loss: 0.015927352
Policy train: iteration: 4000, policy_loss: 0.018949576
Policy train: iteration: 4500, policy_loss: 0.013090145
Policy train: iteration: 5000, policy_loss: 0.017406832
IDM train: iteration: 500, idm_loss: 0.061810
IDM train: iteration: 1000, idm_loss: 0.064852
IDM train: iteration: 1500, idm_loss: 0.050742
IDM train: iteration: 2000, idm_loss: 0.055544
IDM train: iteration: 2500, idm_loss: 0.060330
IDM train: iteration: 3000, idm_loss: 0.059044
IDM train: iteration: 3500, idm_loss: 0.067751
IDM train: iteration: 4000, idm_loss: 0.059544
IDM train: iteration: 4500, idm_loss: 0.063441
IDM train: iteration: 5000, idm_loss: 0.100728

iteration: 24, total_reward: -187.38010048377876, policy_loss: 0.035232116, idm_loss: 0.035257243

Policy train: iteration: 500, policy_loss: 0.019723935
Policy train: iteration: 1000, policy_loss: 0.012715607
Policy train: iteration: 1500, policy_loss: 0.016599346
Policy train: iteration: 2000, policy_loss: 0.009388566
Policy train: iteration: 2500, policy_loss: 0.0129394345
Policy train: iteration: 3000, policy_loss: 0.01157699
Policy train: iteration: 3500, policy_loss: 0.017131738
Policy train: iteration: 4000, policy_loss: 0.020513944
Policy train: iteration: 4500, policy_loss: 0.012645386
Policy train: iteration: 5000, policy_loss: 0.0145772435
IDM train: iteration: 500, idm_loss: 0.071186
IDM train: iteration: 1000, idm_loss: 0.065434
IDM train: iteration: 1500, idm_loss: 0.042220
IDM train: iteration: 2000, idm_loss: 0.076830
IDM train: iteration: 2500, idm_loss: 0.060687
IDM train: iteration: 3000, idm_loss: 0.066604
IDM train: iteration: 3500, idm_loss: 0.048574
IDM train: iteration: 4000, idm_loss: 0.065460
IDM train: iteration: 4500, idm_loss: 0.081050
IDM train: iteration: 5000, idm_loss: 0.068907

iteration: 25, total_reward: 242.96335012278786, policy_loss: 0.032864343, idm_loss: 0.048603825

Policy train: iteration: 500, policy_loss: 0.009694616
Policy train: iteration: 1000, policy_loss: 0.012165589
Policy train: iteration: 1500, policy_loss: 0.017303482
Policy train: iteration: 2000, policy_loss: 0.007792025
Policy train: iteration: 2500, policy_loss: 0.012995235
Policy train: iteration: 3000, policy_loss: 0.01680258
Policy train: iteration: 3500, policy_loss: 0.02973736
Policy train: iteration: 4000, policy_loss: 0.010248022
Policy train: iteration: 4500, policy_loss: 0.004751787
Policy train: iteration: 5000, policy_loss: 0.010185928
IDM train: iteration: 500, idm_loss: 0.059019
IDM train: iteration: 1000, idm_loss: 0.066701
IDM train: iteration: 1500, idm_loss: 0.051631
IDM train: iteration: 2000, idm_loss: 0.081975
IDM train: iteration: 2500, idm_loss: 0.056310
IDM train: iteration: 3000, idm_loss: 0.067460
IDM train: iteration: 3500, idm_loss: 0.052989
IDM train: iteration: 4000, idm_loss: 0.051696
IDM train: iteration: 4500, idm_loss: 0.054930
IDM train: iteration: 5000, idm_loss: 0.055688

iteration: 26, total_reward: 153.42061308051913, policy_loss: 0.028113205, idm_loss: 0.045046672

Policy train: iteration: 500, policy_loss: 0.012157955
Policy train: iteration: 1000, policy_loss: 0.010205137
Policy train: iteration: 1500, policy_loss: 0.009333414
Policy train: iteration: 2000, policy_loss: 0.0091151595
