Collecting idm training data 1000
Collecting idm training data 2000
Collecting idm training data 3000
Collecting idm training data 4000
Collecting idm training data 5000
Collecting idm training data 6000
Collecting idm training data 7000
Collecting idm training data 8000
Collecting idm training data 9000
Collecting idm training data 10000
IDM train: iteration: 500, idm_loss: 0.334813
IDM train: iteration: 1000, idm_loss: 0.387697
IDM train: iteration: 1500, idm_loss: 0.289562
IDM train: iteration: 2000, idm_loss: 0.266797
IDM train: iteration: 2500, idm_loss: 0.191195
IDM train: iteration: 3000, idm_loss: 0.134786
IDM train: iteration: 3500, idm_loss: 0.134004
IDM train: iteration: 4000, idm_loss: 0.124448
IDM train: iteration: 4500, idm_loss: 0.122166
IDM train: iteration: 5000, idm_loss: 0.078375
Policy train: iteration: 500, policy_loss: 0.054526776
Policy train: iteration: 1000, policy_loss: 0.048141282
Policy train: iteration: 1500, policy_loss: 0.030158827
Policy train: iteration: 2000, policy_loss: 0.042330023
Policy train: iteration: 2500, policy_loss: 0.036341514
Policy train: iteration: 3000, policy_loss: 0.047379576
Policy train: iteration: 3500, policy_loss: 0.044648964
Policy train: iteration: 4000, policy_loss: 0.03810629
Policy train: iteration: 4500, policy_loss: 0.022683047
Policy train: iteration: 5000, policy_loss: 0.03911689
IDM train: iteration: 500, idm_loss: 0.095222
IDM train: iteration: 1000, idm_loss: 0.081839
IDM train: iteration: 1500, idm_loss: 0.111139
IDM train: iteration: 2000, idm_loss: 0.065186
IDM train: iteration: 2500, idm_loss: 0.081570
IDM train: iteration: 3000, idm_loss: 0.054819
IDM train: iteration: 3500, idm_loss: 0.092442
IDM train: iteration: 4000, idm_loss: 0.087025
IDM train: iteration: 4500, idm_loss: 0.056006
IDM train: iteration: 5000, idm_loss: 0.087979

iteration: 1, total_reward: 13.035886685222692, policy_loss: 0.053027447, idm_loss: 0.11766223

Policy train: iteration: 500, policy_loss: 0.042774037
Policy train: iteration: 1000, policy_loss: 0.059786372
Policy train: iteration: 1500, policy_loss: 0.08717502
Policy train: iteration: 2000, policy_loss: 0.059359387
Policy train: iteration: 2500, policy_loss: 0.10755186
Policy train: iteration: 3000, policy_loss: 0.06966181
Policy train: iteration: 3500, policy_loss: 0.027189955
Policy train: iteration: 4000, policy_loss: 0.049099006
Policy train: iteration: 4500, policy_loss: 0.06389128
Policy train: iteration: 5000, policy_loss: 0.030610979
IDM train: iteration: 500, idm_loss: 0.066985
IDM train: iteration: 1000, idm_loss: 0.083378
IDM train: iteration: 1500, idm_loss: 0.083057
IDM train: iteration: 2000, idm_loss: 0.068817
IDM train: iteration: 2500, idm_loss: 0.106054
IDM train: iteration: 3000, idm_loss: 0.091563
IDM train: iteration: 3500, idm_loss: 0.069732
IDM train: iteration: 4000, idm_loss: 0.075270
IDM train: iteration: 4500, idm_loss: 0.077841
IDM train: iteration: 5000, idm_loss: 0.060880

iteration: 2, total_reward: 55.559827344945745, policy_loss: 0.04515851, idm_loss: 0.12914301

Policy train: iteration: 500, policy_loss: 0.05755637
Policy train: iteration: 1000, policy_loss: 0.045735974
Policy train: iteration: 1500, policy_loss: 0.041192528
Policy train: iteration: 2000, policy_loss: 0.05144731
Policy train: iteration: 2500, policy_loss: 0.03413615
Policy train: iteration: 3000, policy_loss: 0.017425098
Policy train: iteration: 3500, policy_loss: 0.041479044
Policy train: iteration: 4000, policy_loss: 0.03980881
Policy train: iteration: 4500, policy_loss: 0.024782524
Policy train: iteration: 5000, policy_loss: 0.038651392
IDM train: iteration: 500, idm_loss: 0.096496
IDM train: iteration: 1000, idm_loss: 0.076165
IDM train: iteration: 1500, idm_loss: 0.088600
IDM train: iteration: 2000, idm_loss: 0.082918
IDM train: iteration: 2500, idm_loss: 0.094481
IDM train: iteration: 3000, idm_loss: 0.115752
IDM train: iteration: 3500, idm_loss: 0.064811
IDM train: iteration: 4000, idm_loss: 0.087384
IDM train: iteration: 4500, idm_loss: 0.075279
IDM train: iteration: 5000, idm_loss: 0.095851

iteration: 3, total_reward: 250.0429503495243, policy_loss: 0.052387945, idm_loss: 0.08231398

Policy train: iteration: 500, policy_loss: 0.030917626
Policy train: iteration: 1000, policy_loss: 0.050955378
Policy train: iteration: 1500, policy_loss: 0.040729072
Policy train: iteration: 2000, policy_loss: 0.055798225
Policy train: iteration: 2500, policy_loss: 0.03238583
Policy train: iteration: 3000, policy_loss: 0.028146386
Policy train: iteration: 3500, policy_loss: 0.033341974
Policy train: iteration: 4000, policy_loss: 0.04322653
Policy train: iteration: 4500, policy_loss: 0.058986098
Policy train: iteration: 5000, policy_loss: 0.05971974
IDM train: iteration: 500, idm_loss: 0.112066
IDM train: iteration: 1000, idm_loss: 0.095477
IDM train: iteration: 1500, idm_loss: 0.116907
IDM train: iteration: 2000, idm_loss: 0.115340
IDM train: iteration: 2500, idm_loss: 0.047440
IDM train: iteration: 3000, idm_loss: 0.063314
IDM train: iteration: 3500, idm_loss: 0.069463
IDM train: iteration: 4000, idm_loss: 0.075948
IDM train: iteration: 4500, idm_loss: 0.087714
IDM train: iteration: 5000, idm_loss: 0.072492

iteration: 4, total_reward: 9.392608245293104, policy_loss: 0.039920032, idm_loss: 0.084006

Policy train: iteration: 500, policy_loss: 0.069759436
Policy train: iteration: 1000, policy_loss: 0.032514565
Policy train: iteration: 1500, policy_loss: 0.02556196
Policy train: iteration: 2000, policy_loss: 0.037066527
Policy train: iteration: 2500, policy_loss: 0.040410873
Policy train: iteration: 3000, policy_loss: 0.027285872
Policy train: iteration: 3500, policy_loss: 0.023721252
Policy train: iteration: 4000, policy_loss: 0.048553072
Policy train: iteration: 4500, policy_loss: 0.016729558
Policy train: iteration: 5000, policy_loss: 0.04037979
IDM train: iteration: 500, idm_loss: 0.090601
IDM train: iteration: 1000, idm_loss: 0.066726
IDM train: iteration: 1500, idm_loss: 0.091844
IDM train: iteration: 2000, idm_loss: 0.076471
IDM train: iteration: 2500, idm_loss: 0.060116
IDM train: iteration: 3000, idm_loss: 0.075486
IDM train: iteration: 3500, idm_loss: 0.101296
IDM train: iteration: 4000, idm_loss: 0.087794
IDM train: iteration: 4500, idm_loss: 0.053990
IDM train: iteration: 5000, idm_loss: 0.088457

iteration: 5, total_reward: 292.0335184108976, policy_loss: 0.046181105, idm_loss: 0.05733577

Policy train: iteration: 500, policy_loss: 0.032351464
Policy train: iteration: 1000, policy_loss: 0.020207085
Policy train: iteration: 1500, policy_loss: 0.02993117
Policy train: iteration: 2000, policy_loss: 0.019264929
Policy train: iteration: 2500, policy_loss: 0.023206621
Policy train: iteration: 3000, policy_loss: 0.028326385
Policy train: iteration: 3500, policy_loss: 0.03453234
Policy train: iteration: 4000, policy_loss: 0.0395613
Policy train: iteration: 4500, policy_loss: 0.02449143
Policy train: iteration: 5000, policy_loss: 0.028404688
IDM train: iteration: 500, idm_loss: 0.062502
IDM train: iteration: 1000, idm_loss: 0.068244
IDM train: iteration: 1500, idm_loss: 0.053438
IDM train: iteration: 2000, idm_loss: 0.065571
IDM train: iteration: 2500, idm_loss: 0.057401
IDM train: iteration: 3000, idm_loss: 0.076320
IDM train: iteration: 3500, idm_loss: 0.060812
IDM train: iteration: 4000, idm_loss: 0.074305
IDM train: iteration: 4500, idm_loss: 0.062638
IDM train: iteration: 5000, idm_loss: 0.061609

iteration: 6, total_reward: 266.5609172867581, policy_loss: 0.04120176, idm_loss: 0.057308994

Policy train: iteration: 500, policy_loss: 0.025501464
Policy train: iteration: 1000, policy_loss: 0.041710146
Policy train: iteration: 1500, policy_loss: 0.02965958
Policy train: iteration: 2000, policy_loss: 0.026996022
Policy train: iteration: 2500, policy_loss: 0.030416459
Policy train: iteration: 3000, policy_loss: 0.026866388
Policy train: iteration: 3500, policy_loss: 0.043802038
Policy train: iteration: 4000, policy_loss: 0.032663964
Policy train: iteration: 4500, policy_loss: 0.029003693
Policy train: iteration: 5000, policy_loss: 0.047516964
IDM train: iteration: 500, idm_loss: 0.081729
IDM train: iteration: 1000, idm_loss: 0.122510
IDM train: iteration: 1500, idm_loss: 0.066093
IDM train: iteration: 2000, idm_loss: 0.059280
IDM train: iteration: 2500, idm_loss: 0.054843
IDM train: iteration: 3000, idm_loss: 0.054818
IDM train: iteration: 3500, idm_loss: 0.058804
IDM train: iteration: 4000, idm_loss: 0.079312
IDM train: iteration: 4500, idm_loss: 0.082208
IDM train: iteration: 5000, idm_loss: 0.079073

iteration: 7, total_reward: 275.91943260520884, policy_loss: 0.029143732, idm_loss: 0.076512255

Policy train: iteration: 500, policy_loss: 0.022597471
Policy train: iteration: 1000, policy_loss: 0.03965681
Policy train: iteration: 1500, policy_loss: 0.030709993
Policy train: iteration: 2000, policy_loss: 0.01965002
Policy train: iteration: 2500, policy_loss: 0.022047417
Policy train: iteration: 3000, policy_loss: 0.04885634
Policy train: iteration: 3500, policy_loss: 0.024120264
Policy train: iteration: 4000, policy_loss: 0.030070443
Policy train: iteration: 4500, policy_loss: 0.0461314
Policy train: iteration: 5000, policy_loss: 0.026661493
IDM train: iteration: 500, idm_loss: 0.041930
IDM train: iteration: 1000, idm_loss: 0.066450
IDM train: iteration: 1500, idm_loss: 0.054106
IDM train: iteration: 2000, idm_loss: 0.080253
IDM train: iteration: 2500, idm_loss: 0.066055
IDM train: iteration: 3000, idm_loss: 0.049883
IDM train: iteration: 3500, idm_loss: 0.050495
IDM train: iteration: 4000, idm_loss: 0.067593
IDM train: iteration: 4500, idm_loss: 0.084840
IDM train: iteration: 5000, idm_loss: 0.059258

iteration: 8, total_reward: 246.14719258177908, policy_loss: 0.047586106, idm_loss: 0.08103275

Policy train: iteration: 500, policy_loss: 0.028903717
Policy train: iteration: 1000, policy_loss: 0.022046734
Policy train: iteration: 1500, policy_loss: 0.0275409
