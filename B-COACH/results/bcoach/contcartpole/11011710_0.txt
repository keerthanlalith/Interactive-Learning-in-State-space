Collecting idm training data 1000
IDM train: iteration: 500, idm_loss: 0.014387
IDM train: iteration: 1000, idm_loss: 0.000734

iteration: 1, total_reward: 52.0, policy_loss: 0.956388, idm_loss: 0.000004


iteration: 2, total_reward: 85.0, policy_loss: 0.962503, idm_loss: 0.000009


iteration: 3, total_reward: 48.0, policy_loss: 0.957532, idm_loss: 0.000022


iteration: 4, total_reward: 109.0, policy_loss: 0.958702, idm_loss: 0.000003


iteration: 5, total_reward: 48.0, policy_loss: 0.958418, idm_loss: 0.000025

Collecting idm training data 1000
IDM train: iteration: 500, idm_loss: 0.000510
IDM train: iteration: 1000, idm_loss: 0.000734

iteration: 6, total_reward: 73.0, policy_loss: 0.975533, idm_loss: 0.000000


iteration: 7, total_reward: 50.0, policy_loss: 0.981128, idm_loss: 0.000011


iteration: 8, total_reward: 52.0, policy_loss: 0.974705, idm_loss: 0.000000


iteration: 9, total_reward: 109.0, policy_loss: 0.976555, idm_loss: 0.000015


iteration: 10, total_reward: 63.0, policy_loss: 0.972100, idm_loss: 0.000011

Collecting idm training data 1000
IDM train: iteration: 500, idm_loss: 0.002633
IDM train: iteration: 1000, idm_loss: 0.000607

iteration: 11, total_reward: 61.0, policy_loss: 0.969754, idm_loss: 0.000015


iteration: 12, total_reward: 115.0, policy_loss: 0.917031, idm_loss: 0.000011


iteration: 13, total_reward: 395.0, policy_loss: 0.828660, idm_loss: 0.000014


iteration: 14, total_reward: 500.0, policy_loss: 0.821657, idm_loss: 0.000014


iteration: 15, total_reward: 500.0, policy_loss: 0.821401, idm_loss: 0.000031

Collecting idm training data 1000
IDM train: iteration: 500, idm_loss: 0.000171
IDM train: iteration: 1000, idm_loss: 0.000427

iteration: 16, total_reward: 500.0, policy_loss: 0.820681, idm_loss: 0.000000

