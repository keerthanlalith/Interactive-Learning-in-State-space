IDM train: iteration: 500, idm_loss: 1.0806742
IDM train: iteration: 1000, idm_loss: 1.0971544
IDM train: iteration: 1500, idm_loss: 1.0497209
IDM train: iteration: 2000, idm_loss: 1.1256952
IDM train: iteration: 2500, idm_loss: 1.1126214
IDM train: iteration: 3000, idm_loss: 1.1007851
IDM train: iteration: 3500, idm_loss: 1.0397329
IDM train: iteration: 4000, idm_loss: 1.0383902
Policy train: iteration: 500, policy_loss: 0.6409154
Policy train: iteration: 1000, policy_loss: 0.44997507
Policy train: iteration: 1500, policy_loss: 0.36129573
Policy train: iteration: 2000, policy_loss: 0.22184493
Policy train: iteration: 2500, policy_loss: 0.15105799
Policy train: iteration: 3000, policy_loss: 0.24699622
Policy train: iteration: 3500, policy_loss: 0.11055163
Policy train: iteration: 4000, policy_loss: 0.18394622
IDM train: iteration: 500, idm_loss: 1.130006
IDM train: iteration: 1000, idm_loss: 1.0892603
IDM train: iteration: 1500, idm_loss: 1.0181216
IDM train: iteration: 2000, idm_loss: 1.0621676
IDM train: iteration: 2500, idm_loss: 1.0251518
IDM train: iteration: 3000, idm_loss: 1.1251705
IDM train: iteration: 3500, idm_loss: 1.0752044
IDM train: iteration: 4000, idm_loss: 1.0406237

iteration: 1, total_reward: -136.0, policy_loss: 0.0969108, idm_loss: 0.82286614

Policy train: iteration: 500, policy_loss: 0.021937355
Policy train: iteration: 1000, policy_loss: 0.0077080796
Policy train: iteration: 1500, policy_loss: 0.024155615
Policy train: iteration: 2000, policy_loss: 0.003070231
Policy train: iteration: 2500, policy_loss: 0.02902099
Policy train: iteration: 3000, policy_loss: 0.0015553316
Policy train: iteration: 3500, policy_loss: 0.008018357
Policy train: iteration: 4000, policy_loss: 0.0035485616
IDM train: iteration: 500, idm_loss: 1.1352018
IDM train: iteration: 1000, idm_loss: 1.0795174
IDM train: iteration: 1500, idm_loss: 1.0939493
IDM train: iteration: 2000, idm_loss: 1.0881276
IDM train: iteration: 2500, idm_loss: 1.1561757
IDM train: iteration: 3000, idm_loss: 1.0251904
IDM train: iteration: 3500, idm_loss: 1.1006753
IDM train: iteration: 4000, idm_loss: 0.96881276

iteration: 2, total_reward: -129.0, policy_loss: 0.013929201, idm_loss: 0.84846133

Policy train: iteration: 500, policy_loss: 0.006854539
Policy train: iteration: 1000, policy_loss: 0.021865
Policy train: iteration: 1500, policy_loss: 0.013570754
Policy train: iteration: 2000, policy_loss: 0.16558126
Policy train: iteration: 2500, policy_loss: 0.007988809
Policy train: iteration: 3000, policy_loss: 0.025423802
Policy train: iteration: 3500, policy_loss: 0.0062208497
Policy train: iteration: 4000, policy_loss: 0.042596735
IDM train: iteration: 500, idm_loss: 0.9952167
IDM train: iteration: 1000, idm_loss: 0.9741732
IDM train: iteration: 1500, idm_loss: 0.9731889
IDM train: iteration: 2000, idm_loss: 1.014626
IDM train: iteration: 2500, idm_loss: 1.0017471
IDM train: iteration: 3000, idm_loss: 0.865267
IDM train: iteration: 3500, idm_loss: 0.9670173
IDM train: iteration: 4000, idm_loss: 0.9948265

iteration: 3, total_reward: -131.0, policy_loss: 0.055339105, idm_loss: 0.6289033

Policy train: iteration: 500, policy_loss: 0.002235326
Policy train: iteration: 1000, policy_loss: 0.0659756
Policy train: iteration: 1500, policy_loss: 0.058029365
Policy train: iteration: 2000, policy_loss: 0.19351701
Policy train: iteration: 2500, policy_loss: 0.001434296
Policy train: iteration: 3000, policy_loss: 0.05257737
Policy train: iteration: 3500, policy_loss: 0.1482434
Policy train: iteration: 4000, policy_loss: 0.09753211
IDM train: iteration: 500, idm_loss: 0.9025084
IDM train: iteration: 1000, idm_loss: 0.80660766
IDM train: iteration: 1500, idm_loss: 0.8462598
IDM train: iteration: 2000, idm_loss: 0.7748404
IDM train: iteration: 2500, idm_loss: 0.6219864
IDM train: iteration: 3000, idm_loss: 0.6705111
IDM train: iteration: 3500, idm_loss: 0.6348899
IDM train: iteration: 4000, idm_loss: 0.5966678

iteration: 4, total_reward: -186.0, policy_loss: 0.4252071, idm_loss: 0.20100854

Policy train: iteration: 500, policy_loss: 0.5021087
Policy train: iteration: 1000, policy_loss: 0.11560574
Policy train: iteration: 1500, policy_loss: 0.2811934
Policy train: iteration: 2000, policy_loss: 0.24641381
Policy train: iteration: 2500, policy_loss: 0.7771863
Policy train: iteration: 3000, policy_loss: 0.094817795
Policy train: iteration: 3500, policy_loss: 0.14342876
Policy train: iteration: 4000, policy_loss: 0.12221521
IDM train: iteration: 500, idm_loss: 0.5842962
IDM train: iteration: 1000, idm_loss: 0.5197288
IDM train: iteration: 1500, idm_loss: 0.5927518
IDM train: iteration: 2000, idm_loss: 0.39603573
IDM train: iteration: 2500, idm_loss: 0.43782255
IDM train: iteration: 3000, idm_loss: 0.37222645
IDM train: iteration: 3500, idm_loss: 0.32251617
IDM train: iteration: 4000, idm_loss: 0.2681343

iteration: 5, total_reward: -126.0, policy_loss: 0.6830143, idm_loss: 1.0893974

Policy train: iteration: 500, policy_loss: 0.04739572
Policy train: iteration: 1000, policy_loss: 0.07417262
Policy train: iteration: 1500, policy_loss: 0.2432961
Policy train: iteration: 2000, policy_loss: 0.34819075
Policy train: iteration: 2500, policy_loss: 0.31261638
Policy train: iteration: 3000, policy_loss: 0.49612665
Policy train: iteration: 3500, policy_loss: 0.34338403
Policy train: iteration: 4000, policy_loss: 0.13818833
IDM train: iteration: 500, idm_loss: 0.26136488
IDM train: iteration: 1000, idm_loss: 0.21129403
IDM train: iteration: 1500, idm_loss: 0.3046495
IDM train: iteration: 2000, idm_loss: 0.2312164
IDM train: iteration: 2500, idm_loss: 0.14880408
IDM train: iteration: 3000, idm_loss: 0.16233376
IDM train: iteration: 3500, idm_loss: 0.1435822
IDM train: iteration: 4000, idm_loss: 0.11002627

iteration: 6, total_reward: -115.0, policy_loss: 0.15574615, idm_loss: 0.21111304

Policy train: iteration: 500, policy_loss: 0.22905797
Policy train: iteration: 1000, policy_loss: 0.11661121
Policy train: iteration: 1500, policy_loss: 0.07174286
Policy train: iteration: 2000, policy_loss: 0.14289685
Policy train: iteration: 2500, policy_loss: 0.11996609
Policy train: iteration: 3000, policy_loss: 0.5409975
Policy train: iteration: 3500, policy_loss: 0.14773422
Policy train: iteration: 4000, policy_loss: 0.05657372
IDM train: iteration: 500, idm_loss: 0.08838591
IDM train: iteration: 1000, idm_loss: 0.08940373
IDM train: iteration: 1500, idm_loss: 0.11236818
IDM train: iteration: 2000, idm_loss: 0.08304998
IDM train: iteration: 2500, idm_loss: 0.08458522
IDM train: iteration: 3000, idm_loss: 0.05382376
IDM train: iteration: 3500, idm_loss: 0.065520495
IDM train: iteration: 4000, idm_loss: 0.047614202

iteration: 7, total_reward: -115.0, policy_loss: 0.10137192, idm_loss: 0.06558042

Policy train: iteration: 500, policy_loss: 0.19905466
Policy train: iteration: 1000, policy_loss: 0.17763528
Policy train: iteration: 1500, policy_loss: 0.07988174
Policy train: iteration: 2000, policy_loss: 0.44514963
Policy train: iteration: 2500, policy_loss: 0.09767455
Policy train: iteration: 3000, policy_loss: 0.018761722
Policy train: iteration: 3500, policy_loss: 0.29754776
Policy train: iteration: 4000, policy_loss: 0.034787826
IDM train: iteration: 500, idm_loss: 0.043356612
IDM train: iteration: 1000, idm_loss: 0.0329861
IDM train: iteration: 1500, idm_loss: 0.036862217
IDM train: iteration: 2000, idm_loss: 0.02911243
IDM train: iteration: 2500, idm_loss: 0.040481783
IDM train: iteration: 3000, idm_loss: 0.022025065
IDM train: iteration: 3500, idm_loss: 0.022720471
IDM train: iteration: 4000, idm_loss: 0.028451975

iteration: 8, total_reward: -114.0, policy_loss: 0.11990367, idm_loss: 0.02358592

Policy train: iteration: 500, policy_loss: 0.1347571
Policy train: iteration: 1000, policy_loss: 0.024045425
Policy train: iteration: 1500, policy_loss: 0.07200219
Policy train: iteration: 2000, policy_loss: 0.32959276
Policy train: iteration: 2500, policy_loss: 0.040015817
Policy train: iteration: 3000, policy_loss: 0.21561646
Policy train: iteration: 3500, policy_loss: 0.11911157
Policy train: iteration: 4000, policy_loss: 0.12434081
IDM train: iteration: 500, idm_loss: 0.030153384
IDM train: iteration: 1000, idm_loss: 0.021992642
IDM train: iteration: 1500, idm_loss: 0.020179063
IDM train: iteration: 2000, idm_loss: 0.019713785
IDM train: iteration: 2500, idm_loss: 0.015879616
IDM train: iteration: 3000, idm_loss: 0.011883512
IDM train: iteration: 3500, idm_loss: 0.0141426725
IDM train: iteration: 4000, idm_loss: 0.017092463

iteration: 9, total_reward: -111.0, policy_loss: 0.16472153, idm_loss: 1.2865881

Policy train: iteration: 500, policy_loss: 0.049987655
Policy train: iteration: 1000, policy_loss: 0.074093945
Policy train: iteration: 1500, policy_loss: 0.020902038
Policy train: iteration: 2000, policy_loss: 0.028053857
Policy train: iteration: 2500, policy_loss: 0.1031442
Policy train: iteration: 3000, policy_loss: 0.05319179
Policy train: iteration: 3500, policy_loss: 0.020739704
Policy train: iteration: 4000, policy_loss: 0.16328141
IDM train: iteration: 500, idm_loss: 0.01532567
IDM train: iteration: 1000, idm_loss: 0.020294262
IDM train: iteration: 1500, idm_loss: 0.011683164
IDM train: iteration: 2000, idm_loss: 0.019264076
IDM train: iteration: 2500, idm_loss: 0.013910672
IDM train: iteration: 3000, idm_loss: 0.015464555
IDM train: iteration: 3500, idm_loss: 0.015672034
IDM train: iteration: 4000, idm_loss: 0.05656234

iteration: 10, total_reward: -112.0, policy_loss: 0.13880749, idm_loss: 0.058772173

