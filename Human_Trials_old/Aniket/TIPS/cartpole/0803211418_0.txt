FDM train: iteration: 500, fdm_loss: 0.024116
FDM train: iteration: 1000, fdm_loss: 0.024257
FDM train: iteration: 1500, fdm_loss: 0.022233
FDM train: iteration: 2000, fdm_loss: 0.014636
FDM train: iteration: 2500, fdm_loss: 0.014457
FDM train: iteration: 3000, fdm_loss: 0.003856
FDM train: iteration: 3500, fdm_loss: 0.003062
FDM train: iteration: 4000, fdm_loss: 0.002470
FDM train: iteration: 4500, fdm_loss: 0.001689
FDM train: iteration: 5000, fdm_loss: 0.001602

episode_reward: 111.0
Background Trial: 1, reward: 24.0
Background Trial: 2, reward: 22.0
Background Trial: 3, reward: 23.0
Background Trial: 4, reward: 25.0
Background Trial: 5, reward: 23.0
Background Trial: 6, reward: 23.0
Background Trial: 7, reward: 23.0
Background Trial: 8, reward: 23.0
Background Trial: 9, reward: 24.0
Iteration: 1, average_reward: 23.333333333333332, policy_loss: 0.697023, fdm_loss: 0.150871


episode_reward: 192.0FDM train: iteration: 500, fdm_loss: 0.005765
FDM train: iteration: 1000, fdm_loss: 0.003765
FDM train: iteration: 1500, fdm_loss: 0.001310
FDM train: iteration: 2000, fdm_loss: 0.001373
FDM train: iteration: 2500, fdm_loss: 0.000969
FDM train: iteration: 3000, fdm_loss: 0.000643
FDM train: iteration: 3500, fdm_loss: 0.000870
FDM train: iteration: 4000, fdm_loss: 0.000661
FDM train: iteration: 4500, fdm_loss: 0.000433
FDM train: iteration: 5000, fdm_loss: 0.000437

Background Trial: 1, reward: 111.0
Background Trial: 2, reward: 117.0
Background Trial: 3, reward: 158.0
Background Trial: 4, reward: 143.0
Background Trial: 5, reward: 148.0
Background Trial: 6, reward: 126.0
Background Trial: 7, reward: 115.0
Background Trial: 8, reward: 166.0
Background Trial: 9, reward: 123.0
Iteration: 2, average_reward: 134.11111111111111, policy_loss: 1.018845, fdm_loss: 0.000744


episode_reward: 200.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 166.0
Background Trial: 3, reward: 166.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 165.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 142.0
Background Trial: 8, reward: 177.0
Background Trial: 9, reward: 152.0
Iteration: 3, average_reward: 174.22222222222223, policy_loss: 2.507231, fdm_loss: 0.000411


episode_reward: 200.0FDM train: iteration: 500, fdm_loss: 0.000494
FDM train: iteration: 1000, fdm_loss: 0.000423
FDM train: iteration: 1500, fdm_loss: 0.000542
FDM train: iteration: 2000, fdm_loss: 0.000331
FDM train: iteration: 2500, fdm_loss: 0.000493
FDM train: iteration: 3000, fdm_loss: 0.000213
FDM train: iteration: 3500, fdm_loss: 0.000357
FDM train: iteration: 4000, fdm_loss: 0.000306
FDM train: iteration: 4500, fdm_loss: 0.000429
FDM train: iteration: 5000, fdm_loss: 0.000339

Background Trial: 1, reward: 156.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 151.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 173.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 177.0
Iteration: 4, average_reward: 184.11111111111111, policy_loss: 3.989807, fdm_loss: 0.000233


episode_reward: 200.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 134.0
Background Trial: 3, reward: 150.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 173.0
Background Trial: 6, reward: 176.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 185.0
Iteration: 5, average_reward: 179.77777777777777, policy_loss: 3.324916, fdm_loss: 0.000980


episode_reward: 200.0FDM train: iteration: 500, fdm_loss: 0.000269
FDM train: iteration: 1000, fdm_loss: 0.000339
FDM train: iteration: 1500, fdm_loss: 0.000523
FDM train: iteration: 2000, fdm_loss: 0.000431
FDM train: iteration: 2500, fdm_loss: 0.000312
FDM train: iteration: 3000, fdm_loss: 0.000188
FDM train: iteration: 3500, fdm_loss: 0.000222
FDM train: iteration: 4000, fdm_loss: 0.000218
FDM train: iteration: 4500, fdm_loss: 0.000290
FDM train: iteration: 5000, fdm_loss: 0.000108

Background Trial: 1, reward: 158.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 183.0
Background Trial: 5, reward: 196.0
Background Trial: 6, reward: 190.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 6, average_reward: 191.88888888888889, policy_loss: 3.351856, fdm_loss: 0.000120


episode_reward: 200.0
Background Trial: 1, reward: 186.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 7, average_reward: 198.44444444444446, policy_loss: 1.771794, fdm_loss: 0.000209


episode_reward: 200.0FDM train: iteration: 500, fdm_loss: 0.000167
FDM train: iteration: 1000, fdm_loss: 0.000231
FDM train: iteration: 1500, fdm_loss: 0.000134
FDM train: iteration: 2000, fdm_loss: 0.000354
FDM train: iteration: 2500, fdm_loss: 0.000134
FDM train: iteration: 3000, fdm_loss: 0.000188
FDM train: iteration: 3500, fdm_loss: 0.000042
FDM train: iteration: 4000, fdm_loss: 0.000097
FDM train: iteration: 4500, fdm_loss: 0.000132
FDM train: iteration: 5000, fdm_loss: 0.000093

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 8, average_reward: 200.0, policy_loss: 2.094443, fdm_loss: 0.000339


episode_reward: 185.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 168.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 174.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 9, average_reward: 193.55555555555554, policy_loss: 2.273805, fdm_loss: 0.000087


episode_reward: 200.0FDM train: iteration: 500, fdm_loss: 0.000080
FDM train: iteration: 1000, fdm_loss: 0.000066
FDM train: iteration: 1500, fdm_loss: 0.000056
FDM train: iteration: 2000, fdm_loss: 0.000080
FDM train: iteration: 2500, fdm_loss: 0.000276
FDM train: iteration: 3000, fdm_loss: 0.000113
FDM train: iteration: 3500, fdm_loss: 0.000094
FDM train: iteration: 4000, fdm_loss: 0.000021
FDM train: iteration: 4500, fdm_loss: 0.000064
FDM train: iteration: 5000, fdm_loss: 0.000115

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 159.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 150.0
Iteration: 10, average_reward: 189.88888888888889, policy_loss: 2.341081, fdm_loss: 0.000093


episode_reward: 200.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 188.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 188.0
Iteration: 11, average_reward: 197.33333333333334, policy_loss: 2.825283, fdm_loss: 0.000076


episode_reward: 200.0FDM train: iteration: 500, fdm_loss: 0.000044
FDM train: iteration: 1000, fdm_loss: 0.000076
FDM train: iteration: 1500, fdm_loss: 0.000084
FDM train: iteration: 2000, fdm_loss: 0.000093
FDM train: iteration: 2500, fdm_loss: 0.000153
FDM train: iteration: 3000, fdm_loss: 0.000090
FDM train: iteration: 3500, fdm_loss: 0.000109
FDM train: iteration: 4000, fdm_loss: 0.000072
FDM train: iteration: 4500, fdm_loss: 0.000114
FDM train: iteration: 5000, fdm_loss: 0.000065

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 182.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 12, average_reward: 198.0, policy_loss: 2.408558, fdm_loss: 0.000048

