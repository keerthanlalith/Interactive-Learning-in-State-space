
episode_reward: 200.0
Background Trial: 1, reward: 149.0
Background Trial: 2, reward: 126.0
Background Trial: 3, reward: 132.0
Background Trial: 4, reward: 134.0
Background Trial: 5, reward: 124.0
Background Trial: 6, reward: 129.0
Background Trial: 7, reward: 148.0
Background Trial: 8, reward: 139.0
Background Trial: 9, reward: 127.0
Iteration: 1, average_reward: 134.22222222222223, policy_loss: 0.583386, fdm_loss: 0.053698


episode_reward: 200.0FDM train: iteration: 500, fdm_loss: 0.005694
FDM train: iteration: 1000, fdm_loss: 0.004148
FDM train: iteration: 1500, fdm_loss: 0.003373
FDM train: iteration: 2000, fdm_loss: 0.004082
FDM train: iteration: 2500, fdm_loss: 0.002336
FDM train: iteration: 3000, fdm_loss: 0.001935
FDM train: iteration: 3500, fdm_loss: 0.001559
FDM train: iteration: 4000, fdm_loss: 0.001906
FDM train: iteration: 4500, fdm_loss: 0.001245
FDM train: iteration: 5000, fdm_loss: 0.001072

Background Trial: 1, reward: 102.0
Background Trial: 2, reward: 117.0
Background Trial: 3, reward: 107.0
Background Trial: 4, reward: 105.0
Background Trial: 5, reward: 108.0
Background Trial: 6, reward: 107.0
Background Trial: 7, reward: 109.0
Background Trial: 8, reward: 111.0
Background Trial: 9, reward: 119.0
Iteration: 2, average_reward: 109.44444444444444, policy_loss: 0.632710, fdm_loss: 0.001221


episode_reward: 200.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 185.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 195.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 190.0
Iteration: 3, average_reward: 196.66666666666666, policy_loss: 0.554784, fdm_loss: 0.016164


episode_reward: 200.0FDM train: iteration: 500, fdm_loss: 0.001696
FDM train: iteration: 1000, fdm_loss: 0.002643
FDM train: iteration: 1500, fdm_loss: 0.001301
FDM train: iteration: 2000, fdm_loss: 0.002038
FDM train: iteration: 2500, fdm_loss: 0.001276
FDM train: iteration: 3000, fdm_loss: 0.001713
FDM train: iteration: 3500, fdm_loss: 0.000956
FDM train: iteration: 4000, fdm_loss: 0.000808
FDM train: iteration: 4500, fdm_loss: 0.001465
FDM train: iteration: 5000, fdm_loss: 0.001525

Background Trial: 1, reward: 198.0
Background Trial: 2, reward: 188.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 192.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 197.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 4, average_reward: 197.22222222222223, policy_loss: 0.607067, fdm_loss: 0.001332


episode_reward: 200.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 5, average_reward: 200.0, policy_loss: 0.532010, fdm_loss: 0.001390


episode_reward: 200.0FDM train: iteration: 500, fdm_loss: 0.000558
FDM train: iteration: 1000, fdm_loss: 0.000538
FDM train: iteration: 1500, fdm_loss: 0.000761
FDM train: iteration: 2000, fdm_loss: 0.000439
FDM train: iteration: 2500, fdm_loss: 0.000250
FDM train: iteration: 3000, fdm_loss: 0.000572
FDM train: iteration: 3500, fdm_loss: 0.000210
FDM train: iteration: 4000, fdm_loss: 0.000394
FDM train: iteration: 4500, fdm_loss: 0.000211
FDM train: iteration: 5000, fdm_loss: 0.000229

Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 6, average_reward: 200.0, policy_loss: 0.745003, fdm_loss: 0.000344


episode_reward: 200.0
Background Trial: 1, reward: 200.0
Background Trial: 2, reward: 200.0
Background Trial: 3, reward: 200.0
Background Trial: 4, reward: 200.0
Background Trial: 5, reward: 200.0
Background Trial: 6, reward: 200.0
Background Trial: 7, reward: 200.0
Background Trial: 8, reward: 200.0
Background Trial: 9, reward: 200.0
Iteration: 7, average_reward: 200.0, policy_loss: 0.575534, fdm_loss: 0.000110

