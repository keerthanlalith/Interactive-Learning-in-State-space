IDM train: iteration: 500, idm_loss: 0.00457873
IDM train: iteration: 1000, idm_loss: 0.0024005647
IDM train: iteration: 1500, idm_loss: 0.0014106465
IDM train: iteration: 2000, idm_loss: 0.0024535072
IDM train: iteration: 2500, idm_loss: 5.8196685e-05
IDM train: iteration: 3000, idm_loss: 0.0012894805
IDM train: iteration: 3500, idm_loss: 0.002766406
IDM train: iteration: 4000, idm_loss: 0.0017984336
IDM train: iteration: 4500, idm_loss: 0.0018343014
IDM train: iteration: 5000, idm_loss: 0.0029069465
Policy train: iteration: 500, policy_loss: 0.044552103
Policy train: iteration: 1000, policy_loss: 0.033425037
Policy train: iteration: 1500, policy_loss: 0.021234399
Policy train: iteration: 2000, policy_loss: 0.025936129
Policy train: iteration: 2500, policy_loss: 0.016500844
Policy train: iteration: 3000, policy_loss: 0.018030453
Policy train: iteration: 3500, policy_loss: 0.016629355
Policy train: iteration: 4000, policy_loss: 0.024788715
Policy train: iteration: 4500, policy_loss: 0.016945843
Policy train: iteration: 5000, policy_loss: 0.01767669
IDM train: iteration: 500, idm_loss: 0.00044800548
IDM train: iteration: 1000, idm_loss: 0.0020781115
IDM train: iteration: 1500, idm_loss: 0.00027064318
IDM train: iteration: 2000, idm_loss: 0.0012954648
IDM train: iteration: 2500, idm_loss: 0.0007537687
IDM train: iteration: 3000, idm_loss: 0.0014902245
IDM train: iteration: 3500, idm_loss: 9.691261e-05
IDM train: iteration: 4000, idm_loss: 0.0005020922
IDM train: iteration: 4500, idm_loss: 0.0010587886
IDM train: iteration: 5000, idm_loss: 0.0014452724

iteration: 1, total_reward: -28.493396312465983, policy_loss: 0.053467702, idm_loss: 0.00047421225

Policy train: iteration: 500, policy_loss: 0.019249681
Policy train: iteration: 1000, policy_loss: 0.017084878
Policy train: iteration: 1500, policy_loss: 0.011259869
Policy train: iteration: 2000, policy_loss: 0.011448958
Policy train: iteration: 2500, policy_loss: 0.0127788335
Policy train: iteration: 3000, policy_loss: 0.014226607
Policy train: iteration: 3500, policy_loss: 0.0115625365
Policy train: iteration: 4000, policy_loss: 0.017842064
Policy train: iteration: 4500, policy_loss: 0.011332284
Policy train: iteration: 5000, policy_loss: 0.013771596
IDM train: iteration: 500, idm_loss: 0.00059900736
IDM train: iteration: 1000, idm_loss: 0.00026069226
IDM train: iteration: 1500, idm_loss: 0.00080308184
IDM train: iteration: 2000, idm_loss: 0.00031016307
IDM train: iteration: 2500, idm_loss: 0.0005784124
IDM train: iteration: 3000, idm_loss: 0.0004280332
IDM train: iteration: 3500, idm_loss: 0.00020150495
IDM train: iteration: 4000, idm_loss: 0.00039109585
IDM train: iteration: 4500, idm_loss: 0.00041984604
IDM train: iteration: 5000, idm_loss: 0.00021241436

iteration: 2, total_reward: -8.563709717458023, policy_loss: 0.06788298, idm_loss: 0.00043431506

Policy train: iteration: 500, policy_loss: 0.014819785
Policy train: iteration: 1000, policy_loss: 0.010488733
Policy train: iteration: 1500, policy_loss: 0.011555615
Policy train: iteration: 2000, policy_loss: 0.0075238775
Policy train: iteration: 2500, policy_loss: 0.014565931
Policy train: iteration: 3000, policy_loss: 0.012105574
Policy train: iteration: 3500, policy_loss: 0.00956351
Policy train: iteration: 4000, policy_loss: 0.010842993
Policy train: iteration: 4500, policy_loss: 0.015313159
Policy train: iteration: 5000, policy_loss: 0.00796917
IDM train: iteration: 500, idm_loss: 0.0005857786
IDM train: iteration: 1000, idm_loss: 0.00032471737
IDM train: iteration: 1500, idm_loss: 0.00029003754
IDM train: iteration: 2000, idm_loss: 0.0009113859
IDM train: iteration: 2500, idm_loss: 0.00024910603
IDM train: iteration: 3000, idm_loss: 0.00051216356
IDM train: iteration: 3500, idm_loss: 0.00023668543
IDM train: iteration: 4000, idm_loss: 0.00049560366
IDM train: iteration: 4500, idm_loss: 0.00021734477
IDM train: iteration: 5000, idm_loss: 0.0004013219

iteration: 3, total_reward: 1639.0006646312459, policy_loss: 0.052208617, idm_loss: 0.0070146197

Policy train: iteration: 500, policy_loss: 0.007757989
Policy train: iteration: 1000, policy_loss: 0.0070564994
Policy train: iteration: 1500, policy_loss: 0.0043495498
Policy train: iteration: 2000, policy_loss: 0.003852237
Policy train: iteration: 2500, policy_loss: 0.005199254
