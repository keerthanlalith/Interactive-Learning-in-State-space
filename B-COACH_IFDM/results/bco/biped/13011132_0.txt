Collecting idm training data 1000
Collecting idm training data 2000
Collecting idm training data 3000
Collecting idm training data 4000
Collecting idm training data 5000
Collecting idm training data 6000
Collecting idm training data 7000
Collecting idm training data 8000
Collecting idm training data 9000
Collecting idm training data 10000
Collecting idm training data 11000
Collecting idm training data 12000
Collecting idm training data 13000
Collecting idm training data 14000
Collecting idm training data 15000
Collecting idm training data 16000
Collecting idm training data 17000
Collecting idm training data 18000
Collecting idm training data 19000
Collecting idm training data 20000
Collecting idm training data 21000
Collecting idm training data 22000
Collecting idm training data 23000
Collecting idm training data 24000
Collecting idm training data 25000
Collecting idm training data 26000
Collecting idm training data 27000
Collecting idm training data 28000
Collecting idm training data 29000
Collecting idm training data 30000
Collecting idm training data 31000
Collecting idm training data 32000
Collecting idm training data 33000
Collecting idm training data 34000
Collecting idm training data 35000
Collecting idm training data 36000
Collecting idm training data 37000
Collecting idm training data 38000
Collecting idm training data 39000
Collecting idm training data 40000
Collecting idm training data 41000
Collecting idm training data 42000
Collecting idm training data 43000
Collecting idm training data 44000
Collecting idm training data 45000
Collecting idm training data 46000
Collecting idm training data 47000
Collecting idm training data 48000
Collecting idm training data 49000
Collecting idm training data 50000
IDM train: iteration: 500, idm_loss: 0.181898
IDM train: iteration: 1000, idm_loss: 0.204367
IDM train: iteration: 1500, idm_loss: 0.151715
IDM train: iteration: 2000, idm_loss: 0.144912
IDM train: iteration: 2500, idm_loss: 0.120384
IDM train: iteration: 3000, idm_loss: 0.170650
IDM train: iteration: 3500, idm_loss: 0.164448
IDM train: iteration: 4000, idm_loss: 0.157282
IDM train: iteration: 4500, idm_loss: 0.139976
IDM train: iteration: 5000, idm_loss: 0.169514
IDM train: iteration: 5500, idm_loss: 0.157954
IDM train: iteration: 6000, idm_loss: 0.152317
IDM train: iteration: 6500, idm_loss: 0.135602
IDM train: iteration: 7000, idm_loss: 0.147212
IDM train: iteration: 7500, idm_loss: 0.132508
IDM train: iteration: 8000, idm_loss: 0.090647
IDM train: iteration: 8500, idm_loss: 0.136015
IDM train: iteration: 9000, idm_loss: 0.126347
IDM train: iteration: 9500, idm_loss: 0.123675
IDM train: iteration: 10000, idm_loss: 0.098296
Policy train: iteration: 500, policy_loss: 0.12614498
Policy train: iteration: 1000, policy_loss: 0.07428514
Policy train: iteration: 1500, policy_loss: 0.06372814
Policy train: iteration: 2000, policy_loss: 0.05217018
Policy train: iteration: 2500, policy_loss: 0.05777228
Policy train: iteration: 3000, policy_loss: 0.069382645
Policy train: iteration: 3500, policy_loss: 0.0426441
Policy train: iteration: 4000, policy_loss: 0.05212591
Policy train: iteration: 4500, policy_loss: 0.06976484
Policy train: iteration: 5000, policy_loss: 0.060762305
Policy train: iteration: 5500, policy_loss: 0.05454027
Policy train: iteration: 6000, policy_loss: 0.050955847
Policy train: iteration: 6500, policy_loss: 0.04584203
Policy train: iteration: 7000, policy_loss: 0.031194791
Policy train: iteration: 7500, policy_loss: 0.050454758
Policy train: iteration: 8000, policy_loss: 0.06515078
Policy train: iteration: 8500, policy_loss: 0.033334646
Policy train: iteration: 9000, policy_loss: 0.043649837
Policy train: iteration: 9500, policy_loss: 0.040196348
Policy train: iteration: 10000, policy_loss: 0.045205925
IDM train: iteration: 500, idm_loss: 0.123596
IDM train: iteration: 1000, idm_loss: 0.159031
IDM train: iteration: 1500, idm_loss: 0.122602
IDM train: iteration: 2000, idm_loss: 0.105579
IDM train: iteration: 2500, idm_loss: 0.092043
IDM train: iteration: 3000, idm_loss: 0.148070
IDM train: iteration: 3500, idm_loss: 0.105074
IDM train: iteration: 4000, idm_loss: 0.111845
IDM train: iteration: 4500, idm_loss: 0.103142
IDM train: iteration: 5000, idm_loss: 0.114751
IDM train: iteration: 5500, idm_loss: 0.104783
IDM train: iteration: 6000, idm_loss: 0.121394
IDM train: iteration: 6500, idm_loss: 0.149536
IDM train: iteration: 7000, idm_loss: 0.129523
IDM train: iteration: 7500, idm_loss: 0.128679
IDM train: iteration: 8000, idm_loss: 0.136875
IDM train: iteration: 8500, idm_loss: 0.125560
IDM train: iteration: 9000, idm_loss: 0.109584
IDM train: iteration: 9500, idm_loss: 0.118785
IDM train: iteration: 10000, idm_loss: 0.112681

iteration: 1, total_reward: -101.1414436654641, policy_loss: 0.09782768, idm_loss: 0.07330775

Policy train: iteration: 500, policy_loss: 0.03622019
Policy train: iteration: 1000, policy_loss: 0.04086826
Policy train: iteration: 1500, policy_loss: 0.036096368
Policy train: iteration: 2000, policy_loss: 0.04833968
Policy train: iteration: 2500, policy_loss: 0.0329232
Policy train: iteration: 3000, policy_loss: 0.026122868
Policy train: iteration: 3500, policy_loss: 0.029778326
Policy train: iteration: 4000, policy_loss: 0.038549706
Policy train: iteration: 4500, policy_loss: 0.031086933
Policy train: iteration: 5000, policy_loss: 0.04788798
Policy train: iteration: 5500, policy_loss: 0.03249289
Policy train: iteration: 6000, policy_loss: 0.03736183
Policy train: iteration: 6500, policy_loss: 0.044156816
Policy train: iteration: 7000, policy_loss: 0.060368285
Policy train: iteration: 7500, policy_loss: 0.040993955
Policy train: iteration: 8000, policy_loss: 0.031864632
Policy train: iteration: 8500, policy_loss: 0.036720935
Policy train: iteration: 9000, policy_loss: 0.035635427
Policy train: iteration: 9500, policy_loss: 0.03782478
Policy train: iteration: 10000, policy_loss: 0.036198035
IDM train: iteration: 500, idm_loss: 0.135442
IDM train: iteration: 1000, idm_loss: 0.106071
IDM train: iteration: 1500, idm_loss: 0.121543
IDM train: iteration: 2000, idm_loss: 0.114544
IDM train: iteration: 2500, idm_loss: 0.096446
IDM train: iteration: 3000, idm_loss: 0.118228
IDM train: iteration: 3500, idm_loss: 0.131279
IDM train: iteration: 4000, idm_loss: 0.093862
IDM train: iteration: 4500, idm_loss: 0.100387
IDM train: iteration: 5000, idm_loss: 0.101137
IDM train: iteration: 5500, idm_loss: 0.099870
IDM train: iteration: 6000, idm_loss: 0.088960
IDM train: iteration: 6500, idm_loss: 0.134334
IDM train: iteration: 7000, idm_loss: 0.132119
IDM train: iteration: 7500, idm_loss: 0.121496
IDM train: iteration: 8000, idm_loss: 0.120034
IDM train: iteration: 8500, idm_loss: 0.085893
IDM train: iteration: 9000, idm_loss: 0.124438
IDM train: iteration: 9500, idm_loss: 0.107978
IDM train: iteration: 10000, idm_loss: 0.111058

iteration: 2, total_reward: -96.85549885982584, policy_loss: 0.05280134, idm_loss: 0.07864732

Policy train: iteration: 500, policy_loss: 0.029653616
Policy train: iteration: 1000, policy_loss: 0.030251924
Policy train: iteration: 1500, policy_loss: 0.03478225
Policy train: iteration: 2000, policy_loss: 0.030938655
Policy train: iteration: 2500, policy_loss: 0.03157062
Policy train: iteration: 3000, policy_loss: 0.031751107
Policy train: iteration: 3500, policy_loss: 0.026159275
Policy train: iteration: 4000, policy_loss: 0.031126726
Policy train: iteration: 4500, policy_loss: 0.020778013
Policy train: iteration: 5000, policy_loss: 0.03547937
Policy train: iteration: 5500, policy_loss: 0.019501
Policy train: iteration: 6000, policy_loss: 0.022130284
Policy train: iteration: 6500, policy_loss: 0.03887681
Policy train: iteration: 7000, policy_loss: 0.022439606
Policy train: iteration: 7500, policy_loss: 0.02050943
Policy train: iteration: 8000, policy_loss: 0.020617336
Policy train: iteration: 8500, policy_loss: 0.022743922
Policy train: iteration: 9000, policy_loss: 0.038248867
Policy train: iteration: 9500, policy_loss: 0.03216427
Policy train: iteration: 10000, policy_loss: 0.01962792
IDM train: iteration: 500, idm_loss: 0.134371
IDM train: iteration: 1000, idm_loss: 0.085973
IDM train: iteration: 1500, idm_loss: 0.106122
IDM train: iteration: 2000, idm_loss: 0.130665
IDM train: iteration: 2500, idm_loss: 0.115269
IDM train: iteration: 3000, idm_loss: 0.091582
IDM train: iteration: 3500, idm_loss: 0.120440
IDM train: iteration: 4000, idm_loss: 0.093367
IDM train: iteration: 4500, idm_loss: 0.108315
IDM train: iteration: 5000, idm_loss: 0.096088
IDM train: iteration: 5500, idm_loss: 0.092656
IDM train: iteration: 6000, idm_loss: 0.086961
IDM train: iteration: 6500, idm_loss: 0.126223
IDM train: iteration: 7000, idm_loss: 0.126800
IDM train: iteration: 7500, idm_loss: 0.116351
IDM train: iteration: 8000, idm_loss: 0.103183
IDM train: iteration: 8500, idm_loss: 0.113597
IDM train: iteration: 9000, idm_loss: 0.097361
IDM train: iteration: 9500, idm_loss: 0.130407
IDM train: iteration: 10000, idm_loss: 0.108231

iteration: 3, total_reward: 293.9057463107778, policy_loss: 0.045079112, idm_loss: 0.086758345

Policy train: iteration: 500, policy_loss: 0.024635911
Policy train: iteration: 1000, policy_loss: 0.017711237
Policy train: iteration: 1500, policy_loss: 0.025865257
Policy train: iteration: 2000, policy_loss: 0.025142718
Policy train: iteration: 2500, policy_loss: 0.017825756
Policy train: iteration: 3000, policy_loss: 0.017702382
Policy train: iteration: 3500, policy_loss: 0.02775652
Policy train: iteration: 4000, policy_loss: 0.02256962
Policy train: iteration: 4500, policy_loss: 0.021851972
Policy train: iteration: 5000, policy_loss: 0.026540695
Policy train: iteration: 5500, policy_loss: 0.025314067
Policy train: iteration: 6000, policy_loss: 0.018871762
Policy train: iteration: 6500, policy_loss: 0.025150724
Policy train: iteration: 7000, policy_loss: 0.030445237
Policy train: iteration: 7500, policy_loss: 0.027904887
Policy train: iteration: 8000, policy_loss: 0.013905817
Policy train: iteration: 8500, policy_loss: 0.028157825
Policy train: iteration: 9000, policy_loss: 0.02672542
Policy train: iteration: 9500, policy_loss: 0.020735992
Policy train: iteration: 10000, policy_loss: 0.01977143
IDM train: iteration: 500, idm_loss: 0.114578
IDM train: iteration: 1000, idm_loss: 0.099427
IDM train: iteration: 1500, idm_loss: 0.151832
IDM train: iteration: 2000, idm_loss: 0.091464
IDM train: iteration: 2500, idm_loss: 0.094247
IDM train: iteration: 3000, idm_loss: 0.088982
IDM train: iteration: 3500, idm_loss: 0.097244
IDM train: iteration: 4000, idm_loss: 0.085666
IDM train: iteration: 4500, idm_loss: 0.114269
IDM train: iteration: 5000, idm_loss: 0.132229
IDM train: iteration: 5500, idm_loss: 0.079719
IDM train: iteration: 6000, idm_loss: 0.100412
IDM train: iteration: 6500, idm_loss: 0.102025
IDM train: iteration: 7000, idm_loss: 0.116108
IDM train: iteration: 7500, idm_loss: 0.082357
IDM train: iteration: 8000, idm_loss: 0.124788
IDM train: iteration: 8500, idm_loss: 0.118092
IDM train: iteration: 9000, idm_loss: 0.107437
IDM train: iteration: 9500, idm_loss: 0.074910
IDM train: iteration: 10000, idm_loss: 0.099891

iteration: 4, total_reward: -22.560236125703824, policy_loss: 0.045922656, idm_loss: 0.064160444

Policy train: iteration: 500, policy_loss: 0.017770197
Policy train: iteration: 1000, policy_loss: 0.015944956
Policy train: iteration: 1500, policy_loss: 0.020664062
Policy train: iteration: 2000, policy_loss: 0.02072785
Policy train: iteration: 2500, policy_loss: 0.018024959
Policy train: iteration: 3000, policy_loss: 0.018198453
Policy train: iteration: 3500, policy_loss: 0.024957687
Policy train: iteration: 4000, policy_loss: 0.020379871
Policy train: iteration: 4500, policy_loss: 0.023998912
Policy train: iteration: 5000, policy_loss: 0.02769885
Policy train: iteration: 5500, policy_loss: 0.015587799
Policy train: iteration: 6000, policy_loss: 0.014310385
Policy train: iteration: 6500, policy_loss: 0.019767711
Policy train: iteration: 7000, policy_loss: 0.020272383
Policy train: iteration: 7500, policy_loss: 0.016379675
Policy train: iteration: 8000, policy_loss: 0.016154462
Policy train: iteration: 8500, policy_loss: 0.018163826
Policy train: iteration: 9000, policy_loss: 0.011917798
Policy train: iteration: 9500, policy_loss: 0.02169111
Policy train: iteration: 10000, policy_loss: 0.021670245
IDM train: iteration: 500, idm_loss: 0.086193
IDM train: iteration: 1000, idm_loss: 0.095234
IDM train: iteration: 1500, idm_loss: 0.105153
IDM train: iteration: 2000, idm_loss: 0.129264
IDM train: iteration: 2500, idm_loss: 0.109637
IDM train: iteration: 3000, idm_loss: 0.128711
IDM train: iteration: 3500, idm_loss: 0.107604
IDM train: iteration: 4000, idm_loss: 0.088829
IDM train: iteration: 4500, idm_loss: 0.101614
IDM train: iteration: 5000, idm_loss: 0.091284
IDM train: iteration: 5500, idm_loss: 0.084609
IDM train: iteration: 6000, idm_loss: 0.086937
IDM train: iteration: 6500, idm_loss: 0.078122
IDM train: iteration: 7000, idm_loss: 0.088093
IDM train: iteration: 7500, idm_loss: 0.125273
IDM train: iteration: 8000, idm_loss: 0.117918
IDM train: iteration: 8500, idm_loss: 0.104949
IDM train: iteration: 9000, idm_loss: 0.113171
IDM train: iteration: 9500, idm_loss: 0.122557
IDM train: iteration: 10000, idm_loss: 0.078739

iteration: 5, total_reward: -112.39457332346899, policy_loss: 0.035425104, idm_loss: 0.05875956

Policy train: iteration: 500, policy_loss: 0.014394856
Policy train: iteration: 1000, policy_loss: 0.016995732
Policy train: iteration: 1500, policy_loss: 0.016804505
Policy train: iteration: 2000, policy_loss: 0.014030512
Policy train: iteration: 2500, policy_loss: 0.024035998
Policy train: iteration: 3000, policy_loss: 0.01763955
Policy train: iteration: 3500, policy_loss: 0.01211885
Policy train: iteration: 4000, policy_loss: 0.015376043
Policy train: iteration: 4500, policy_loss: 0.019208785
Policy train: iteration: 5000, policy_loss: 0.028750187
Policy train: iteration: 5500, policy_loss: 0.018345362
Policy train: iteration: 6000, policy_loss: 0.014674607
Policy train: iteration: 6500, policy_loss: 0.011965836
Policy train: iteration: 7000, policy_loss: 0.020633848
Policy train: iteration: 7500, policy_loss: 0.011411002
Policy train: iteration: 8000, policy_loss: 0.019575063
Policy train: iteration: 8500, policy_loss: 0.016669624
Policy train: iteration: 9000, policy_loss: 0.017332625
Policy train: iteration: 9500, policy_loss: 0.020053478
Policy train: iteration: 10000, policy_loss: 0.020434447
IDM train: iteration: 500, idm_loss: 0.059528
IDM train: iteration: 1000, idm_loss: 0.091427
IDM train: iteration: 1500, idm_loss: 0.086960
IDM train: iteration: 2000, idm_loss: 0.106418
IDM train: iteration: 2500, idm_loss: 0.088435
IDM train: iteration: 3000, idm_loss: 0.101917
IDM train: iteration: 3500, idm_loss: 0.100569
IDM train: iteration: 4000, idm_loss: 0.102517
IDM train: iteration: 4500, idm_loss: 0.123079
IDM train: iteration: 5000, idm_loss: 0.095521
IDM train: iteration: 5500, idm_loss: 0.105587
IDM train: iteration: 6000, idm_loss: 0.106617
IDM train: iteration: 6500, idm_loss: 0.082244
IDM train: iteration: 7000, idm_loss: 0.091083
IDM train: iteration: 7500, idm_loss: 0.076589
IDM train: iteration: 8000, idm_loss: 0.119412
IDM train: iteration: 8500, idm_loss: 0.094047
IDM train: iteration: 9000, idm_loss: 0.077977
IDM train: iteration: 9500, idm_loss: 0.099582
IDM train: iteration: 10000, idm_loss: 0.087097

iteration: 6, total_reward: -112.43780393171622, policy_loss: 0.042802062, idm_loss: 0.0786853

Policy train: iteration: 500, policy_loss: 0.018226609
Policy train: iteration: 1000, policy_loss: 0.018482337
Policy train: iteration: 1500, policy_loss: 0.015929284
Policy train: iteration: 2000, policy_loss: 0.02293065
Policy train: iteration: 2500, policy_loss: 0.01232321
Policy train: iteration: 3000, policy_loss: 0.013549591
Policy train: iteration: 3500, policy_loss: 0.019419216
Policy train: iteration: 4000, policy_loss: 0.015478805
Policy train: iteration: 4500, policy_loss: 0.01039231
Policy train: iteration: 5000, policy_loss: 0.018883795
Policy train: iteration: 5500, policy_loss: 0.025584487
Policy train: iteration: 6000, policy_loss: 0.012649899
Policy train: iteration: 6500, policy_loss: 0.009359456
Policy train: iteration: 7000, policy_loss: 0.014929752
Policy train: iteration: 7500, policy_loss: 0.012431254
Policy train: iteration: 8000, policy_loss: 0.01479131
Policy train: iteration: 8500, policy_loss: 0.016518945
Policy train: iteration: 9000, policy_loss: 0.01894807
Policy train: iteration: 9500, policy_loss: 0.013814862
Policy train: iteration: 10000, policy_loss: 0.011816957
IDM train: iteration: 500, idm_loss: 0.076422
IDM train: iteration: 1000, idm_loss: 0.111575
IDM train: iteration: 1500, idm_loss: 0.102295
IDM train: iteration: 2000, idm_loss: 0.094680
IDM train: iteration: 2500, idm_loss: 0.116914
IDM train: iteration: 3000, idm_loss: 0.086104
IDM train: iteration: 3500, idm_loss: 0.114126
IDM train: iteration: 4000, idm_loss: 0.097430
IDM train: iteration: 4500, idm_loss: 0.072976
IDM train: iteration: 5000, idm_loss: 0.106818
IDM train: iteration: 5500, idm_loss: 0.100780
IDM train: iteration: 6000, idm_loss: 0.078669
IDM train: iteration: 6500, idm_loss: 0.104484
IDM train: iteration: 7000, idm_loss: 0.100613
IDM train: iteration: 7500, idm_loss: 0.095836
IDM train: iteration: 8000, idm_loss: 0.097865
IDM train: iteration: 8500, idm_loss: 0.088643
IDM train: iteration: 9000, idm_loss: 0.108970
IDM train: iteration: 9500, idm_loss: 0.110768
IDM train: iteration: 10000, idm_loss: 0.090284

iteration: 7, total_reward: -77.42054586894997, policy_loss: 0.03660589, idm_loss: 0.06669598

Policy train: iteration: 500, policy_loss: 0.017312061
Policy train: iteration: 1000, policy_loss: 0.017618328
Policy train: iteration: 1500, policy_loss: 0.016402341
Policy train: iteration: 2000, policy_loss: 0.01589913
Policy train: iteration: 2500, policy_loss: 0.01574287
Policy train: iteration: 3000, policy_loss: 0.013089269
Policy train: iteration: 3500, policy_loss: 0.010376219
Policy train: iteration: 4000, policy_loss: 0.014685141
Policy train: iteration: 4500, policy_loss: 0.014808081
Policy train: iteration: 5000, policy_loss: 0.024968173
Policy train: iteration: 5500, policy_loss: 0.017118068
Policy train: iteration: 6000, policy_loss: 0.0133655295
Policy train: iteration: 6500, policy_loss: 0.01473691
Policy train: iteration: 7000, policy_loss: 0.014673397
Policy train: iteration: 7500, policy_loss: 0.009885754
Policy train: iteration: 8000, policy_loss: 0.013453178
Policy train: iteration: 8500, policy_loss: 0.013612238
Policy train: iteration: 9000, policy_loss: 0.022483788
Policy train: iteration: 9500, policy_loss: 0.01383165
Policy train: iteration: 10000, policy_loss: 0.012713078
IDM train: iteration: 500, idm_loss: 0.097944
IDM train: iteration: 1000, idm_loss: 0.082847
IDM train: iteration: 1500, idm_loss: 0.115180
IDM train: iteration: 2000, idm_loss: 0.082057
IDM train: iteration: 2500, idm_loss: 0.112451
IDM train: iteration: 3000, idm_loss: 0.103317
IDM train: iteration: 3500, idm_loss: 0.100240
IDM train: iteration: 4000, idm_loss: 0.114537
IDM train: iteration: 4500, idm_loss: 0.087558
IDM train: iteration: 5000, idm_loss: 0.107766
IDM train: iteration: 5500, idm_loss: 0.094299
IDM train: iteration: 6000, idm_loss: 0.085909
IDM train: iteration: 6500, idm_loss: 0.075701
IDM train: iteration: 7000, idm_loss: 0.076572
IDM train: iteration: 7500, idm_loss: 0.086116
IDM train: iteration: 8000, idm_loss: 0.072316
IDM train: iteration: 8500, idm_loss: 0.089574
IDM train: iteration: 9000, idm_loss: 0.084982
IDM train: iteration: 9500, idm_loss: 0.094161
IDM train: iteration: 10000, idm_loss: 0.127815

iteration: 8, total_reward: -89.55079099935543, policy_loss: 0.022377184, idm_loss: 0.07732473

Policy train: iteration: 500, policy_loss: 0.016864888
Policy train: iteration: 1000, policy_loss: 0.012263273
Policy train: iteration: 1500, policy_loss: 0.013155209
Policy train: iteration: 2000, policy_loss: 0.013352979
Policy train: iteration: 2500, policy_loss: 0.029141998
Policy train: iteration: 3000, policy_loss: 0.011643419
Policy train: iteration: 3500, policy_loss: 0.015353482
Policy train: iteration: 4000, policy_loss: 0.012211457
Policy train: iteration: 4500, policy_loss: 0.018166535
Policy train: iteration: 5000, policy_loss: 0.0123390425
Policy train: iteration: 5500, policy_loss: 0.011705774
Policy train: iteration: 6000, policy_loss: 0.013508499
Policy train: iteration: 6500, policy_loss: 0.012645567
Policy train: iteration: 7000, policy_loss: 0.013542043
Policy train: iteration: 7500, policy_loss: 0.012763634
Policy train: iteration: 8000, policy_loss: 0.012491737
Policy train: iteration: 8500, policy_loss: 0.0135858115
Policy train: iteration: 9000, policy_loss: 0.0132771935
Policy train: iteration: 9500, policy_loss: 0.016339853
Policy train: iteration: 10000, policy_loss: 0.012042085
IDM train: iteration: 500, idm_loss: 0.100886
IDM train: iteration: 1000, idm_loss: 0.090832
IDM train: iteration: 1500, idm_loss: 0.110177
IDM train: iteration: 2000, idm_loss: 0.087726
IDM train: iteration: 2500, idm_loss: 0.083559
IDM train: iteration: 3000, idm_loss: 0.080713
IDM train: iteration: 3500, idm_loss: 0.087849
IDM train: iteration: 4000, idm_loss: 0.056806
IDM train: iteration: 4500, idm_loss: 0.090359
IDM train: iteration: 5000, idm_loss: 0.098550
IDM train: iteration: 5500, idm_loss: 0.099690
IDM train: iteration: 6000, idm_loss: 0.110328
IDM train: iteration: 6500, idm_loss: 0.100341
IDM train: iteration: 7000, idm_loss: 0.077221
IDM train: iteration: 7500, idm_loss: 0.094697
IDM train: iteration: 8000, idm_loss: 0.095917
IDM train: iteration: 8500, idm_loss: 0.094235
IDM train: iteration: 9000, idm_loss: 0.114443
IDM train: iteration: 9500, idm_loss: 0.098770
IDM train: iteration: 10000, idm_loss: 0.084965

iteration: 9, total_reward: -1.3071574012170828, policy_loss: 0.031355456, idm_loss: 0.080253094

Policy train: iteration: 500, policy_loss: 0.015232226
Policy train: iteration: 1000, policy_loss: 0.012420511
Policy train: iteration: 1500, policy_loss: 0.016460482
Policy train: iteration: 2000, policy_loss: 0.015523885
Policy train: iteration: 2500, policy_loss: 0.009874743
Policy train: iteration: 3000, policy_loss: 0.01099545
Policy train: iteration: 3500, policy_loss: 0.021100689
Policy train: iteration: 4000, policy_loss: 0.012182448
Policy train: iteration: 4500, policy_loss: 0.011382099
Policy train: iteration: 5000, policy_loss: 0.012700096
Policy train: iteration: 5500, policy_loss: 0.013682626
Policy train: iteration: 6000, policy_loss: 0.012831839
Policy train: iteration: 6500, policy_loss: 0.019123692
Policy train: iteration: 7000, policy_loss: 0.013568616
Policy train: iteration: 7500, policy_loss: 0.019387294
Policy train: iteration: 8000, policy_loss: 0.013065967
Policy train: iteration: 8500, policy_loss: 0.013382411
Policy train: iteration: 9000, policy_loss: 0.016745755
Policy train: iteration: 9500, policy_loss: 0.014548335
Policy train: iteration: 10000, policy_loss: 0.013521558
IDM train: iteration: 500, idm_loss: 0.096059
IDM train: iteration: 1000, idm_loss: 0.098578
IDM train: iteration: 1500, idm_loss: 0.086096
IDM train: iteration: 2000, idm_loss: 0.081659
IDM train: iteration: 2500, idm_loss: 0.074897
IDM train: iteration: 3000, idm_loss: 0.094205
IDM train: iteration: 3500, idm_loss: 0.109708
IDM train: iteration: 4000, idm_loss: 0.098091
IDM train: iteration: 4500, idm_loss: 0.092922
IDM train: iteration: 5000, idm_loss: 0.096229
IDM train: iteration: 5500, idm_loss: 0.101565
IDM train: iteration: 6000, idm_loss: 0.110562
IDM train: iteration: 6500, idm_loss: 0.117990
IDM train: iteration: 7000, idm_loss: 0.103829
IDM train: iteration: 7500, idm_loss: 0.109593
IDM train: iteration: 8000, idm_loss: 0.070958
IDM train: iteration: 8500, idm_loss: 0.072594
IDM train: iteration: 9000, idm_loss: 0.077282
IDM train: iteration: 9500, idm_loss: 0.088808
IDM train: iteration: 10000, idm_loss: 0.121815

iteration: 10, total_reward: 145.23367776987197, policy_loss: 0.039538458, idm_loss: 0.058972396

Policy train: iteration: 500, policy_loss: 0.017598592
Policy train: iteration: 1000, policy_loss: 0.010398882
Policy train: iteration: 1500, policy_loss: 0.012081106
Policy train: iteration: 2000, policy_loss: 0.012779328
Policy train: iteration: 2500, policy_loss: 0.013736941
Policy train: iteration: 3000, policy_loss: 0.012515655
Policy train: iteration: 3500, policy_loss: 0.012399407
Policy train: iteration: 4000, policy_loss: 0.017824955
Policy train: iteration: 4500, policy_loss: 0.011426596
Policy train: iteration: 5000, policy_loss: 0.013327774
Policy train: iteration: 5500, policy_loss: 0.01543246
Policy train: iteration: 6000, policy_loss: 0.0119396085
Policy train: iteration: 6500, policy_loss: 0.0128925685
Policy train: iteration: 7000, policy_loss: 0.014072851
Policy train: iteration: 7500, policy_loss: 0.010958451
Policy train: iteration: 8000, policy_loss: 0.012930886
Policy train: iteration: 8500, policy_loss: 0.013718759
Policy train: iteration: 9000, policy_loss: 0.01658844
Policy train: iteration: 9500, policy_loss: 0.013994889
Policy train: iteration: 10000, policy_loss: 0.037248228
IDM train: iteration: 500, idm_loss: 0.081607
IDM train: iteration: 1000, idm_loss: 0.105080
IDM train: iteration: 1500, idm_loss: 0.076037
IDM train: iteration: 2000, idm_loss: 0.093064
IDM train: iteration: 2500, idm_loss: 0.098871
IDM train: iteration: 3000, idm_loss: 0.071766
IDM train: iteration: 3500, idm_loss: 0.068215
IDM train: iteration: 4000, idm_loss: 0.076194
IDM train: iteration: 4500, idm_loss: 0.097528
IDM train: iteration: 5000, idm_loss: 0.085591
IDM train: iteration: 5500, idm_loss: 0.098047
IDM train: iteration: 6000, idm_loss: 0.073412
IDM train: iteration: 6500, idm_loss: 0.078495
IDM train: iteration: 7000, idm_loss: 0.098108
IDM train: iteration: 7500, idm_loss: 0.070970
IDM train: iteration: 8000, idm_loss: 0.102106
IDM train: iteration: 8500, idm_loss: 0.097447
IDM train: iteration: 9000, idm_loss: 0.083379
IDM train: iteration: 9500, idm_loss: 0.091292
IDM train: iteration: 10000, idm_loss: 0.080766

iteration: 11, total_reward: -88.61978663794386, policy_loss: 0.030730434, idm_loss: 0.08877168

Policy train: iteration: 500, policy_loss: 0.014482312
Policy train: iteration: 1000, policy_loss: 0.0128961615
Policy train: iteration: 1500, policy_loss: 0.016691647
Policy train: iteration: 2000, policy_loss: 0.009111855
Policy train: iteration: 2500, policy_loss: 0.016189251
Policy train: iteration: 3000, policy_loss: 0.017972628
Policy train: iteration: 3500, policy_loss: 0.0130805
Policy train: iteration: 4000, policy_loss: 0.011379501
Policy train: iteration: 4500, policy_loss: 0.015934162
Policy train: iteration: 5000, policy_loss: 0.0123871155
Policy train: iteration: 5500, policy_loss: 0.0128357755
Policy train: iteration: 6000, policy_loss: 0.0119416425
Policy train: iteration: 6500, policy_loss: 0.0152436225
Policy train: iteration: 7000, policy_loss: 0.011317486
Policy train: iteration: 7500, policy_loss: 0.01471016
Policy train: iteration: 8000, policy_loss: 0.029172182
Policy train: iteration: 8500, policy_loss: 0.011563588
Policy train: iteration: 9000, policy_loss: 0.01032634
Policy train: iteration: 9500, policy_loss: 0.011285456
Policy train: iteration: 10000, policy_loss: 0.011604026
IDM train: iteration: 500, idm_loss: 0.084421
IDM train: iteration: 1000, idm_loss: 0.093509
IDM train: iteration: 1500, idm_loss: 0.089130
IDM train: iteration: 2000, idm_loss: 0.085113
IDM train: iteration: 2500, idm_loss: 0.083484
IDM train: iteration: 3000, idm_loss: 0.108537
IDM train: iteration: 3500, idm_loss: 0.094045
IDM train: iteration: 4000, idm_loss: 0.084460
IDM train: iteration: 4500, idm_loss: 0.110485
IDM train: iteration: 5000, idm_loss: 0.094953
IDM train: iteration: 5500, idm_loss: 0.066552
IDM train: iteration: 6000, idm_loss: 0.063523
IDM train: iteration: 6500, idm_loss: 0.095973
IDM train: iteration: 7000, idm_loss: 0.105241
IDM train: iteration: 7500, idm_loss: 0.091837
IDM train: iteration: 8000, idm_loss: 0.087290
IDM train: iteration: 8500, idm_loss: 0.098668
IDM train: iteration: 9000, idm_loss: 0.077811
IDM train: iteration: 9500, idm_loss: 0.079440
IDM train: iteration: 10000, idm_loss: 0.083934

iteration: 12, total_reward: -83.86533186164748, policy_loss: 0.022179805, idm_loss: 0.04752501

Policy train: iteration: 500, policy_loss: 0.011832567
Policy train: iteration: 1000, policy_loss: 0.011457492
Policy train: iteration: 1500, policy_loss: 0.009793041
Policy train: iteration: 2000, policy_loss: 0.008911894
Policy train: iteration: 2500, policy_loss: 0.00893789
Policy train: iteration: 3000, policy_loss: 0.010868916
Policy train: iteration: 3500, policy_loss: 0.008885335
Policy train: iteration: 4000, policy_loss: 0.009529012
Policy train: iteration: 4500, policy_loss: 0.009144315
Policy train: iteration: 5000, policy_loss: 0.0106446
Policy train: iteration: 5500, policy_loss: 0.015951704
Policy train: iteration: 6000, policy_loss: 0.011225736
Policy train: iteration: 6500, policy_loss: 0.012639906
Policy train: iteration: 7000, policy_loss: 0.012496371
Policy train: iteration: 7500, policy_loss: 0.014368945
Policy train: iteration: 8000, policy_loss: 0.012603881
Policy train: iteration: 8500, policy_loss: 0.015466512
Policy train: iteration: 9000, policy_loss: 0.012767615
Policy train: iteration: 9500, policy_loss: 0.0132345
Policy train: iteration: 10000, policy_loss: 0.013793198
IDM train: iteration: 500, idm_loss: 0.093668
IDM train: iteration: 1000, idm_loss: 0.083744
IDM train: iteration: 1500, idm_loss: 0.095876
IDM train: iteration: 2000, idm_loss: 0.107542
IDM train: iteration: 2500, idm_loss: 0.110219
IDM train: iteration: 3000, idm_loss: 0.069147
IDM train: iteration: 3500, idm_loss: 0.103022
IDM train: iteration: 4000, idm_loss: 0.092946
IDM train: iteration: 4500, idm_loss: 0.090531
IDM train: iteration: 5000, idm_loss: 0.066212
IDM train: iteration: 5500, idm_loss: 0.091022
IDM train: iteration: 6000, idm_loss: 0.086615
IDM train: iteration: 6500, idm_loss: 0.060355
IDM train: iteration: 7000, idm_loss: 0.127123
IDM train: iteration: 7500, idm_loss: 0.093837
IDM train: iteration: 8000, idm_loss: 0.113900
IDM train: iteration: 8500, idm_loss: 0.132475
IDM train: iteration: 9000, idm_loss: 0.090889
IDM train: iteration: 9500, idm_loss: 0.094843
IDM train: iteration: 10000, idm_loss: 0.072941

iteration: 13, total_reward: -22.030134174010428, policy_loss: 0.02916726, idm_loss: 0.049255393

Policy train: iteration: 500, policy_loss: 0.011657907
Policy train: iteration: 1000, policy_loss: 0.007316929
Policy train: iteration: 1500, policy_loss: 0.011813788
Policy train: iteration: 2000, policy_loss: 0.015115885
Policy train: iteration: 2500, policy_loss: 0.009974236
Policy train: iteration: 3000, policy_loss: 0.015130494
Policy train: iteration: 3500, policy_loss: 0.011273075
Policy train: iteration: 4000, policy_loss: 0.015693488
Policy train: iteration: 4500, policy_loss: 0.014471724
Policy train: iteration: 5000, policy_loss: 0.012919114
Policy train: iteration: 5500, policy_loss: 0.01553036
Policy train: iteration: 6000, policy_loss: 0.012501075
Policy train: iteration: 6500, policy_loss: 0.01102832
Policy train: iteration: 7000, policy_loss: 0.01304367
Policy train: iteration: 7500, policy_loss: 0.015380263
Policy train: iteration: 8000, policy_loss: 0.0102825435
Policy train: iteration: 8500, policy_loss: 0.009415288
Policy train: iteration: 9000, policy_loss: 0.010145421
Policy train: iteration: 9500, policy_loss: 0.011886762
Policy train: iteration: 10000, policy_loss: 0.0073167514
IDM train: iteration: 500, idm_loss: 0.080955
IDM train: iteration: 1000, idm_loss: 0.070042
IDM train: iteration: 1500, idm_loss: 0.074290
IDM train: iteration: 2000, idm_loss: 0.095875
IDM train: iteration: 2500, idm_loss: 0.092860
IDM train: iteration: 3000, idm_loss: 0.114087
IDM train: iteration: 3500, idm_loss: 0.077380
IDM train: iteration: 4000, idm_loss: 0.122823
IDM train: iteration: 4500, idm_loss: 0.069772
IDM train: iteration: 5000, idm_loss: 0.077062
IDM train: iteration: 5500, idm_loss: 0.094282
IDM train: iteration: 6000, idm_loss: 0.106373
IDM train: iteration: 6500, idm_loss: 0.093247
IDM train: iteration: 7000, idm_loss: 0.085808
IDM train: iteration: 7500, idm_loss: 0.112569
IDM train: iteration: 8000, idm_loss: 0.096383
IDM train: iteration: 8500, idm_loss: 0.056170
IDM train: iteration: 9000, idm_loss: 0.076929
IDM train: iteration: 9500, idm_loss: 0.061384
IDM train: iteration: 10000, idm_loss: 0.077907

iteration: 14, total_reward: -104.44377078295778, policy_loss: 0.023415618, idm_loss: 0.04749923

Policy train: iteration: 500, policy_loss: 0.014080378
Policy train: iteration: 1000, policy_loss: 0.014881298
Policy train: iteration: 1500, policy_loss: 0.0137275215
Policy train: iteration: 2000, policy_loss: 0.013514283
Policy train: iteration: 2500, policy_loss: 0.011263611
Policy train: iteration: 3000, policy_loss: 0.012002277
Policy train: iteration: 3500, policy_loss: 0.010036221
Policy train: iteration: 4000, policy_loss: 0.011138455
Policy train: iteration: 4500, policy_loss: 0.01246368
Policy train: iteration: 5000, policy_loss: 0.0111982
Policy train: iteration: 5500, policy_loss: 0.027311236
Policy train: iteration: 6000, policy_loss: 0.0104511855
Policy train: iteration: 6500, policy_loss: 0.01898996
Policy train: iteration: 7000, policy_loss: 0.011143123
Policy train: iteration: 7500, policy_loss: 0.011542123
Policy train: iteration: 8000, policy_loss: 0.02815498
Policy train: iteration: 8500, policy_loss: 0.012725798
Policy train: iteration: 9000, policy_loss: 0.013817591
Policy train: iteration: 9500, policy_loss: 0.009920873
Policy train: iteration: 10000, policy_loss: 0.010719387
IDM train: iteration: 500, idm_loss: 0.087652
IDM train: iteration: 1000, idm_loss: 0.083384
IDM train: iteration: 1500, idm_loss: 0.113239
IDM train: iteration: 2000, idm_loss: 0.075609
IDM train: iteration: 2500, idm_loss: 0.063171
IDM train: iteration: 3000, idm_loss: 0.076172
IDM train: iteration: 3500, idm_loss: 0.081589
IDM train: iteration: 4000, idm_loss: 0.075978
IDM train: iteration: 4500, idm_loss: 0.099940
IDM train: iteration: 5000, idm_loss: 0.103065
IDM train: iteration: 5500, idm_loss: 0.096930
IDM train: iteration: 6000, idm_loss: 0.108165
IDM train: iteration: 6500, idm_loss: 0.073536
IDM train: iteration: 7000, idm_loss: 0.081645
IDM train: iteration: 7500, idm_loss: 0.095832
IDM train: iteration: 8000, idm_loss: 0.083570
IDM train: iteration: 8500, idm_loss: 0.073750
IDM train: iteration: 9000, idm_loss: 0.117654
IDM train: iteration: 9500, idm_loss: 0.085532
IDM train: iteration: 10000, idm_loss: 0.067345

iteration: 15, total_reward: -77.96689311563907, policy_loss: 0.023504168, idm_loss: 0.07050672

Policy train: iteration: 500, policy_loss: 0.010054732
Policy train: iteration: 1000, policy_loss: 0.017866125
Policy train: iteration: 1500, policy_loss: 0.011789762
Policy train: iteration: 2000, policy_loss: 0.010472409
Policy train: iteration: 2500, policy_loss: 0.014194794
Policy train: iteration: 3000, policy_loss: 0.013206524
Policy train: iteration: 3500, policy_loss: 0.0076393643
Policy train: iteration: 4000, policy_loss: 0.009449766
Policy train: iteration: 4500, policy_loss: 0.008531736
Policy train: iteration: 5000, policy_loss: 0.010292933
Policy train: iteration: 5500, policy_loss: 0.010448575
Policy train: iteration: 6000, policy_loss: 0.009575677
Policy train: iteration: 6500, policy_loss: 0.011045302
Policy train: iteration: 7000, policy_loss: 0.013137437
Policy train: iteration: 7500, policy_loss: 0.009798281
Policy train: iteration: 8000, policy_loss: 0.012402324
Policy train: iteration: 8500, policy_loss: 0.009350836
Policy train: iteration: 9000, policy_loss: 0.010421837
Policy train: iteration: 9500, policy_loss: 0.008633779
Policy train: iteration: 10000, policy_loss: 0.007936249
IDM train: iteration: 500, idm_loss: 0.084803
IDM train: iteration: 1000, idm_loss: 0.091809
IDM train: iteration: 1500, idm_loss: 0.104905
IDM train: iteration: 2000, idm_loss: 0.077162
IDM train: iteration: 2500, idm_loss: 0.089493
IDM train: iteration: 3000, idm_loss: 0.080342
IDM train: iteration: 3500, idm_loss: 0.087736
IDM train: iteration: 4000, idm_loss: 0.068474
IDM train: iteration: 4500, idm_loss: 0.085858
IDM train: iteration: 5000, idm_loss: 0.072399
IDM train: iteration: 5500, idm_loss: 0.071581
IDM train: iteration: 6000, idm_loss: 0.110199
IDM train: iteration: 6500, idm_loss: 0.091531
IDM train: iteration: 7000, idm_loss: 0.066484
IDM train: iteration: 7500, idm_loss: 0.057945
IDM train: iteration: 8000, idm_loss: 0.066219
IDM train: iteration: 8500, idm_loss: 0.098167
IDM train: iteration: 9000, idm_loss: 0.076928
IDM train: iteration: 9500, idm_loss: 0.064623
IDM train: iteration: 10000, idm_loss: 0.089941

iteration: 16, total_reward: 180.41075818961883, policy_loss: 0.02525109, idm_loss: 0.06629157

Policy train: iteration: 500, policy_loss: 0.012672195
Policy train: iteration: 1000, policy_loss: 0.007025786
Policy train: iteration: 1500, policy_loss: 0.011608415
Policy train: iteration: 2000, policy_loss: 0.011549156
Policy train: iteration: 2500, policy_loss: 0.01203708
Policy train: iteration: 3000, policy_loss: 0.0127868755
Policy train: iteration: 3500, policy_loss: 0.0062875026
Policy train: iteration: 4000, policy_loss: 0.01393498
Policy train: iteration: 4500, policy_loss: 0.008109449
Policy train: iteration: 5000, policy_loss: 0.012071996
Policy train: iteration: 5500, policy_loss: 0.011386987
Policy train: iteration: 6000, policy_loss: 0.011114149
Policy train: iteration: 6500, policy_loss: 0.0087411925
