
iteration: 1, total_reward: -434.242966007873, policy_loss: 1.350591, idm_loss: 1.311048

Policy train: iteration: 500, policy_loss: 0.000798
Policy train: iteration: 1000, policy_loss: 0.000259
Policy train: iteration: 1500, policy_loss: 0.000103
Policy train: iteration: 2000, policy_loss: 0.000053
Policy train: iteration: 2500, policy_loss: 0.000030
Policy train: iteration: 3000, policy_loss: 0.000020
Policy train: iteration: 3500, policy_loss: 0.000012
Policy train: iteration: 4000, policy_loss: 0.000009
Policy train: iteration: 4500, policy_loss: 0.000007
Policy train: iteration: 5000, policy_loss: 0.000004
Policy train: iteration: 5500, policy_loss: 0.000005
Policy train: iteration: 6000, policy_loss: 0.000003
Policy train: iteration: 6500, policy_loss: 0.000001
Policy train: iteration: 7000, policy_loss: 0.000001

iteration: 2, total_reward: -610.2079413173767, policy_loss: 0.000002, idm_loss: 1.310859


iteration: 3, total_reward: -623.2845320272073, policy_loss: 0.000002, idm_loss: 1.310898

Policy train: iteration: 500, policy_loss: 0.000001
Policy train: iteration: 1000, policy_loss: 0.000001
Policy train: iteration: 1500, policy_loss: 0.000001
Policy train: iteration: 2000, policy_loss: 0.000000
Policy train: iteration: 2500, policy_loss: 0.000000
Policy train: iteration: 3000, policy_loss: 0.000000
Policy train: iteration: 3500, policy_loss: 0.000000
Policy train: iteration: 4000, policy_loss: 0.000000
Policy train: iteration: 4500, policy_loss: 0.000000
Policy train: iteration: 5000, policy_loss: 0.000000
Policy train: iteration: 5500, policy_loss: 0.000000
Policy train: iteration: 6000, policy_loss: 0.000000
Policy train: iteration: 6500, policy_loss: 0.000000
Policy train: iteration: 7000, policy_loss: 0.000000

iteration: 4, total_reward: -552.5939311044868, policy_loss: 0.000000, idm_loss: 1.310620

