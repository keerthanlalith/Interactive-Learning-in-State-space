Collecting idm training data 1000
IDM train: iteration: 500, idm_loss: 0.024782
IDM train: iteration: 1000, idm_loss: 0.003735

iteration: 1, total_reward: 11.0, policy_loss: 0.692971, idm_loss: 0.002760


iteration: 2, total_reward: 10.0, policy_loss: 0.696919, idm_loss: 0.001938


iteration: 3, total_reward: 9.0, policy_loss: 0.691986, idm_loss: 0.001699


iteration: 4, total_reward: 9.0, policy_loss: 0.717665, idm_loss: 0.001876


iteration: 5, total_reward: 10.0, policy_loss: 0.718951, idm_loss: 0.002011


iteration: 6, total_reward: 9.0, policy_loss: 0.736761, idm_loss: 0.001988


iteration: 7, total_reward: 8.0, policy_loss: 0.746211, idm_loss: 0.001812


iteration: 8, total_reward: 9.0, policy_loss: 0.753255, idm_loss: 0.002008


iteration: 9, total_reward: 10.0, policy_loss: 0.720835, idm_loss: 0.002095


iteration: 10, total_reward: 9.0, policy_loss: 0.736552, idm_loss: 0.001826


iteration: 11, total_reward: 10.0, policy_loss: 0.752607, idm_loss: 0.002143


iteration: 12, total_reward: 9.0, policy_loss: 0.739949, idm_loss: 0.002098


iteration: 13, total_reward: 10.0, policy_loss: 0.756856, idm_loss: 0.001884


iteration: 14, total_reward: 9.0, policy_loss: 0.764988, idm_loss: 0.002000


iteration: 15, total_reward: 9.0, policy_loss: 0.767484, idm_loss: 0.001777


iteration: 16, total_reward: 10.0, policy_loss: 0.779250, idm_loss: 0.001655


iteration: 17, total_reward: 9.0, policy_loss: 0.772359, idm_loss: 0.002199


iteration: 18, total_reward: 10.0, policy_loss: 0.764820, idm_loss: 0.002019


iteration: 19, total_reward: 10.0, policy_loss: 0.768147, idm_loss: 0.001895


iteration: 20, total_reward: 10.0, policy_loss: 0.769907, idm_loss: 0.002231


iteration: 21, total_reward: 10.0, policy_loss: 0.774753, idm_loss: 0.001597


iteration: 22, total_reward: 10.0, policy_loss: 0.761416, idm_loss: 0.001939


iteration: 23, total_reward: 10.0, policy_loss: 0.767974, idm_loss: 0.001866


iteration: 24, total_reward: 9.0, policy_loss: 0.761508, idm_loss: 0.002269


iteration: 25, total_reward: 10.0, policy_loss: 0.757735, idm_loss: 0.002033


iteration: 26, total_reward: 11.0, policy_loss: 0.765879, idm_loss: 0.001999


iteration: 27, total_reward: 9.0, policy_loss: 0.759582, idm_loss: 0.002135


iteration: 28, total_reward: 9.0, policy_loss: 0.762524, idm_loss: 0.001574


iteration: 29, total_reward: 10.0, policy_loss: 0.763827, idm_loss: 0.001726


iteration: 30, total_reward: 9.0, policy_loss: 0.761557, idm_loss: 0.002157


iteration: 31, total_reward: 8.0, policy_loss: 0.755743, idm_loss: 0.002029


iteration: 32, total_reward: 10.0, policy_loss: 0.753279, idm_loss: 0.001803


iteration: 33, total_reward: 10.0, policy_loss: 0.740728, idm_loss: 0.002229


iteration: 34, total_reward: 10.0, policy_loss: 0.750464, idm_loss: 0.001881


iteration: 35, total_reward: 10.0, policy_loss: 0.769907, idm_loss: 0.002218


iteration: 36, total_reward: 10.0, policy_loss: 0.769505, idm_loss: 0.002097


iteration: 37, total_reward: 9.0, policy_loss: 0.785109, idm_loss: 0.002008


iteration: 38, total_reward: 10.0, policy_loss: 0.777467, idm_loss: 0.001680

