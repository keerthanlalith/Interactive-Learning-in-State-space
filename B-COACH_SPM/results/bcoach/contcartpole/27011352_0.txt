Collecting idm training data 1000
IDM train: iteration: 500, idm_loss: 0.088387
IDM train: iteration: 1000, idm_loss: 0.002459

iteration: 1, total_reward: 56.0, policy_loss: 0.942181, idm_loss: 0.000345


iteration: 2, total_reward: 45.0, policy_loss: 0.948098, idm_loss: 0.000074


iteration: 3, total_reward: 68.0, policy_loss: 0.930481, idm_loss: 0.000129


iteration: 4, total_reward: 50.0, policy_loss: 0.888362, idm_loss: 0.000089


iteration: 5, total_reward: 99.0, policy_loss: 0.865535, idm_loss: 0.000021

Collecting idm training data 1000
IDM train: iteration: 500, idm_loss: 0.002321
IDM train: iteration: 1000, idm_loss: 0.001281

iteration: 6, total_reward: 134.0, policy_loss: 0.874218, idm_loss: 0.000020


iteration: 7, total_reward: 271.0, policy_loss: 0.880585, idm_loss: 0.000146


iteration: 8, total_reward: 500.0, policy_loss: 0.855446, idm_loss: 0.000051


iteration: 9, total_reward: 500.0, policy_loss: 0.874770, idm_loss: 0.000082


iteration: 10, total_reward: 500.0, policy_loss: 0.866106, idm_loss: 0.000070

Collecting idm training data 1000
IDM train: iteration: 500, idm_loss: 0.000071
IDM train: iteration: 1000, idm_loss: 0.000383
