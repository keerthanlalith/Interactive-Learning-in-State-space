Collecting idm training data 1000
Collecting idm training data 2000
Collecting idm training data 3000
Collecting idm training data 4000
Collecting idm training data 5000
Collecting idm training data 6000
Collecting idm training data 7000
Collecting idm training data 8000
Collecting idm training data 9000
Collecting idm training data 10000
Collecting idm training data 11000
Collecting idm training data 12000
Collecting idm training data 13000
Collecting idm training data 14000
Collecting idm training data 15000
Collecting idm training data 16000
Collecting idm training data 17000
Collecting idm training data 18000
Collecting idm training data 19000
Collecting idm training data 20000
IDM train: iteration: 500, idm_loss: 0.339254
IDM train: iteration: 1000, idm_loss: 0.319354
IDM train: iteration: 1500, idm_loss: 0.339819
IDM train: iteration: 2000, idm_loss: 0.189035
IDM train: iteration: 2500, idm_loss: 0.199710
IDM train: iteration: 3000, idm_loss: 0.209538
IDM train: iteration: 3500, idm_loss: 0.171004
IDM train: iteration: 4000, idm_loss: 0.170418
IDM train: iteration: 4500, idm_loss: 0.122850
IDM train: iteration: 5000, idm_loss: 0.118668
IDM train: iteration: 5500, idm_loss: 0.075668
IDM train: iteration: 6000, idm_loss: 0.065590
IDM train: iteration: 6500, idm_loss: 0.102930
IDM train: iteration: 7000, idm_loss: 0.115387
SPM train: iteration: 500, spm_loss: 0.031394
SPM train: iteration: 1000, spm_loss: 0.002396
SPM train: iteration: 1500, spm_loss: 0.003134
SPM train: iteration: 2000, spm_loss: 0.001346
SPM train: iteration: 2500, spm_loss: 0.006051
SPM train: iteration: 3000, spm_loss: 0.004209
SPM train: iteration: 3500, spm_loss: 0.001123
SPM train: iteration: 4000, spm_loss: 0.005321
SPM train: iteration: 4500, spm_loss: 0.000605
SPM train: iteration: 5000, spm_loss: 0.000508
SPM train: iteration: 5500, spm_loss: 0.000643
SPM train: iteration: 6000, spm_loss: 0.004819
SPM train: iteration: 6500, spm_loss: 0.000185
SPM train: iteration: 7000, spm_loss: 0.011572

iteration: 1, total_reward: -386.9131969273299, policy_loss: 0.167166, idm_loss: 0.052641


iteration: 2, total_reward: -296.2278148151587, policy_loss: 0.177547, idm_loss: 0.073282


iteration: 3, total_reward: -148.57575451724318, policy_loss: 0.163027, idm_loss: 0.060458


iteration: 4, total_reward: -152.48956858536934, policy_loss: 0.154330, idm_loss: 0.067793


iteration: 5, total_reward: -176.10791733072887, policy_loss: 0.132742, idm_loss: 0.087068


iteration: 6, total_reward: -367.06706941429024, policy_loss: 0.157743, idm_loss: 0.041356


iteration: 7, total_reward: -329.00933854683035, policy_loss: 0.146641, idm_loss: 0.043953


iteration: 8, total_reward: -129.75793741466134, policy_loss: 0.146746, idm_loss: 0.063781


iteration: 9, total_reward: -118.10657885061255, policy_loss: 0.209081, idm_loss: 0.086567


iteration: 10, total_reward: -133.79392866932403, policy_loss: 0.204601, idm_loss: 0.124726


iteration: 11, total_reward: -137.4808748855448, policy_loss: 0.186741, idm_loss: 0.068044


iteration: 12, total_reward: -377.0930588402213, policy_loss: 0.251045, idm_loss: 0.126200


iteration: 13, total_reward: -407.81546166290707, policy_loss: 0.286708, idm_loss: 0.126284


iteration: 14, total_reward: -101.12054844079557, policy_loss: 0.250014, idm_loss: 0.044358


iteration: 15, total_reward: -488.1671666552734, policy_loss: 0.252421, idm_loss: 0.282311


iteration: 16, total_reward: -481.4781492204968, policy_loss: 0.400059, idm_loss: 0.200800


iteration: 17, total_reward: -126.60589566984925, policy_loss: 0.319849, idm_loss: 0.250472


iteration: 18, total_reward: -416.4903211902084, policy_loss: 0.191814, idm_loss: 0.057372


iteration: 19, total_reward: -137.34356354860955, policy_loss: 0.184720, idm_loss: 0.134105


iteration: 20, total_reward: -52.05111955166231, policy_loss: 0.213723, idm_loss: 0.099978


iteration: 21, total_reward: -93.08833018777403, policy_loss: 0.189886, idm_loss: 0.088946


iteration: 22, total_reward: -103.65497929095416, policy_loss: 0.194986, idm_loss: 0.074088

