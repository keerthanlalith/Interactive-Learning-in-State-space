Collecting idm training data 1000
Collecting idm training data 2000
Collecting idm training data 3000
Collecting idm training data 4000
Collecting idm training data 5000
Collecting idm training data 6000
Collecting idm training data 7000
Collecting idm training data 8000
Collecting idm training data 9000
Collecting idm training data 10000
Collecting idm training data 11000
Collecting idm training data 12000
Collecting idm training data 13000
Collecting idm training data 14000
Collecting idm training data 15000
Collecting idm training data 16000
Collecting idm training data 17000
Collecting idm training data 18000
Collecting idm training data 19000
Collecting idm training data 20000
IDM train: iteration: 500, idm_loss: 0.001091
IDM train: iteration: 1000, idm_loss: 0.002763
IDM train: iteration: 1500, idm_loss: 0.009331
IDM train: iteration: 2000, idm_loss: 0.009291
IDM train: iteration: 2500, idm_loss: 0.021242
IDM train: iteration: 3000, idm_loss: 0.010898
IDM train: iteration: 3500, idm_loss: 0.015267
IDM train: iteration: 4000, idm_loss: 0.046952
IDM train: iteration: 4500, idm_loss: 0.054323
IDM train: iteration: 5000, idm_loss: 0.072017
IDM train: iteration: 5500, idm_loss: 0.070138
IDM train: iteration: 6000, idm_loss: 0.182874
IDM train: iteration: 6500, idm_loss: 0.086284
IDM train: iteration: 7000, idm_loss: 0.146324
SPM train: iteration: 500, spm_loss: 0.091677
SPM2 train: iteration: 500, spm2_loss: 0.076428
SPM train: iteration: 1000, spm_loss: 0.058328
SPM2 train: iteration: 1000, spm2_loss: 0.063065
SPM train: iteration: 1500, spm_loss: 0.036551
SPM2 train: iteration: 1500, spm2_loss: 0.050096
SPM train: iteration: 2000, spm_loss: 0.029152
SPM2 train: iteration: 2000, spm2_loss: 0.041617
SPM train: iteration: 2500, spm_loss: 0.020703
SPM2 train: iteration: 2500, spm2_loss: 0.035012
SPM train: iteration: 3000, spm_loss: 0.017692
SPM2 train: iteration: 3000, spm2_loss: 0.028423
SPM train: iteration: 3500, spm_loss: 0.017002
SPM2 train: iteration: 3500, spm2_loss: 0.021655
SPM train: iteration: 4000, spm_loss: 0.016905
SPM2 train: iteration: 4000, spm2_loss: 0.018154
SPM train: iteration: 4500, spm_loss: 0.015206
SPM2 train: iteration: 4500, spm2_loss: 0.016574
SPM train: iteration: 5000, spm_loss: 0.011646
SPM2 train: iteration: 5000, spm2_loss: 0.010979
SPM train: iteration: 5500, spm_loss: 0.009505
SPM2 train: iteration: 5500, spm2_loss: 0.009101
SPM train: iteration: 6000, spm_loss: 0.012940
SPM2 train: iteration: 6000, spm2_loss: 0.012157
SPM train: iteration: 6500, spm_loss: 0.009789
SPM2 train: iteration: 6500, spm2_loss: 0.021419
SPM train: iteration: 7000, spm_loss: 0.011097
SPM2 train: iteration: 7000, spm2_loss: 0.013528

iteration: 1, total_reward: -187.61130601283134, policy_loss: 0.158280, idm_loss: 0.138590


iteration: 2, total_reward: -110.48282606062395, policy_loss: 0.144683, idm_loss: 0.143437


iteration: 3, total_reward: -107.14968929724051, policy_loss: 0.170164, idm_loss: 0.136921


iteration: 4, total_reward: -122.15765609256073, policy_loss: 0.150969, idm_loss: 0.143246


iteration: 5, total_reward: -106.5696619367042, policy_loss: 0.161607, idm_loss: 0.140252


iteration: 6, total_reward: -100.6975825387214, policy_loss: 0.282517, idm_loss: 0.059866


iteration: 7, total_reward: -45.440116558591896, policy_loss: 0.155887, idm_loss: 0.158734


iteration: 8, total_reward: 13.121193262557384, policy_loss: 0.148229, idm_loss: 0.076430


iteration: 9, total_reward: -72.1646657713262, policy_loss: 0.191415, idm_loss: 0.141897


iteration: 10, total_reward: -0.2783610328944377, policy_loss: 0.207082, idm_loss: 0.082232


iteration: 11, total_reward: -3.543284277060536, policy_loss: 0.280093, idm_loss: 0.122596


iteration: 12, total_reward: 1.3061406839874223, policy_loss: 0.229307, idm_loss: 0.118454


iteration: 13, total_reward: 1.8397359710602217, policy_loss: 0.231918, idm_loss: 0.130903


iteration: 14, total_reward: -288.6671461165427, policy_loss: 0.282242, idm_loss: 0.344203

