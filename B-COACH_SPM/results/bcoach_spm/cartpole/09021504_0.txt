Collecting idm training data 1000
IDM train: iteration: 500, idm_loss: 0.014041
IDM train: iteration: 1000, idm_loss: 0.001474
IDM train: iteration: 1500, idm_loss: 0.000729
IDM train: iteration: 2000, idm_loss: 0.000298
IDM train: iteration: 2500, idm_loss: 0.000140
IDM train: iteration: 3000, idm_loss: 0.000104
IDM train: iteration: 3500, idm_loss: 0.000061
IDM train: iteration: 4000, idm_loss: 0.000039
IDM train: iteration: 4500, idm_loss: 0.000022
IDM train: iteration: 5000, idm_loss: 0.000022
SPM train: iteration: 500, spm_loss: 0.021920
SPM train: iteration: 1000, spm_loss: 0.009399
SPM train: iteration: 1500, spm_loss: 0.004657
SPM train: iteration: 2000, spm_loss: 0.004424
SPM train: iteration: 2500, spm_loss: 0.003932
SPM train: iteration: 3000, spm_loss: 0.003924
SPM train: iteration: 3500, spm_loss: 0.003629
SPM train: iteration: 4000, spm_loss: 0.003015
SPM train: iteration: 4500, spm_loss: 0.003139
SPM train: iteration: 5000, spm_loss: 0.002231

iteration: 1, total_reward: 9.0, policy_loss: 0.693193, idm_loss: 0.000019


iteration: 2, total_reward: 9.0, policy_loss: 0.693347, idm_loss: 0.000020


iteration: 3, total_reward: 9.0, policy_loss: 0.693074, idm_loss: 0.000023


iteration: 4, total_reward: 9.0, policy_loss: 0.693110, idm_loss: 0.000019


iteration: 5, total_reward: 9.0, policy_loss: 0.693464, idm_loss: 0.000021


iteration: 6, total_reward: 9.0, policy_loss: 0.693371, idm_loss: 0.000019


iteration: 7, total_reward: 8.0, policy_loss: 0.693134, idm_loss: 0.000023


iteration: 8, total_reward: 9.0, policy_loss: 0.693064, idm_loss: 0.000027


iteration: 9, total_reward: 10.0, policy_loss: 0.693041, idm_loss: 0.000022


iteration: 10, total_reward: 10.0, policy_loss: 0.692910, idm_loss: 0.000022

